== TCP server ==
1. 每个客户端连接产生TcpServerThread线程
2. 每个数据库产生WriterThread（负责定时flush）以及FileLock对象（Lock method）
3. 每个TcpServerThread线程有一个用户Session
4、每个连接（Session）一次启动一个事务中，每个事务可以由多个QUERY、UPDATE的statement组成，执行statement都会发送到Server端。默认情况下，Server端只允许一个session给同一个database执行statement，所以每次执行statement都会对database进行synchronized（可以设置MULTI_THREADED属性，这样就允许多个session同时执行statement，所以是对session进行synchronized，但不确保该特性稳定）。为了确保不同连接之间的事务保持ACID，H2使用table lock机制。
5、每个连接一次只能打开一个数据库


Database相关：
*每个DataBase对象有一个PageStore对象表示Database文件的页集合。

*创建PageStore的时候，会从文件的Page 4读取meta table的root page数据(其中包括所有表的索引的indexId和对应的rootPageId)
*然后创建Public.SYS. Public.SYS保存创建其它元数据表的SQL语句

*PageStore读取一个指定pageId的Page时候，根据pageId << pageSizeShift计算Page的偏移，然后读取pageSize大小（默认2048）到byte数组中。即文件按照固定pageSize大小分每个Page。

*RegularTable对象表示数据库中的表。
*RegularTable初始化的时候，如果是持久化则创建PageDataIndex作为mainIndex和scanIndex，否则创建ScanIndex对象作为scanIndex，mainIndex为null。
*RegularTable的primary key是单一列，并且类型是long,int,short,byte的时候，会创建封装mainIndex的PageDelegateIndex作为primary key的索引，否则会创建PageBtreeIndex作为primary key的索引。

DataBase
|
|--RegularTable meta(Public.SYS)
|--PageStore
   |
   |--CacheLRU
   |--FileStore


PageStore相关：
*PageStore是整个Database的存储层抽象；包含FileStore对象，封装随机访问文件的功能，包含CacheLRU对象，利用LRU算法缓存Page数据
*PageStore同时负责通过PageId读取底层文件中不同类型的Page（如PageDataLeaf,PageDataNode, PageBtreeLeaf, PageBtreeNode等）。
*PageStore也负责本Database的undo log的操控。
*FileStore对象可以根据实际情况修改底层访问，如FileDisk、FileMem等

-初始化的时候，从Page0读取固定文件头，初始化pageSize、freeListPagesPerList、fileLength、pageCount；接着需要读变量文件头readVariableHeader，首先校验Page1的checksum，如果校验失败，则尝试读Page2，如果都失败则文件损坏。从可变文件头读取，logKey、logFirstTrunkPage、logFirstDataPage等undo日志相关的值。然后初始化PageLog。Page0，Page1，Page2都不会被cache。

-PageFreeList。
使用1 bit表示页是否在使用。pageSize为2048的时候，一个PageFreeList就可以表示2045 * 8 = 16360页，总共可以表示约32MB的数据，当pageID超过16360 + 3的时候，则会重新分配PageFreeList，负责表示后面的16360页是否使用。内部用used的BitField代表已经使用的页，注意从Page4开始计算used的值。
PageStore包括一个PageFreeList数组。

Page类型：
TYPE_EMPTY = 0;          //An empty page.
TYPE_DATA_LEAF = 1;      //A data leaf page (without overflow: + FLAG_LAST)
TYPE_DATA_NODE = 2;      //A data node page (never has overflow pages).
TYPE_DATA_OVERFLOW = 3;  //A data overflow page (the last page: + FLAG_LAST).
TYPE_BTREE_LEAF = 4;     //A b-tree leaf page (without overflow: + FLAG_LAST).
TYPE_BTREE_NODE = 5;     //A b-tree node page (never has overflow pages).
TYPE_FREE_LIST = 6;      //A page containing a list of free pages (the last page: + FLAG_LAST).
TYPE_STREAM_TRUNK = 7;   //A stream trunk page.   PageLog日志使用
TYPE_STREAM_DATA = 8;    //A stream data page.    PageLog日志使用


文件中Page分布：
Page 0:
固定文件头。
HEADER、pageSize、writeVersion、readVersion

Page1:
变量文件头。
checksum、writeCountBase、logKey、logFirstTrunkPage、logFirstDataPage

Page2:
Page1的备份，当checksum无效的时候会被读取。

Page3:
PAGE_ID_FREE_LIST_ROOT
freeList的root。

Page4:
元数据表metaTable（PAGE_INDEX表）的数据页。
负责内部表初始化。

Page5 -- logFirstTrunkPage（1067？） 中都为数据页或者索引页


(以下开始索引的讨论，暂时忽略用于地理坐标的spatial类型的index)
====    PageIndex   ====  
*PageIndex是索引类（PageBtreeIndex, PageDataIndex以及PageDelegateIndex）的基类
*成员变量rootPageId指示对应的PageDataNode/PageDataLeaf或PageBtreeNode/PageBtreeLeaf根索引数据页；
*PageBtreeIndex, PageDataIndex子类都有PageStore的引用方便从rootPageId获取索引数据页


====  Page索引页数据  ====
Page
|
--PageData
| |
| --PageDataNode
| --PageDataLeaf
|
--PageBtree
  |
  --PageBtreeNode
  --PageBtreeLeaf


PageData（PageDataNode/PageDataLeaf父类）
--PageDataIndex index
--int parentPageId
--Data data         data page
--int entryCount    number of entries
--long[] keys       row keys

PageDataNode
--int[] childPageIds
layout:
entries (child page id: int, key: varLong)

PageDataLeaf
--int[] offsets     row offsets to read data
--Row[] rows        the rows
layout:
list of key / offset pairs (key: varLong, offset: shortInt)
data

PageBtree（PageBtreeNode/PageBtreeLeaf父类）
--PageBtreeIndex index
--int parentPageId
--Data data         data page
--int[] offsets     read data to get child page key
--int entryCount    number of entries
--SearchRow[] rows  index data
--onlyPosition      data是否只保存row的key（scanIndex的key），详细见下面

PageBtreeNode
--int[] childPageIds
layout:
entries (child page id: int, offset: short)   offsets

PageBtreeLeaf
layout:
list of offsets: short
data (key: varLong, value,...)


*XNode类是内部结点，XLeaf类作为叶子结点
*内部成员rootPageId所指示索引页，如果数据量少，则指定一个XLeaf，数据量大，rootPageId则指定XNode。
*结构都是由多层XNode内部结点到最后XLeaf叶子结点的树。
*PageDataNode保存keys和对应的childPageIds；PageDataLeaf保存keys和对应的offsets，以及data保存row的全部列值。PageDataNode中keys[0]是childPageIds[0]中最大的rowKey，并且keys大小为entryCount，childPageIds大小为entryCount+1，最后一个childPageIds为最右边的子页。
*PageBtreeNode保存keys（SearchRow）和对应的childPageIDs；PageBtreeLeaf根据情况可能保存row的key或者row的全部值。


====  PageDataIndex/PageDataNode/PageDataLeaf ====
*PageDataIndex主要作用就是组织表数据，RegularTable默认创建的mainIndex，只可以用于mainIndex。

*primary key符合条件（单列，并且类型是long,int,short,byte）时，primary key的Index类就简单封装PageDataIndex，同时PageDataNode/PageDataLeaf保存的keys就是primary key的值，否则parimary key的Index类就是PageBtreeIndex类，PageDataNode/Leaf保存的keys数组是对应每个row的自增值。

*PageDataNode保存Keys和对应的childPageIds表示子页PageDataLeaf/PageDataNode的pageId，查找key时，通过二分查找找到对应的子页的pageId。然后通过PageStore获取对应的子页
*PageDataLeaf内部保存Key和对应的offset。keys数组表示保存的key，offsets数组表示成员变量data里面每个key对应的数据offset。data保存的数据是row的全部列的值。


====  PageBtreeIndex/PageBtreeNode/PageBtreeLeaf  ====
*PageBtreeIndex就是二级B树索引，用于主键或者二级索引，不能用于内部scanIndex的索引（另外还有SpatialTreeIndex，基于MVR TreeMap，R树的一个实现）。
*PageBtreeNode与PageDataNode类似，代表的是B树的内部结点，PageBtreeLeaf则是其B树的叶子结点。

*onlyPosition成员变量，指示data是否只保存row的key，注意key为scanIndex所表示的key，即可能为primary key或者内部自增key。默认false。
 onlyPosition = true，则获取row的时候，需要通过offset获取data里面的key，然后通过RegularTable的scanIndex去查找对应的row的所有列的数据（同样利用二分查找）。由于需要scanIndex查找，产生更多的I/O。
 onlyPosition = false，则获取row的时候，直接通过offset获取data里面的数据，也就是row对应所有 索引列 的数据。注意只是索引列。直接从内存中data数据获取，不要消耗I/O。
 一般在PageBtreeNode插入新的childPage，或者PageBtreeLeaf插入新的row的时候data空间不足的时候可能会令onlyPosition=true，另外还要考虑split的情况。(TODO)

*PageBtreeNode/Leaf在二分查找的时候，根据row的索引列进行Value值对比：首先根据两个比较类型，按照规则转换到同一个指定类型，然后进行比较。

*迭代PageBtreeCursor

*默认NULL比较时，会小于任何非NULL的值，因此NULL会排在最前

== SQL Parser ==
使用Recursive descent中的predictive parser算法（https://en.wikipedia.org/wiki/Recursive_descent_parser）

流程：
Parser.parse(String sql)
1.initialize(String sql) 把sql转换大写，同时解析每个字符的所属类型（CHAR_SPECIAL_1，CHAR_NAME等）
2.read(), parsePrepared() 根据第一个符号分类进行SQL解析。parseSelect, parseInsert, parseDelete etc.
3.parseSelect() parse的具体过程，根据符号进行predictive parse，注意区分parseSelectUnion, parseSelectSimple等  
4.Select.prepare() 进行SQL优化（包括解析列名称，值优化、索引选择），CBO选择最优执行计划，各种优化细节等。
5.解析结果Command放入cache中


//select
======================================
=============== Select ===============
======================================
*Select命令执行的时候，每个表用TableFilter表示，每个TableFilter只能有一个index。
*TableFilter有IndexCursor cursor对象，方便利用PageIndex对象进行迭代查询

*Select.preparePlan() -> Optimizer.optimize() -> Optimizer.calculateBestPlan() 如果只有一个表，则采用计算这个表的cost选择select索引。少于等于7个表的时候，采用BruteForce算法（应该是对所有排列可能性计算cost）
*计算表的cost的时候，如果没有可用索引的条件语句，则使用RegularTable的scanIndex作为此次查询的索引。否则遍历所有索引，调用Index.getCost，通过where中条件列的情况，以及sortOrder计算cost，并选择出cost最低的索引，因此每次一个table只能一个索引。
对于B-树范围索引，计算cost的方法是BaseIndex.getCostRangeIndex()。具体cost计算方法建议查看代码。需要考虑多列索引的情况下，每一列指定相等、范围、半范围条件的情况，另外还要考虑符合order by的情况下，可以减轻cost。


TableFilter -> IndexCursor(支持IN(..)以及IN(SELECT ...)优化) -> PageDataCursor/PageBtreeCursor

*IndexCursor in优化？
*PageDataCursor的成员变量maxKey在每次迭代的时候判断是否超出范围，成员变量idx表示当前的row索引

*rowCount。计算cost的时候，rowCount是必须的。rowCount在PageDataIndex/PageBtreeIndex, RegularTable, Page都有保存。rowCount会保存到page head中，初始化会从Page读取出来，如果无效则会遍历树计算。另外要注意表数据格式有修改的时候，rowCount的值会跟着修改。


--------
//select * from test where id = 5;
1.CommandContainer.query(int maxrows); 
2.Query.query(int limit, ResultTarget target);
  fireBeforeSelectTriggers() 激发触发器

3.Select.queryFlat() //Not groupby/join/distinct
  TableFilter.next() 

  1.IndexCursor.find() //index type

    PageDataIndex.find(Session session, long first, long last, boolean multiVersion) (或者PageBtreeIndex)
      PageDataIndex.getPage()
        PageStore.getPage()
          CacheLRU.get() CacheLRU查找page data。CacheLRU没有使用mysql把缓存队列分为old/young。
                          另外，CacheLRU里缓存有PageDataLeaf,PageBtreeLeaf等B树以及data叶子节点。
          PageDataLeaf.find() 调用PageData.find()，二分查找。如果一个PageDataLeaf放不下，就会在PageDataNode

    二分查找成功后，cursor = PageDataCursor

  2.IndexCurosr.next()
    PageDataCursor.next()


=====  Select.queryFlat ===== 
select * from test where id = 5;

--Path
Select.queryFlat(TableFilter) -> IndexCursor(支持IN(..)以及IN(SELECT ...)优化) -> PageDataCursor/PageBtreeCursor

*该过程中，直接拿RegularTable的scanIndex进行迭代，key的最小值和最大值为Long.MIN_VALUE和Long.MAX_VALUE，然后不断遍历叶子结点遍历数据。要注意的是叶子结点PageBtreeLeaf/PageDataLeaf的遍历过程: 两个兄弟叶子结点之间并没有指针连接起来，遍历完这个叶子结点要通过递归查询父结点获取下一个兄弟结点。具体为PageDataLeaf.getNextPage / PageBtreeLeaf.nextPage


*select索引过程中，首先从索引条件中解析出索引的最小值(>= LONG_MIN)和最大值(<= LONG_MAX)，然后去寻找所属范围最可能包含最小key的PageDataLeaf，寻找成功后PageDataLeaf构造一个PageDataCursor返回。然后TableFilter就开始进行cursor的迭代操作。超出范围则会退出迭代。


Condidtion总体：
返回boolean值或NULL的条件语句
Expression
 - Condition
    - ConditionNot              Not ...
    - ConditionAndOr            An 'and' or 'or' condition as in WHERE ID=1 AND NAME=?   index
    - ConditionInConstantSet    IN(...)中In list全部均为同种类型的常量                   index
    - CompareLike               where name like xxx                                      index
    - Comparison                >=,>,<=,<, !=, is null, is not null                      index
    - ConditionExists           WHERE EXISTS(SELECT ...)
    - ConditionIn               WHERE NAME IN(...)                                       index
    - ConditionInSelect         WHERE [ID IN(SELECT ...) / ID >= [ALL/ANY] (SELECT...)]  index

ConditionNot、ConditionExists不会建立索引。
ConditionAndOr只在And连接的条件建立索引。
ConditionInConstantSet默认情况下都建立索引。
CompareLike（like，regexp）中regexp不建立，like中如果patter首字母为匹配字符，即_或%时，则不建立索引，如果比较列类型不为字符也不建立索引。也就是对pattern为%xyz%, _xyz%不建立索引，对于xyz%，建立>=xyz的索引，以及<xy(z+1)的索引
Comparison，除了!=和is not null不建立索引，其它（>=,>,<=,<,is null等）比较与非自己表的列的表达式值时，都建立索引。
ConditionIn，要求inList的所有值都不能来自父select，具有非相关性，才能建立索引。
ConditionInSelect要求子select中selectList，condition，having子句全都不能来自父select语句，也就是与父select非相关，才能建立索引。

对于多重Condition，如where a.name >= 'aaa' and a.id <= 99 and b.v1 = 39 and b.v2 >= 'aaa'，会组成一颗树，根据括号的优先级最高，AND优先级比OR高，从左到右建立的一颗二叉树。
需要注意的是一个规律是，由于AND比OR优先级高，如果同一层级里出现OR条件，则OR会作为树根，判断的时候会从OR开始。


具体细节：
*操作符>=,>,<=,<比较值的过程中，把形如a > 3的表达式分解为三个对象ExpressionColumn(a)、Comparison(>)、ValueExpression(3)，然后select出值后，通过ExpressionColumn解析出当前值所在列的值，ValueExpression取出指定值，然后Comparison进行比较，如果两种类型不一致，则会每个row都需要进行转型，如a > 3里，a是string类型，则每次都要转换成Int。
*操作符!=, is not null不会使用索引，以[Long.MIN_VALUE, Long.MAX_VALUE]范围从scanIndex搜索，每个row进行比较判断是否添加到结果集
*操作符is null会使用索引，对于PageDataIndex，由于key不可能为null，会以[Long.MIN_VALUE, Long.MIN_VALUE]进行一次搜索。对于PageBtreeIndex，由于允许NULL的key存在，则直接以null为key进行搜索，NULL比任何非NULL的值要小，因此所需搜索值都在前面的叶子结点。
*操作符in(...)，把常量值排序后，逐个利用索引查找。IndexCursor保存了inList，负责迭代inList的值，然后用Index进行查找。
*操作符Not。一般把Not的condition在内层。在Select层判断中，迭代结果会被NOT内层的condition判断，然后判断结果再进行NOT操作。
*操作符between ... and ...。编译为ConditionAndOr对象(可初始化为And或者Or，这里是And)，内部包含两个Compairson对象，left和right。left是>=，right是<=。如between start and end：简单地创建以[start, end]为范围，使用index进行搜索，将搜索结果在Select层再进行ConditionAndOr的判断，这里是And，即left和right必须均为true。
*操作符And，Or。
1.操作符And，left and right会对left, right表达式尝试建立索引条件，Or则不会建立索引条件。
2.注意And和Or的短路判断。
3.And的优先级比Or要高。

*in (select ...)
select id1 from test_btree t where v2 in (select v2 from test2 where id >= 30) no index
select id1 from test_btree t where id1 in (select v2 from test2 where id >= 30) index

子select与父select非相关，要分两种情况（no index和index）：
---如果in表达式的左侧列不能使用索引，则会先逐个查询外层table的行，然后在select的condition过滤中，进行子select查询获取总的结果集（只查询一次，结果集会cache到子Select.lastResult），然后在这个结果集中进行查找，有两个方式 1，对于非all的并且是in/=的相等比较时，使用hash的distinct比较(LocalResult.containsDistinct）使用hash而而不用排序＋binary search可以减少value值的实际比较；2、否则遍历结果集逐个比较判断，要注意考虑是否all，最后返回condtion过滤结果。
---如果in表达式的左侧列可以使用索引，则左侧列对应的TableFilter会创建indexConditions，这样在计算cost的时候，由于子select是evauable，所以可以创建对应索引。执行时进行子select递归查询，获取结果集，缓存到内存中，再逐个对这些值进行父select的索引查询。
（对于非相关性，实现就是和缓存小表进行join一样，但是如果in的子select结果集大，则会消耗大量内存。改良方法：可以考虑转化为子select去重后进行nested loop join。如果转化为join之后，则通过改变join顺序可能会提高效率）

子select与父select相关，则不能建立索引，这时会首先逐个查询父select的行，然后再传给子select进行查询（可以根据这个值进行索引查询），看看是否满足in的值相等条件。如select * from test_btree t where id1 in (select v2 from test2 where id = t.id)，则会先逐个查询test_btree的值，然后传入t.id到子select，子select会利用id的索引进行查询，如果存在row，则查看v2是否等于id1，如果等于则添加到结果集。
以上查询执行效果与join类似：select * from test_btree a join test2 b on (a.id = b.id and a.id1 = b.v2)。但以上的子查询等于限制了join顺序，不能进行优化。

关于join和子查询的比较
http://stackoverflow.com/questions/2577174/join-vs-sub-query
结论是1、子查询在逻辑上更加容易理解；2、子查询不用担心B有重复值带来的影响；3、一般情况join比子查询效率更高。

*多重操作符混合。解析过程见Parser.readCondition()。
*ConditionAndOr.optimize()优化：
0.根据cost大小，交换left和right（优化选取第一个进行索引查询的策略）
1.B=A AND B=0 -> B=A AND B=0 AND A=0  (多表join中有用)
2.B=3 AND B=0 -> B in (3, 0)
3.A IN(1, 2) OR A=3 -> A IN(1, 2, 3)
4.短路判断
*多个in(...)进行And合并。 则选取第一个进行索引查询，然后其它在最终进行condition进行过滤。
*Or不会建立索引！
*范围搜索And连接，则会对范围进行交集。

=====  Select.queryGroup/queryQuick/queryGroupSorted =====
isGroupQuery = true

select count(1) from test;
group by
order by
having ...
where + index

Expression
 - Aggregate    integrated aggregate functions, such as COUNT, MAX, SUM.

有以下的type
COUNT_ALL             COUNT(*)
COUNT                 COUNT(expression)
GROUP_CONCAT          GROUP_CONCAT(...)
SUM                   SUM(expression)
MIN                   MIN(expression)
MAX                   MAX(expression)
AVG                   AVG(expression)
STDDEV_POP            STDDEV_POP(expression)    (总体的标准差, VAR_POP()的平方根)
STDDEV_SAMP           STDDEV_SAMP(expression)   (样本的标准差, VAR_SAMP()的平方根)
VAR_POP               VAR_POP(expression)       (总体的统计方差)
VAR_SAMP              VAR_SAMP(expression)      (样本的统计方差)
BOOL_OR               BOOL_OR(expression)
BOOL_AND              BOOL_AND(expression)
SELECTIVITY           SELECTIVITY(expression)   (Selectivity 100 means values are unique, 10 means every distinct value appears 10 times on average)
HISTOGRAM             HISTOGRAM(expression)     （柱状图）

------
*queryQuick()，一种优化聚集的查找，执行时，直接获取aggreate的值。
如SELECT COUNT(*) FROM TEST 或者 SELECT MAX(ID) FROM TEST可以采用queryQuick。
只能COUNT_ALL，COUNT，MIN，MAX的聚集类型。对于COUNT、COUNT_ALL直接获取表的行数即可。对于MIN、MAX根据情况利用索引获取第一个或最后一个的值。
检查的条件比较严格：
没有group by，having语句，且只查找一个表
expressions：类型为COUNT时，里面的表达式不能为distinct且不能为NULL，最后还需要表能直接获取行数。类型为COUNT_ALL只需要表能直接获取行数。类型为MIN、MAX的要存在以该列为第一索引列的索引，如以索引(a,b)，则MIN(a)为true，MAX(b)为false。
condition：存在有列表达式就为false。

------
select sum(id), avg(v1) from test2 group by v3 having sum(v2) > 10;
*queryGroup()：
首先要索引查找where condition指定的，然后进行group by聚集计算，最后进行having过滤。

聚集过程：
ValueHashMap<HashMap<Expression, Object>> groups，group by分组和对应表达式分组数据的映射。
-->  HashMap<Expression, Object>  currentGroup， 某个group by分组的表达式以及对应的聚集数据的映射。
-->  AggregateData data。具体group by分组的具体select或having表达式的聚集数据。
-->  调用data.add()将row的值进行叠加计算到聚集数据中。
having过滤：
根据分组的key遍历ValueHashMap<HashMap<Expression, Object>> groups，复制出对应的值在row中，然后根据having条件进行过滤，最后添加到结果集中。

*优化的聚集投影（非强制表达式必须出现在group by中）：
ExpressionColumn.updateAggregate()
select的表达式以及having表达式中，如果某一列在同一group by分组中的值均相等，则该列可以不需要出现在group by分组。

*Aggreate.updateAggreate() --> AggregateData.add()
对于COUNT、SUM、MIN、MAX、AVG的处理都很简单，基本在row分到对应分组后进行处理，最后获取结果的时候如有需要继续进行处理。

------
*queryGroupSorted()  group by index
isGroupSortedQuery=true
存在非scan非hash的索引，并且group by的column符合索引前缀的条件（index(a,b,c) good:group by b,a bad:group by a,c)。

总体流程：
在索引查找后经过where condition过滤，然后通过判断当前分组key是否与上一次的相同，如果相同则用上一次key的分组数据，然后进行聚集计算，如果不同则创建新的分组HashMap<Expression, Object>  currentGroup，并且同时会把上一次分组的数据进行having过滤，添加到结果集。
这是由于符合前缀索引条件时，可以确保数据按照分组的顺序进行遍历，可以按顺序计算出聚集结果输出单个分组，不需要遍历完所有数据，减轻内存负担。


=====  distinct  =====
Select.distinct=true

------
*select distinct v1,v2 from test2
distinct只能放在select表达式第一位，此时所有select表达式组成key进行distinct操作，
LocalResult.addRow()进行distinct操作，利用ValueHashMap<Value[]> distinctRows。如果结果集超过MAX_MEMORY_ROWS_DISTINCT，会使用临时表。

-----
*select sum(distinct v1) from test2 group by ...
与group by流程一致，将在聚集计算的时候进行distinct操作，利用ValueHashMap过滤重复的值。注意此时Select.distinct=false

------
*queryDistinct
distinct查询的一个优化，当distinct仅包含一个列col时，存在符合该col的前缀条件的索引，则会利用该索引进行查询，特别的是这里不是范围查找，而是每次指定刚好大于上一次col结果的值来进行查找，这样就不需要在LocalResult进行distinct操作。
另外要注意该col的selectivity < 20，也就是存在较多的冗余值，这样能过滤更多不必要的查找，更加有效。


=====  Order by SortOrder.sort =====
Select.sort=true

------
*SortOrder.sort
查找完所有的结果后，执行LocalResult.done --> SortOrder.sort进行排序。
如果内存允许，并且没有limit和offset，则直接调用Collections.sort(rows, this)，Java内置的List排序算法进行排序（Timsort，对于部分有序的数组会有远小于NLog(N)，并且对于随机乱序的数组同样保持NLog(N)）。
如果存在offset或limit，则使用Utils.sortTopN(arr, offset, limit, this)。首先使用快速排序进行部分排序，具体是使[offset, limit + offset - 1]这范围内的值放到这范围上（该范围内的值不一定有序），然后使用Arrays.sort(array, offset, (int) Math.min((long) offset + limit, array.length), comp)保证[offset, limit + offset - 1]有序（Arrays.sort同样是Timsort，仅对指定范围排序，其它范围顺序不变）。

使用快速排序进行部分排序，可以参考Utils.partialQuickSort(X[] array, int low, int high, Comparator<? super X> comp, int start, int end)，关键是在开始增加判断条件(low > end || high < start || (low > start && high < end))，如果成立则直接return，不需要继续排序。

------
*sortUsingIndex=true
使用索引进行排序。利用索引的顺序遍历数据，数据集就保证有序，可以避免在最后进行的排序操作，对于结果集数据比较大的时候相当有效。
使用条件：
1.符合order by里指定列顺序，非scan和非hash索引，并且索引的每列排序类型必须符合order by的指定（如index(v1, v2), order by v1 asec, v2 desc不符合，order by v1, v2符合），这个索引为排序索引
2.如果之前经过cost选择的索引current是scan（默认索引），或者与排序索引一致，并且不存在IN条件查询（IN条件查询可能导致遍历结果与order by不一致），则sortUsingIndex=true。
3.代码上是替换current索引，如果排序索引列排序类型与current索引不一致，但按照cost计算已经考虑order by因素，暂时没有想到这种情况出现。


=====  join  =====
只利用嵌套循环实现join（join可以通过把小表放内存、排序-合并、散列、等方法实现。）（对于小表join下，嵌套循环效果比较简单有效）

inner join
------
select a.id, b.v1 from test a join test2 b on a.id = b.id
select a.id, b.v1 from test a, test2 b where a.id = b.id;
两条SQL经过parse一致。

*cost计算。列出所有join表的组合A(n, n)(n为join表的数量)(Permutations类实现)作为Plan，分别计算每个Plan的cost，取最小值的plan。每个Plan中，不同的table分别计算cost，cost += cost * item.cost计算plan的总cost。另外要注意当前tableA计算cost之后，evaluatable=true，这样下一个有该tableA关联条件的tableB就可以利用索引计算。
这里要注意一个可能的规律，小表放在最左边能够使cost更小。（这样会对大表使用索引查找，在嵌套循环更加有效）。因此，在计算完每个table的cost的时候，考虑到indexConditions越多则一般表越小，所以会有以下的计算：
item.cost -= item.cost * indexConditions.size() / 100 / level;  （level是join表的顺序，100是一个启发式计算值）
（nested loop实现的join，oracle计算cost = costA + rowA * costB，估计这里为了方便所以是cost = costA + costA * costB）

对于这种cost计算方式，如果join不能使用索引，如以下SQL：
select * from test_btree a join test2 b on (a.v2 = b.v2);
a的scan cost为10320，b的scan cost为58880，由于启发式cost对b减小差值较多，因此会令b作为第一个join表（有点像副作用，实际这里join顺序影响不大），实际上是一个cross join最后加上Select的condition过滤。
但如果有index，则差别会非常大，这个cost计算方式就会生效。

*完成SQL语句编译后，把最左边的join table作为topTableFilter，然后从它开始进行循环。
*先读入TableA一列数据（实际读入整个block），然后b再根据id利用索引搜索，找出所有相同id的列。
foreach tableA as rowA
 foreach tableB as rowB
  if (rowB.id == rowA.id) {
    result.addRow(rowA,rowB);
  }

*H2的inner join/left, right join的on子句都是可选的。如果没有on子句，效果就和cross join一致。


condition push down & filterCondition
------
select a.id, b.v1 from test a join test2 b on a.id = b.id where a.name >= 'aaa' and a.id <= 99 and b.v1 = 39 and b.v2 >= 'aaa'
select a.id, b.v1 from test a join test2 b on a.id = b.id where a.name >= 'aaa' and a.id = 99 or b.v1 = 39 or b.v2 >= 'aaa'  （可以考虑会出现什么判断，注意OR）

原理：
为了提高join的效率，在嵌套循环中，可以把condition push down到join表中，这样就可能减少join的次数，提高效率。另外，对于最后一个join表，则不需要这个优化，因为已经完成了join，最终还是会到condition的过滤，不需要filterCondition的提前过滤。

流程：
1、条件上推（Parser阶段）。Parser.parseJoinTableFilter把非outer join的joinCondition（a.id = b.id）添加到Select.condition中，Parser.parseSelectSimple把where的条件加入到Select.condition中。这样就把所有的condition上推到顶层Select中。
2、索引条件下推（准备阶段）。Select.prepare中，所有的TableFilter会根据Select的condition判断是否适合创建IndexCondition（Index遍历需要）。
3、cost计算（优化阶段）。Select.preparePlan过程中，首先push所有Select的condition到每个TableFilter的fullCondition中，然后Optimizer.optimize()优化过程计算所有A(n,n)的join组合，这个过程会参考indexCondition进行cost的计算，最后选择最小cost的join组合作为执行plan。
4、fullCondition下推（优化阶段）。主要把满足条件的fullCondition下推到filterCondition（在嵌套循环中过滤，Plan.optimizeFullCondition）。大致要求condition的表达式必须是evaluatable，也就是如果涉及别的表的列表达式，则该表达式必须是较前join顺序的表。另外对于AND的condition，可以left和right分别判断是否符合条件，但对于OR的condition，必须是左右同时满足evaluatable（可以仔细想想为什么，因为OR的话，如果仅仅left符合，但不确定是否可以filter，所以必须left和right均一起添加到filterCondition才有意义，但AND则可以left或者right符合，则可以判断是否filter）。

结果：
在上面例子最终选择的join顺序为（B,A）：具体如下
TableFilter b的filterCondition为((B.V2 >= 'aaa') AND (B.V1 = 39))
，同时index为PageBtreeIndex（v1, v2），indexCondition为((B.V2 >= 'aaa') AND (B.V1 = 39))
TableFilter a的filterCondition是NULL，同时index为scanIndex，indexCondition为a.id = b.id。
Select的condition为
((A.ID = B.ID) AND ((B.V2 >= 'aaa') AND ((B.V1 = 39) AND ((A.NAME >= 'aaa') AND (A.ID <= 99)))))
之所有选择B,A，是因为当B作为topTableFilter的时候，A就可以利用scanIndex进行join匹配，这时候由于是EQUAL，所以cost比id <= 99的范围要少得多，因此就选择了B，A。

virtual table join
------
select a.id, b.v1 from test a join (select * from test2 where id = 99) b on (a.id = b.id)  where b.v1 <= 99  
（深入优化：可以考虑把id >= 99 上推到外层的select，然后再下推到test中）

select a.id, b.v1 from test a join (select * from test2 where id <= 99) b on (a.id = b.id)  where a.id <= 99
（indexConditions和filterCondition都包括相同的a.id <= 99，H2的优化不足，没有取出冗余条件）

总体流程和上面的condition push down & filterCondition差不多，关键是内层的Select看成virtual table，table为TableView，视图。

过程：
-外层Select解析为TableFilterA和TableFilterB。TableFilterB（内部的table为TableView，视图。同时包含内层的Select语句），就是把内层Select解析成一个virtual table。（内层Select解析的过程有点麻烦（待深入））
-条件上推。外层Select的condition为 a.id = b.id and b.v1 <= 99
-索引条件下推。TableFilterA的IndexCondition为 a.id = b.id。TableFilterB的IndexCondition为 a.id = b.id和v1 <= 99。
-计算cost。同样是列出所有的排序顺序A(n,n)，然后通过公式cost = costA + costA * costB计算cost。另外还会push顶层的condition到TableFilterA, TableFilterB的fullCondition。
-计算TableFilterB的cost（ViewIndex.getCost）。首先将内层的Select语句再次解析到Select q，然后根据传入的索引masks，往q传入参数指定的列和对应的参数，把a.id = b.id and b.v1 <= 99 转换为 TEST2.ID IS ?1 AND TEST2.V1 <= ?2，添加到q的condition。（Select.addGlobalCondition）。这时q的condition变为id >= 99 and TEST2.ID IS ?1 AND TEST2.V1 <= ?2，然后重新取出q的SQL语句，重新对该SQL语句进行解析编译，根据刚刚的condition进行解析，cost计算等，获取了新的select对象q。对于该例子，还是选取了id is ?1以及id >= 99同时作为IndexCondition。
-经过分析后，执行条件就显而易见：TableFilterA作为外层循环，通过scanIndex得出row，然后，TableFilterB作为内层循环，通过id is ?1 以及 id >= 99的indexConditions获取每次搜索的范围，然后利用索引查找对应的join的row，这里TableFilterB的索引是ViewIndex，负责了把id is ?1的条件转换为每次循环的实际值，也就是A的id。然后还要经过内层Select的condition过滤。
-另外有一个有趣的是，如果把内层的select的condition改为id = 99，此时则会是TableFilterB作为外层的循环，TableFilterA变成内层循环，具体cost计算可以参考下面，主要是因为TableFilterB为外层循环的时候，v1 = 99的EQUAL条件可以令cost大大降低，于是总的cost也大大降低
id >= 99
A  10206.9          29.85
B  30.096           19055.708
   317424           587899

id = 99
A  10206.9        29.85
B   30.096        30.086
     317424       959

select a.sid, b.v1 from (select sum(id) as sid from test where id >= 30 group by name) a join (select * from test2 where id >= 99) b on (a.sid = b.id);
-在计算TableFilterA的cost中，把顶层Select的condition下推的时候，该select子句是group by查询，并且参数指定的列不在group by的列中，会直接把该参数条件转换为having子句。即会变成
SELECT SUM(ID) AS SID FROM PUBLIC.TEST WHERE ID >= 30 GROUP BY NAME HAVING SUM(ID) IS ?1

结构：
Select  (select a.id, b.v1 from test a join (select * from test2 where v1 >= 99) b on (a.id = b.id))
  condition (A.ID = B.ID)
  TableFilter (A)
    indexCondition (null)
    RegularTable (A)
    PageDataIndex (scanIndex)
  TableFilter (B)
    indexCondition (A.ID = B.ID)
    TableView (B)
      ViewIndex
    ViewIndex
      Select (SELECT TEST2.ID,TEST2.V1,TEST2.V2,TEST2.V3 FROM PUBLIC.TEST2 WHERE (V1 >= 99) AND (TEST2.ID IS ?1))
        condition (v1 >= 99 and test2.id is ?1)
        TableFilter (test2)
          indexCondition (ID is ?1)
          RegularTable (test2)
          PageDelegateIndex (scanIndex wrap)

left outer join
------
select a.id, b.v1 from test a left outer join test2 b on (a.id = b.id)  where b.v1 <= 99 and a.name >= 'aa'

由于left outer join不能决定了join的顺序，因此对比之前的join有了一定的限制：
-topFilters只有TableFilter A，并且a.id = b.id也没有上推到外层Select的condition，这是由于上推是为了在计算cost的时候对于不同join顺序，计算对应的cost，但现在只计算一个顺序，因此不需要上推。（Parser.parseJoinTableFilter, isOuter = true）
-另外对于outer join后面的表，只有原来的a.id = b.id，不会从Select的condition中创建indexConditions（索引条件下推），因为下推可能会影响结果。可以假设下推条件到B，如果B过滤了某些行，但是一样可以产生join结果，只不过在对应B的列为NULL，这时就等于过滤失败。具体可以参考下面的SQL：
select p, c from parent left outer join child on p = pc where c is null;
-计算cost的时候，只计算A，B的顺序，并且TableFilterB被计算了两次，可能有BUG。
-fullCondition下推到filterCondition的时候，对于TableFilterB不会执行（并且也没有意义），这和前面索引条件不能下推的理由一样。

*执行Plan大致为：TableFilterA使用scanIndex，filterCondition为a.name >= 'aa'，indexConditions为NULL；TableFilterB使用PRIMARY_KEY_INDEX，indexConditions为a.id = b.id，joinCondition为a.id = b.id，filterCondition为NULL。
*过程：A先遍历出一行，然后B遍历，首先根据主键索引找出对应的行，然后通过joinCondition过滤（a.id = b.id使用了两次，此处的joinCondition应该是冗余），如果B找不到row，则会设置为NULL row。B遍历完毕，返回到顶层的Select，Select的condition过滤后，将投影的列的值从对应的A、B取出。

right ouer join
------
select a.id, b.v1 from test a right outer join test2 b on (a.id = b.id)  where b.v1 <= 99 and a.name >= 'aa'
三个TableFilters：B, SYSTEM_JOIN_78(DUAL table，一行一列), A
SYSTEM_JOIN_78作为一个DUAL table，类似一个proxy，进行nested join的查询。

外层Select的condition为b.v1 <= 99 and a.name >= 'aa'；
B的indexConditions为v1 <= 99，filterCondition也为v1 <= 99，index为PageBtreeIndex（v1，v2），join为SYSTEM_JOIN_78；
SYSTEM_JOIN_78的joinCondition为a.id = b.id，index为RANGE_INDEX (实际不会用到)，nestedJoin为A，joinOuter=joinOuterIndirect=true；
A的index为主键索引，indexConditions为a.id = b.id，另外fullCondition为NULL, joinOuterIndirect=true, joinOuter=false。

SYSTEM_JOIN_78进行类似nested join的查询，当调用next()的时候，会调用nestedJoin.next()进行查询。

natural join
------
select a.id, b.v1 from test a natural join test2 b where b.v1 <= 99 and a.name >= 'aa'
natural join与inner join类似，注意亮点：
1、Select中出现*这个通配符需要去除a和b的相同列b.id，2、自动添加condition a.id = b.id。
其余都与采用a.id = b.id的inner join一致，即同样的condition下推，join顺序优化，索引选择等。

cross join
------
select a.id, b.v1 from test a cross join test2 b where b.v1 <= 99 and a.name >= 'aa'
cross join流程与inner join类似，就是没有了inner join的on condition（a.id = b.id），同样又condition下推，join顺序优化，索引选择等。


nested join
------
select a.id, b.v1, b.v3 from test a join test2 b on a.id = b.id and a.name = b.v2 
left outer join test3 c
join test4 d on (c.id = d.id)
on (a.id = c.id) where a.name >= 'a';

通过移动on子句的位置，可以改变join的顺序，对于inner join结果一样，但outer join会有差别。可以通过配置来控制是否支持netsed join，具体通过在URL中添加配置，如"jdbc:h2:test;;NESTED_JOINS=FALSE"，则会关闭此特性的解析。
关于nested join的实现，主要看TableFilter.next()中的循环（就是nested loop对于每个TableFilter的一次循环，代码写得比较复杂）：
1、如果没有nestedJoin表，则首先当前TableFilter通过索引查找出合适条件一行，否则，调用nestedJoin.next()，即让nestedJoin进行迭代；
2、如果前面当前TableFilter无法查找适合条件一行，则退出当前循环；如果nestedJoin.next()返回false，即同样没有找到合适的行，并且为outer join且之前没有找出符合的一行，则设置当前行为NULL行。
3、filterCondition过滤（join前过滤），如果不符合条件则会退出循环。注意nested Join的filterCondition为NULL，则肯定符合条件。
4、joinCondition过滤（join后过滤），如果不符合条件则会退出循环。
5、join.next()。如果join.next()返回false，即没有找到合适的行，则退出当前循环。


以下针对outer join进行讨论：
nestedJoins=true：
则会解释为
(A join B) left ouer join (C join D)
Parser解析为：
A join B outer join SYSTEM_JOIN_XXX nested join C join D
left outer join当遇到nested join的时候会借助SYSTEM_JOIN_XX进行nested join循环的辅助。

nestedJoins=false:
解释为：
A join B outer join D outer join C
Parser解析为：
A join B join D(outer:true) join C(outer:true)
另外，以上的SQL由于C放在后面，因此d on (c.id = d.id)中的c.id无效，解析会失败。

如果将left outer join改为right outer join，则：
nestedJOins=true，解释为：
(C join D) outer join (A join B)
Parser解析为：
C join D outer join SYSTEM_JOIN_XX nested join A join B
right outer join无论是否有nested join都会借助SYSTEM_JOIN_XX进行nested join循环的辅助。这里与left outer join不同，因为left outer join是在判断nested && joined后可以直接往left outer join的右边添加SYSTEM_JOIN_XX，right outer join需要往中间添加SYSTEM_JOIN_XX，为了方便，因此right outer join的右边不会判断是否存在nested join，直接往中间添加。具体可以参考Parser.readJoin()。

nestedJOins=false，解释为：
C join D outer join A outer join B
Parser解析为：
C join D outer join A outer join B


Join的解析 ＋ condition作用总结
------------
Praser.readJoin
从左到右解析join：
如果cross join, natural join, inner join，则可以任意组合join顺序，也不改变topTableFilter，并且可以condition下推等优化。
如果left outer join，则左边的表以及之后的所有TableFilter的join顺序就会被固定，但不会改变topTableFilter，不可执行condition下推的优化。
如果right outer join，则把topTableFilter转为右边的表，并且整个join顺序都不能再改变，并且会创建SYSTEM_JOIN_xxx表进行join辅助。
--尤其要注意的是outer join对join顺序限制，仔细考虑为什么是这样的规则，具体原因是join顺序改变会对结果造成影响。


outer join不能随意下推condition：
一致：
select * from test5 a join test6 b on (a.id = b.id) where a.name = b.name;
select * from test5 a join test6 b on (a.id = b.id and a.name = b.name);

不一致：
select * from test5 a left outer join test6 b on (a.id = b.id) where a.name = b.name;
select * from test5 a left outer join test6 b on (a.id = b.id and a.name = b.name);
因此在left outer join中，不能把where的条件子句下推到B.joinCondition/B.indexCondition，会影响结果。


join, outer join的condition总结：
Select.condition是查询结果加入结果集前的过滤条件，最后的过滤；indexCondition一般是索引查找过程的条件；filterCondition一般是where的条件子句，主要用于join之前的过滤；joinCondition一般是on的条件子句，主要用于join之后的过滤。由于outer join的限制，包括优化存在，这三个condition有可能为NULL。

select a.id, b.v1, b.v2 from test a right outer join test2 b on a.id = b.id and a.name = b.v2 join test3 c on (a.id = c.id) where b.v3 >= 'a'

0、初次编译。根据join顺序，给join表B的join和joinCondition赋值。即A.join = B, B.joinCondition = (a.id = b.id and a.name = b.v2)。然后会让join表B对on表达式的条件尝试创建indexConditions（TableFilter.mapAndAddFilter）。另外注意：
inner join： A.isJoinOuter() == A.isJoinOuterIndirect() == B.isJoinOuter() == B.isJoinOuterIndirect() == false；
left outer join： A.isJoinOuter() == A.isJoinOuterIndirect() == false； B.isJoinOuter() == B.isJoinOuterIndirect() == true；
right ouer join：
1、条件上推（Parser阶段）。对于inner join、natural join，Parser.parseJoinTableFilter把join的joinCondition（a.id = b.id）添加到Select.condition中，Parser.parseSelectSimple把where的条件加入到Select.condition中。这样就把所有的condition上推到顶层Select中。另外，在这阶段，同时把所有非outer join的TableFilter都成为topTableFilters，表明可以更改join顺序。（outer join不参与，condition只包含where部分）
2、索引条件下推（准备阶段）。Select.prepare中，对于!isJoinOuter() && !isJoinOuterIndirect()的TableFilter会根据Select的condition判断是否适合创建IndexCondition（Index遍历需要）。
3、cost计算（优化阶段）。Select.preparePlan过程中，首先push所有Select的condition到每个TableFilter的fullCondition中，然后Optimizer.optimize()优化过程计算所有A(n,n)的join组合，这个过程会参考indexCondition进行cost的计算，最后选择最小cost的join组合作为执行plan。
4、fullCondition下推（优化阶段）。主要把满足条件的fullCondition下推到filterCondition（在嵌套循环中过滤，Plan.optimizeFullCondition）。大致要求condition的表达式必须是evaluatable，也就是如果涉及别的表的列表达式，则该表达式必须是较前join顺序的表。另外对于AND的condition，可以left和right分别判断是否符合条件，但对于OR的condition，必须是左右同时满足evaluatable（可以仔细想想为什么，因为OR的话，如果仅仅left符合，但不确定是否可以filter，所以必须left和right均一起添加到filterCondition才有意义，但AND则可以left或者right符合，则可以判断是否filter）。（isJoinOuter() == true不参与）

inner join可以对A、B进行filterConditions、indexConditions优化，left outer join只会对A进行filterConditions、indexConditions优化。

BUG:
1、Select.condition不会对已经下推的condition进行删除，所以会有不必要的冗余过滤。
2、Plan.calculateCost()根据每个join顺序的plan中，循环是根据join顺序中每个表计算cost。但如果是outer join则join顺序已经固定，因此循环里应该是join顺序固定好的filters，而不是allFilters，不必要遍历其它join顺序。目前在循环的时候，allFilters为filters中的表才是有效的PlanItem，outer join固定了join顺序后，会递归计算join表的cost，而不再需要在循环里再次计算cost。
即allFilters是包括A，B，C，但事实上只要计算B的时候，会递归计算SYSTEM_JOIN_XX，A，C，具体如下：

B -join-> SYSTEM_JOIN_XX -nestedJoin-> A
                         -join->       C
A
C

3、Plan.removeUnusableIndexConditions()同样也是allFilters应该转换为filters？


multi-table mixed join
------
select a.id, b.v1, c.v2 from test a right outer join test2 b on (a.id = b.id) right outer join test_btree c on (c.id = a.id) where b.v1 >= 99 and a.name >= 'a' and c.id1 >= 'aa'

TableFilters: C --join--> SYSTEM_JOIN_130 --nestedJoin--> B --join--> SYSTEM_JOIN_83 -->nestedJoin--> A
其中，除了C以外，joinOuterIndirect均为true。


select a.id, b.v1, c.v2 from test a join test2 b on (a.id = b.id) join test_btree c on (c.id = a.id) where b.v1 >= 99 and a.name >= 'a' and c.id1 >= 'aa'
A join B join C，和之前流程一致，计算所有的join顺序的cost，然后选出最小的join顺序。注意上面特殊例子中，两个join条件，a.id = b.id和c.id = a.id，优化器会添加b.id = c.id到condition，能产生更有效的执行plan。
cross join、natural join、inner join都不会因为join顺序影响，可以通过计算不同join顺序的cost得出最优执行plan。


union/union all/except/intersect
------
select a.id, b.v1 from test a cross join test2 b where b.v1 <= 99 and a.name >= 'aa'
union/union all/except/intersect
select a.id, b.v1 from test a left outer join test2 b on (a.id = b.id)  where b.v1 <= 99 and a.name >= 'aa'

SelectUnion，unionType可以为UNION（并集去重）, UNION_ALL（并集）, EXCEPT/MINUS（left中不包括right）, INTERSECT（交集）
有left和right两个select对象，根据unionType分别对left和right进行query，还有结果集LocalResult的处理。
查询前准备：
对于UNION和EXCEPT，要求left和right采用distinct查询，以及LocalResult设置distinct处理，INTERSECT则需要left和right采用distinct查询，UNION_ALL忽略。
查询后处理：
UNION_ALL添加结果集即可，UNION通过addRows添加left和right结果集同时进行distinct处理，EXCEPT先添加left结果集同时进行distinct处理，然后去掉right的结果集中相同的部分。INTERSECT需要创建一个临时结果集，先把left结果集添加到temp同时进行distinct处理，然后查看right结果集中，如果包含在temp中则添加到返回的结果集里。


***
Select总结：Select的实现由于仅支持nested loop，扩展性极差，是属于面向过程的实现；对于condition的优化不够好，loop过程中有一些重复的condition。可以参考PostgreSQL的执行流程，让一些诸如scan、sort、join的操作对象化，组成类似树的结构。另外对于condition优化，应该参考Hive的树遍历机制，整理condition。
尽量不要用right outer join，不要用in子查询（join+distinct替代），

//insert
======================================
=============== insert ===============
======================================
insert into test4 values(14, 14);

流程：
1、Parser解析
2、Insert.prepare()进行简单的优化。对values表达式每个进行简单优化，或者调用select.prepare()优化select的表达式
3、Insert.update()执行命令。


insert into test4 values(13, 13);
-Insert.insertRows()
..将values列表的值按照插入对应的Column定义的类型进行转换，然后对每一行插入数据进行操作：按照默认值更新NULL值，检查插入值限制，精度转换，Sequence值更新操作。
..table.lock锁表
..RegularTable.addRow。循环该table的所有index添加row。具体调用index.add()。另外这里有个trick，如果更改次数超过一定，则会取一定数量的列作为sample，然后创建SQL查询每列的selectivity，然后更新每列的selectivity（RegularTable.analyzeIfRequired()）。
..Session.log()。往session的undoLog添加undo log（与PageLog不同）。主要用于事务roll back。
-Session.commit()
往PageLog写入commit日志，包括当前session的id，表示当前session提交事务。
接着清空undoLog。
unlock所有在Session保存的锁表locks中的锁。


*index.add()实现 (PageDataIndex、PageBtreeIndex)：
PageDataIndex ：
把row插入rootPage，然后计算出split point，如有需要则split该rootPage，rootPage有可能是Leaf或Node。注意split rootPage的时候，为了不改变rootPageId带来的负担，更改原来rootPage的pageID，然后再原来的rootPageID上创建新的PageDataNode。split完成后，然后需要重新插入查找插入位置，再进行插入操作。
然后更新rowCount，然后调用PageStore.logAddOrRemoveRow()，让当前session记录当前logSectionId，logPos作为第一个没提交的事务记录。然后往PageLog写入type为ADD的日志并输出到PageOutputStream。

PageBtreeIndex：
add方法基本一致，但不需要后面的logAddOrRemoveRow（PageDataIndex必定已调用）

插入row到PageDataLeaf、PageDataNode、PageBtreeLeaf、PageBtreeNode：
主要有两个方法addRowTry()、split()。4个页类型都有自己的实现，addRowTry()主要是添加row到该页，并且返回split point。split()则是split page，创建新的兄弟叶子结点。

----
-PageDataLeaf
addRowTry()
修改之前，要写入undo日志。undo日志是以page为单位，格式为[type(UNDO), pageId, pageData]，pageData会经过LZF压缩。（PageStore.logUndo()）注意这里并没有flush操作，undo日志仍然可能在内存中；接着然后判断添加row是否会溢出页面大小（添加的row是从底部向上的，因此只需要判断最后的offset - row长度 < start + keyoffset）：
..没有溢出
如果之前没有数据，或者插入后不会溢出。首先通过二分查找找出insert point，然后往offsets数组插入新的offset，注意offsets中插入点后面的值要偏移。接着往keys，rows数组插入row的key以及row。然后调用PageStore.update()更新该page，主要是在对应的PageFreeList设置used的标志，然后更新一下CacheLRU的链表。接着要更新page的数据data，把数据从insert point开始前移rowLength（逆序增加），然后在insert point写入row。最后返回-1作为split point，表示不需要后续的split操作。
..插入前有数据，并且插入后溢出：
需要增加新的Leaf结点作为兄弟，按照insert point的大小，有3种情况：
1.entryCount/3
如果insert point位于[0, entryCount/3)，则split point为entryCount/3；
如果位于[entryCount/3, 2*entryCount/3)，split point为insert point；
如果位于[2*entryCount/3, entryCount - 1]，split point为2*entryCount/3。
由于Leaf页保存row的数据，比单纯保存keys要大，因此这个方式可以保证split point比较接近insert point的同时，也保证split之后page至少包括entryCount/3，确保一个更好的页面利用率。
2.entryCount/2
如果insert point<5的时候（<= 5 ?），entryCount/3的算法并不能保证更好的分配，因此split point只为entryCount/2。
3.insert point
如果sortedInsertMode为true，则insert point为split point。按照不同情形直接返回对应的split point，不进行插入row操作。
..插入前没有数据，插入row后溢出，即rowLength大于页大小，需要写overflow page。具体就是，首先把row的部分复制到page剩下的空间，然后根据剩下大小分配PageDataOverflow页，然后继续把剩下的复制进去，如果仍然不足，继续分配PageDataOverflow页，继续填充该页，直到把rowLength充满位置，注意PageDataOverflow之间都有parentPageId、nextPage代表前后页的pageID，另外当前PageDataLeaf页也有保留第一个PageDataOverflow的pageID。要注意的是，为了方便后面的读操作，有SoftReference直接对该row的引用，避免要遍历PageDataOverflow读取数据。
split()。
分配并创建新的PageDataLeaf，然后把范围[split point, entryCount - 1)的数据添加到新的叶子结点，然后删除这段范围的记录。删除前写入undo日志，然后偏移页数据data覆盖旧值，以及修改offsets、keys、rows数组。返回创建的新页。

-PageDataNode
addRowTry()
写入undo日志。然后是一个循环，需要不断循环尝试查找插入点，如果遇到split则先split后再查找，直到不需要进行split可直接插入row为止。具体为：
二分查找插入点，选择插入点的子page，调用page.addRowTry()，进行递归查找，直到叶子结点调用addRowTry添加row。如果子page需要进行split操作，表示当前页也需要进行插入row。需要判断是否溢出，这里的逻辑比Leaf简单，具体为
如果溢出，则直接返回entryCount/2作为split point。（由于Node结点只包括key值，不需要考虑页面利用率）
如果没有溢出，首先取出子page的split point - 1的位置的key作为pivot，然后子page.split()出新的兄弟页page2，然后PageStore.update()更新该page,page2的相关缓存信息，接着调用addChild()把page2插入，pivot作为key作为新的子page。然后再PageStore.update()更新当前Node页的相关缓存信息。split完成后，返回循环开始，再重新查找插入点。
成功插入row后更新行数＋1。
split()
分配并创建新的PageDataNode。把[split point, entryCount - 1)的数据添加到新的PageDataNode，并且从该页删除。删除前同样写入undo日志，然后修改pages、childpageIds数组。
要注意对于PageDataNode，keys[0]是childPageIds[0]中最大的rowKey，并且childPageIds大小为entryCount+1，最后一个childPageIds为最右边的子页。因此childPageIds是从split point + 1开始移动到新的子页。最后并且要注意把新的PageDataNode的子页重新设置parent为自己。

-PageBtreeLeaf
addRowTry()
基本和PageDataLeaf一致，在溢出的时候，会令onlyPosition为true，只保存position。
split()
基本和PageDataLeaf一致。
-PageBtreeNode
基本和PageDataNode一致。

总结：
PageDataIndex插入row，具体为：
查找插入点      -->     是否进行split操作 -不需要split-> 插入row。
           <-需要split-

查找插入是从根到叶，split操作是从叶到根的遍历。

首先从rootPage开始利用二分搜索查找插入点，一直遍历到底层的PageDataLeaf。如果PageDataLeaf溢出，则从split point创建兄弟结点，然后父PageDataNode则会尝试增加它的兄弟。这样相当于向父结点插入新的值。如果父结点已满，则递归向其父结点PageDataNode请求插入，如果一直递归到PageDataIndex，则需要新增PageDataNode作为rootPage根索引页，层数增加1。然后重新查找插入点，直到不需要进行split成功插入为止。

存在问题：
1.插入row非常大的时候（超过pageSize），按照entryCount/3的算法有可能不断split page，直到split出空页，然后再插入该空页以及分配overflow页，这样会导致大量的低利用率的page产生。（使用CLOB类型）CLOB根据大小，如果数据不大，则保存内存并直接把数据写入用户表；如果数据太大，则写入专门的LOB表，通常是把数据压缩后插入，同样需要overflow页保存数据，然后获取LOB表中对应的id，把这个id插入用户表。
2.需要先split，然后再insert，考虑如何同时完成split以及insert操作。


*h2的insert into...select...扩展语法
insert into xxx [direct/sorted] select ...
默认Select的结果保存到结果集中，默认在内存中，如果结果集太大，可能写入临时文件，或者建立临时表（需要随机访问结果集）。然后遍历结果集，作为insert的输入，逐个row插入。

When using DIRECT, then the results from the query are directly applied in the target table without any intermediate step.
-Insert.insertFromSelect=true
把select的结果row直接作为insert的输入，直接插入。

When using SORTED, b-tree pages are split at the insertion point. This can improve performance and reduce disk usage.
-Insert.sortedInsertMode=true
PageDataLeaf插入row溢出的时候，则以insert point作为split point。


Insert总结：
1、锁。
有4个lock mode。默认为LOCK_MODE_READ_COMMITTED
LOCK_MODE_OFF(0)，            READ_UNCOMMITTED，不上锁
LOCK_MODE_TABLE(1)，          SERIALIZABLE，    表锁
LOCK_MODE_TABLE_GC(2)，       SERIALIZABLE+GC， 表锁+GC，等待锁的时候会进行GC
LOCK_MODE_READ_COMMITTED(3)， READ_COMMITTED，  表锁，read lock在命令执行完后马上释放

insert前调用RegularTable.lock()，每个RegularTable都包含lockShared（HashSet<Session>），lockExclusive（Session）对象表示获取共享锁，互斥锁的Session对象。同时Session通过locks记录获取锁的RegularTable。上锁时，按照共享和互斥锁锁兼容性判断，另外注意的是，在LOCK_MODE_READ_COMMITTED下，如果是单线程则不用获取share lock。如果无法获得锁，则进行sleep，同时检测超时、检测死锁，GC等操作。

死锁检测是一个DFS的算法，每次只允许一个session进行检测，具体为，将当前Session，A等待的RegularTable的lockShared，lockExclusive（即获得此表锁的Session）进行遍历，获取这些Session正在等待的表锁，然后递归遍历这些表锁的Session，如果遍历过程中，发现A，则表示死锁。另外注意为了避免堆栈溢出的死循环，要保存每次已经访问过的session，避免重复访问。

2、b-tree page的修改。

3、undo日志。（用于recover）
<<数据库系统实现>>提到undo日志实现如下：
..添加undo日志为修改前数据
..修改记录的内存数据
..刷新undo日志到硬盘
..刷新记录的内存数据到硬盘
..添加commit日志(commit开始)
..刷新undo日志到硬盘

问题：每次commit就执行flush会造成大量的IO，并且由于硬盘的转速限制，写入量过大则会限制写入速度。另外，市面上的硬盘都会有自己的buffer，flush并不会真正写入到介质上，断电后一样会丢失（除非是不间断电源UPS）。

H2的默认实现采用了commit事务延迟写（大部分数据库都支持的特性），具体如下：
添加undo日志PageStore.logUndo()，修改记录的内存数据PageStore.update()，添加commit日志PageStore.commit()。
...记录刷新：
每次PageStore.commit()的时候，都会检查undo日志大小，超过一定大小（默认阀值DEFAULT_MAX_LOG_SIZE，16MB）则调用PageStore.checkpoint()，删除多余日志，同时会调用PageStore.writeBack()，把记录在内存中的修改刷新到硬盘上。
...undo日志刷新：
WriteThread定时刷新undo日志，默认500ms刷新一次。另外可以设置WRITE_DELAY（commit和flush之间最大延迟，实际上是WriteThread的延迟间隔）使每次commit执行flush。

总结：commit延迟写机制可以减轻IO，提高性能，但提高了丢失数据的风险。

4、Session的UndoLog（用于rollback）
Session.log()
RegularTable插入row后，往Session添加undo日志，记录的是插入的row（PageLog是插入前添加undo日志，记录的是修改前的page），如果undo日志条数过多，则会写入临时文件。
commit，直接把之前插入的undo日志删除。
rollback，从最后开始，倒序遍历undo日志（如果日志保存在临时文件，则批量导入部分undo日志到内存），然后根据日志记录的操作执行反操作（如Inser则delete，delete则insert），然后删除多余的undo日志。由于修改了记录，因此最后还需要执行PageLog.commit添加PageLog的undo日志。


字节流写入
------
写入byte数组流（目前只有PageLog，undo日志使用），要利用PageOutputStream写入，类型包括TYPE_STREAM_TRUNK和TYPE_STREAM_DATA

*Page页面结构
TYPE_STREAM_TRUNK   （包含TYPE_STREAM_DATA的id，可以包含(pageSize - DATA_START) / 4个TYPE_STREAM_DATA，以及下一个TYPE_STREAM_TRUNK的id）
TYPE_STREAM_DATA    （包含数据流的数据，最高可容纳pageSize - DATA_START个字节）
TYPE_STREAM_DATA
TYPE_STREAM_DATA
......
TYPE_STREAM_TRUNK
TYPE_STREAM_DATA
TYPE_STREAM_DATA

*PageOutputStream
  PageStreamData data;      内存byte数组Data的封装。
  IntArray reservedPages;   预留页的id数组
  PageStreamTrunk trunk;    负责保留管理多个pageIDs的数据

*write()方法负责把数据写入到文件。
写入前进行预留操作，具体是调用reserve()，根据写入数据大小预留一定的page页面（预留策略见下）。接着开始往data page写数据，data page会分配好一个页面大小的buffer，然后往buffer写数据（页面头已经写入）。如果数据太大超出data page的buffer，则把当前data page写入磁盘，然后从PageStreamTrunk中分配新的data page（一般已经预留足够），继续进行写入操作。如果trunk page可以保存的data page也写完，则会从之前预留的页面里拿出一页作为新的trunk page，再开始分配data page。这里注意到，由于每次写之前都进行好预留操作，因此不用担心预留页面不足，需要向PageStore重新分配影响写性能。

*reserve()预留操作。以trunk page能够保存的页面为单位进行分配。
首先计算trunk Page可以保存多少页面（页面字节大小为2048 - 页面头，则能分配507个），然后计算这些页面总共可以保存多少字节（2048-页面头），如果总共保存字节大于预留字节（这里为1字节），则请求PageStore分配这些页面＋1个trunk page（作为下一个trunk page，总共508页）；初始化trunk page对象PageStremTrunk以及data page对象PageStreamData。初始化trunk page的页面头，并且写入磁盘。


PageLog机制
------
PageStore成员变量。
PageLog属于undo log机制，需要不断地写入日志数据，利用PageOutputStream完成底层写入操作。另外如下类型页面都需要添加undo log：
TYPE_DATA_LEAF = 1;      //A data leaf page (without overflow: + FLAG_LAST)
TYPE_DATA_NODE = 2;      //A data node page (never has overflow pages).
TYPE_DATA_OVERFLOW = 3;  //A data overflow page (the last page: + FLAG_LAST).
TYPE_BTREE_LEAF = 4;     //A b-tree leaf page (without overflow: + FLAG_LAST).
TYPE_BTREE_NODE = 5;     //A b-tree node page (never has overflow pages).
TYPE_FREE_LIST = 6;      //A page containing a list of free pages (the last page: + FLAG_LAST).


*初始化
PageLog的初始化过程在Database的初始化中。PageLog的初始化步骤包括读初始化openForReading和写初始化openForWriting，读初始化只是记录第一个trunk page和data page，写初始化需要涉及trunk page和data page的分配。

写初始化PageLog.openForWriting：
-PageStore分配一个页面作为logFirstTrunkPage，也就是PageLog的第一个trunk page；
-初始化输出流PageOutputStream。new PageOutputStream(...)
-输出流预留1字节。产生data page以及下一个trunk page的分配。
-PageStore.setLogFirstPage。PageStore把第一个trunk page，logFirstTrunkPage以及第一个data page，logFirstDataPage记录记录在页面头中，然后写入磁盘
-初始化writeBuffer。初始化PageLog自身的writeBuffer。

*添加undo log
对于每个添加undo log的页面，在checkpoint之间只写入一次。
-PageStore.logUndo()。入口函数在PageStore.logUndo()。利用bit数组判断对应的页面是否已经刷新到硬盘上，如果没有刷新，则把PageStore转换为写模式（初始化的时候为读模式，PageStore.openForWriting()，一般情况下，初始化转换为写模式，此后不需要转化。）

PageStore.openForWriting()转换写模式。
-首先PageLog.free()释放PageLog分配的页面。然后重新分配新的页面作为日志的第一个trunk page，logFirstTrunkPage。
-调用PageLog.openForWriting重新初始化PageLog。
-调用checkpoint()。具体见下

*CheckPoint
入口在PageStore.checkpoint()：首先database.checkPowerOff()，然后把PageStore保存的索引逐个写入rowCount大小（刚初始化的时候，只有PAGE_INDEX表的索引）；
..调用PageLog.checkpoint()，首先在PageOutputStream写入1字节大小的check point标记，然后把已写入undo页面BitField标记清空（表明所有页面可以再次开始写入undo日志），logSectionId加一（把undo日志按照每个check point进行分割，两个check point之间的位置以logSectionId标记），flush掉PageOutputStream（把当前的data page写入硬盘）。重新预留并分配新的data page。把新的logSectionId和新的data page的id保存到logSectionPageMap中。
..writeBack()回写。把PageStore的内存cache中已经修改过的页面写回硬盘。
..清理多余的undo日志。首先获取连接到数据库的所有session中第一个没有被提交的事务的sectionID（对应undo日志上的logSectionId），然后PageLog.removeUntil()进行删除操作：具体是首先从logSectionPageMap获取对应的sectionID对应的data page, firstDataPageToKeep，然后从firstTrunkPage的trunk page开始一直删除到包含该firstDataPageToKeep的trunk page为止，具体是往undo日志写入要释放的pages的id，然后从PageStore的缓存中去掉这些页面，同时添加到PageStore的freeList。最后返回剩下的第一个trunk page作为firstTrunkPage。PageStore重新设置firstTrunkPage, firstDataPageToKeep为当前的trunk page和data page。清空logSectionPageMap中多余的logSectionID。（undo日志、freeList page都可能被修改）
before: trunk1, data1, data2... trunk2, data21, data22, ... trunk3, data31, data32, data_firstDataPageToKeep
after:  trunk3, data31, data32, data_firstDataPageToKeep
..再次writeBack()。把freeList在之前的修改刷新到硬盘中。
..再次PageLog.checkpoint()。确保undo日志写入硬盘。
..清空硬盘空闲页数据。从PAGE_ID_FREE_LIST_ROOT（值为3）开始到PageStore的所有页，逐个通过FreeList判断查看是否在中使用，如果已经使用freed标记置为false；如果没有使用，则往该页写入0，freed置为true。


//delete
======================================
=============== delete ===============
======================================




//update
======================================
=============== update ===============
======================================


//recover
======================================
============== recover ===============
======================================
//add, remove, undo, COMMIT, PREPARE_COMMIT, ROLLBACK...

compact?


TODO:

Select
//order by --  TimSort!!  http://svn.python.org/projects/python/trunk/Objects/listsort.txt

FOR UPDATE



//TCP server
// memtable

//FOREIGN KEY

//MVStore engine

//MVCC ?  database.isMultiVersion()
//MULTI_THREADED















