== TCP server ==
1. 每个客户端连接产生TcpServerThread线程
2. 每个数据库产生WriterThread（负责定时flush）以及FileLock对象（Lock method）
3. 每个TcpServerThread线程有一个用户Session
4、每个连接（Session）一次启动一个事务中，每个事务可以由多个QUERY、UPDATE的statement组成，执行statement都会发送到Server端。默认情况下，Server端只允许一个session给同一个database执行statement，所以每次执行statement都会对database进行synchronized（可以设置MULTI_THREADED属性，这样就允许多个session同时执行statement，所以是对session进行synchronized，但不确保该特性稳定）。为了确保不同连接之间的事务保持ACID，H2使用table lock机制。
5、每个连接一次只能打开一个数据库


Database相关：
*每个DataBase对象有一个PageStore对象表示Database文件的页集合。
*创建PageStore的时候，会从文件的Page 4读取meta table的root page数据(其中包括所有表的索引的indexId和对应的rootPageId)
*然后创建Public.SYS. Public.SYS保存创建其它元数据表的SQL语句
*schemas保存两个Schema对象，PUBLIC和INFORMATION_SCHEMA。PUBLIC是用户表的Schema，其中有表PUBLIC.SYS专门保存所有表的CREATE SQL语句。INFORMATION_SCHEMA是LOB存储，SESSION，USER，RIGHTS等的Schema。Schema对象中，tablesAndViews负责保存tableName和Table对象的映射，执行Select,insert,delete等operations的时候就从映射获取Table对象。


DataBase
|
|--schemas
|--mainSchema(PUBLIC)
|--infoSchema(INFORMATION_SCHEMA)
|--RegularTable meta(Public.SYS)
|--PageStore
   |
   |--CacheLRU
   |--FileStore

Database初始化：
Database.open()
1.先完成数据库文件的初始化
2.然后是PageStore/MVStore存储引擎的初始化（Database.getPageStore()，包含MVStore初始化，名字不好。）
3.Background flush thread的初始化
4.Schema的初始化。Schema包括PUBLIC和INFORMATION_SCHEMA。
  1)首先新建是PUBLIC和INFORMATION_SCHEMA的Schema对象，
  2)然后创建PUBLIC.SYS表，默认的objectID为0，让存储引擎Store映射对应的表数据。
  PageStore和MVStore存储引擎都有各自的meta数据保存机制。
  PageStore在rootPageID为4的位置存放meta数据（PAGE_INDEX表，负责记录表的所有primary和二级索引，包括对应的id和rootPageID，以及索引列等），在Database的初始化前的recover阶段完成ObjectID和rootPageID的映射初始化，包括0映射对应的rootPageID。
  MVStore在readFileHeader()读取lastChunk.metaRootPos作为meta表的rootPos。table.0到对应的map结构获取PUBLIC.SYS数据。

  3)Public.SYS表初始化的时候，通过保存的SQL语句，创建对应的TableEngine，由它创建对应的Table对象，如果没有TableEngine则默认创建RegularTable。保存创建的Table对象到对应的Schma对象中。
  4)INFORMATION_SCHEMA的Schema采用延迟初始化，当第一次读取该Schema对象才开始创建表，创建的都是MetaTable，保存的都是和Database相关的一些meta数据，包括SESSION，USER，RIGHTS等。



PageStore相关：
*PageStore是整个Database的存储层抽象；包含FileStore对象，封装随机访问文件的功能，包含CacheLRU对象，利用LRU算法缓存Page数据
*PageStore同时负责通过PageId读取底层文件中不同类型的Page（如PageDataLeaf,PageDataNode, PageBtreeLeaf, PageBtreeNode等）。
*PageStore也负责本Database的undo/redo日志的操控。
*FileStore对象可以根据实际情况修改底层访问，如FileDisk、FileMem等

*PageStore读取一个指定pageId的Page时候，根据pageId << pageSizeShift计算Page的偏移，然后读取pageSize大小（默认2048）到byte数组中。即文件按照固定pageSize大小分每个Page。

-初始化的时候，从Page0读取固定文件头，初始化pageSize、freeListPagesPerList、fileLength、pageCount；接着需要读变量文件头readVariableHeader，首先校验Page1的checksum，如果校验失败，则尝试读Page2，如果都失败则文件损坏。从可变文件头读取，logKey、logFirstTrunkPage、logFirstDataPage等undo/redo日志相关的值。然后初始化PageLog。Page0，Page1，Page2都不会被cache。

-PageFreeList。
使用1 bit表示页是否在使用。pageSize为2048的时候，一个PageFreeList就可以表示2045 * 8 = 16360页，总共可以表示约32MB的数据，当pageID超过16360 + 3的时候，则会重新分配PageFreeList，负责表示后面的16360页是否使用。内部用used的BitField代表已经使用的页，注意从Page4开始计算used的值。
除了undo/redo日志是数据流，读和写使用顺序IO提升性能，
PageStore包括一个PageFreeList数组。
PageStore分配页面需要依靠PageFreeList实现，维护的PageFreeList数组分别管理大量的页面，分配页面的时候，从头遍历PageFreeList数组，找到可以进行分配PageFreeList，进行分配。

-compact
关闭数据库的时候会进行compact操作，进行碎片整理，清理空页。TODO。


Page类型：
TYPE_EMPTY = 0;          //An empty page.
TYPE_DATA_LEAF = 1;      //A data leaf page (without overflow: + FLAG_LAST)
TYPE_DATA_NODE = 2;      //A data node page (never has overflow pages).
TYPE_DATA_OVERFLOW = 3;  //A data overflow page (the last page: + FLAG_LAST).
TYPE_BTREE_LEAF = 4;     //A b-tree leaf page (without overflow: + FLAG_LAST).
TYPE_BTREE_NODE = 5;     //A b-tree node page (never has overflow pages).
TYPE_FREE_LIST = 6;      //A page containing a list of free pages (the last page: + FLAG_LAST).
TYPE_STREAM_TRUNK = 7;   //A stream trunk page.   PageLog日志使用
TYPE_STREAM_DATA = 8;    //A stream data page.    PageLog日志使用


文件中Page分布：
Page 0:
固定文件头。
HEADER、pageSize、writeVersion、readVersion

Page1:
变量文件头。
checksum、writeCountBase、logKey、logFirstTrunkPage、logFirstDataPage

Page2:
Page1的备份，当checksum无效的时候会被读取。

Page3:
PAGE_ID_FREE_LIST_ROOT
freeList的root。

Page4:
元数据表metaTable（PAGE_INDEX表）的root page。
负责记录所有表的元数据。


Table相关：
PageStore对应RegularTable，MVStore对应MVTable。

RegularTable相关：
RegularTable属于默认PageStore对应的Table对象。（MVStore对应MVTable）
*RegularTable对象表示数据库中的表。
*RegularTable初始化的时候，如果是持久化则创建PageDataIndex作为mainIndex和scanIndex，否则创建ScanIndex对象作为scanIndex，mainIndex为null。
*RegularTable的primary key是单一列，并且类型是long,int,short,byte的时候，会创建封装mainIndex的PageDelegateIndex作为primary key的索引，否则会创建PageBtreeIndex作为primary key的索引。




(以下开始索引的讨论，暂时忽略用于地理坐标的spatial类型的index)
====    PageIndex   ====  
*PageIndex是索引类（PageBtreeIndex, PageDataIndex以及PageDelegateIndex）的基类
*成员变量rootPageId指示对应的PageDataNode/PageDataLeaf或PageBtreeNode/PageBtreeLeaf根索引数据页；
*PageBtreeIndex, PageDataIndex子类都有PageStore的引用方便从rootPageId获取索引数据页


====  Page索引页数据  ====
Page
|
--PageData
| |
| --PageDataNode
| --PageDataLeaf
|
--PageBtree
  |
  --PageBtreeNode
  --PageBtreeLeaf


PageData（PageDataNode/PageDataLeaf父类）
--PageDataIndex index
--int parentPageId
--Data data         data page
--int entryCount    number of entries
--long[] keys       row keys

PageDataNode
--int[] childPageIds
layout:
entries (child page id: int, key: varLong)

PageDataLeaf
--int[] offsets     row offsets to read data
--Row[] rows        the rows
layout:
list of key / offset pairs (key: varLong, offset: shortInt)
data

PageBtree（PageBtreeNode/PageBtreeLeaf父类）
--PageBtreeIndex index
--int parentPageId
--Data data         data page
--int[] offsets     read data to get child page key
--int entryCount    number of entries
--SearchRow[] rows  index data
--onlyPosition      data是否只保存row的key（scanIndex的key），详细见下面

PageBtreeNode
--int[] childPageIds
layout:
entries (child page id: int, offset: short)   offsets

PageBtreeLeaf
layout:
list of offsets: short
data (key: varLong, value,...)


*XNode类是内部结点，XLeaf类作为叶子结点
*内部成员rootPageId所指示索引页，如果数据量少，则指定一个XLeaf，数据量大，rootPageId则指定XNode。
*结构都是由多层XNode内部结点到最后XLeaf叶子结点的树。
*PageDataNode保存keys和对应的childPageIds；PageDataLeaf保存keys和对应的offsets，以及data保存row的全部列值。PageDataNode中keys[0]是childPageIds[0]中最大的rowKey，并且keys大小为entryCount，childPageIds大小为entryCount+1，最后一个childPageIds为最右边的子页。
*PageBtreeNode保存keys（SearchRow）和对应的childPageIDs；PageBtreeLeaf根据情况可能保存row的key或者row的全部值。PageBtreeNode中keys[0]同样也是childPageIds[0]中最大的rowKey。


====  PageDataIndex/PageDataNode/PageDataLeaf ====
*PageDataIndex主要作用就是组织表数据，RegularTable默认创建的mainIndex，只可以用于mainIndex。

*primary key符合条件（单列，并且类型是long,int,short,byte）时，primary key的Index类就简单封装PageDataIndex，同时PageDataNode/PageDataLeaf保存的keys就是primary key的值，否则parimary key的Index类就是PageBtreeIndex类，PageDataNode/Leaf保存的keys数组是对应每个row的自增值。
*如果表中有数据，添加/删除列会令primary key的Index类变为PageBtreeIndex类。（这是由于改变列先复制表，把原来的数据插入表中，然后删除原来的表，初始化新表的时候，会检查mainIndex是否有数据，如果有则不能使用原来的primary key索引。）
*PageDataNode保存Keys和对应的childPageIds表示子页PageDataLeaf/PageDataNode的pageId，查找key时，通过二分查找找到对应的子页的pageId。然后通过PageStore获取对应的子页
*PageDataLeaf内部保存Key和对应的offset。keys数组表示保存的key，offsets数组表示成员变量data里面每个key对应的数据offset。data保存的数据是row的全部列的值。


====  PageBtreeIndex/PageBtreeNode/PageBtreeLeaf  ====
*PageBtreeIndex就是二级B树索引，用于主键或者二级索引，不能用于内部scanIndex的索引（另外还有SpatialTreeIndex，基于MVR TreeMap，R树的一个实现）。
*PageBtreeNode与PageDataNode类似，代表的是B树的内部结点，PageBtreeLeaf则是其B树的叶子结点。

*onlyPosition成员变量，指示data是否只保存row的key，注意key为scanIndex所表示的key，即可能为primary key或者内部自增key。默认false。
 onlyPosition = true，则获取row的时候，需要通过offset获取data里面的key，然后通过RegularTable的scanIndex去查找对应的row的所有列的数据（同样利用二分查找）。由于需要scanIndex查找，产生更多的I/O。
 onlyPosition = false，则获取row的时候，直接通过offset获取data里面的数据，也就是row对应所有 索引列 的数据。注意只是索引列。直接从内存中data数据获取，不要消耗I/O。
 一般在PageBtreeNode插入新的childPage，或者PageBtreeLeaf插入新的row的时候data空间不足的时候可能会令onlyPosition=true，另外还要考虑split的情况。(TODO)

*PageBtreeNode/Leaf在二分查找的时候，根据row的索引列进行Value值对比：首先根据两个比较类型，按照规则转换到同一个指定类型，然后进行比较。

*迭代PageBtreeCursor

*默认NULL比较时，会小于任何非NULL的值，因此NULL会排在最前

== SQL Parser ==
使用Recursive descent中的predictive parser算法（https://en.wikipedia.org/wiki/Recursive_descent_parser）

流程：
Parser.parse(String sql)
1.initialize(String sql) 把sql转换大写，同时解析每个字符的所属类型（CHAR_SPECIAL_1，CHAR_NAME等）
2.read(), parsePrepared() 根据第一个符号分类进行SQL解析。parseSelect, parseInsert, parseDelete etc.
3.parseSelect() parse的具体过程，根据符号进行predictive parse，注意区分parseSelectUnion, parseSelectSimple等  
4.Select.prepare() 进行SQL优化（包括解析列名称，值优化、索引选择），CBO选择最优执行计划，各种优化细节等。
5.解析结果Command放入cache中



=======================================================================================================================
***********************************************************************************************************************


                                                     Select


***********************************************************************************************************************
=======================================================================================================================

*Select命令执行的时候，每个表用TableFilter表示，每个TableFilter只能有一个index。
*TableFilter有IndexCursor cursor对象，方便利用PageIndex对象进行迭代查询。通常情况下，查找都会预先指定一段范围[first, last]，然后利用二分查找到刚小于或等于first的元素，接着由Cursor进行next/previous的逐个元素遍历，直到超出指定范围为止。

*Select.preparePlan() -> Optimizer.optimize() -> Optimizer.calculateBestPlan() 如果只有一个表，则采用计算这个表的cost选择select索引。少于等于7个表的时候，采用BruteForce算法（对所有排列可能性计算cost）
*计算表的cost的时候，如果没有可用索引的条件语句，则使用RegularTable的scanIndex作为此次查询的索引。否则遍历所有索引，调用Index.getCost，通过where中条件列的情况，以及sortOrder计算cost，并选择出cost最低的索引，因此每次一个table只能一个索引。
对于PageBtreeIndex和PageDelegateIndex，计算cost的方法是BaseIndex.getCostRangeIndex()。具体cost计算方法建议查看代码。需要考虑多列索引的情况下，每一列指定相等、范围、半范围条件的情况（前缀索引），还要考虑符合order by的情况下，可以减轻cost。


*IndexCursor in优化？
*PageDataCursor的成员变量maxKey在每次迭代的时候判断是否超出范围，成员变量idx表示当前的row索引

*rowCount。计算cost的时候，rowCount是必须的。rowCount在PageDataIndex/PageBtreeIndex, RegularTable, Page都有保存。rowCount会保存到page head中，初始化会从Page读取出来，如果无效则会遍历树计算。另外要注意表数据格式有修改的时候，rowCount的值会跟着修改。


--------
//select * from test where id = 5;
1.CommandContainer.query(int maxrows); 
2.Query.query(int limit, ResultTarget target);
  fireBeforeSelectTriggers() 激发触发器

3.Select.queryFlat() //Not groupby/join/distinct
  TableFilter.next() 

  1.IndexCursor.find() //index type

    PageDataIndex.find(Session session, long first, long last, boolean multiVersion) (或者PageBtreeIndex)
      PageDataIndex.getPage()
        PageStore.getPage()
          CacheLRU.get() CacheLRU查找page data。CacheLRU没有使用mysql把缓存队列分为old/young。
                          另外，CacheLRU里缓存有PageDataLeaf,PageBtreeLeaf等B树以及data叶子节点。
          PageDataLeaf.find() 调用PageData.find()，二分查找。如果一个PageDataLeaf放不下，就会在PageDataNode

    二分查找成功后，cursor = PageDataCursor



IndexCursor.next()
-----
对于PageStore只有一层
PageDataCursor/PageBtreeCursor.next()
超出max范围就停止遍历，返回false。

对于MVStore，则有三层，见下面详细解释。


Select的缓存lastResult：
------
主要用途，当多次执行Select命令时，如果table数据没有被修改，可以不用执行Select，直接返回shallow copy后的lastResult。

1.首先是如何确定客户端发送的是否已经被执行过的命令？ 
客户端向服务器执行select需要4个来回协议：SESSION_PREPARE_READ_PARAMS，COMMAND_EXECUTE_QUERY，RESULT_CLOSE，COMMAND_CLOSE
(insert, delete, update由于不需要缓存结果集，只需要2个协议, SESSION_PREPARE_READ_PARAMS准备协议以及COMMAND_EXECUTE_UPDATE执行协议)

*执行SESSION_PREPARE_READ_PARAMS协议时，命令经过解析后，Session会缓存对应sql字符串以及解析后的命令对象Command。Session.prepareLocal()。因此如果客户端执行一摸一样的SQL查询时，就可以免去解析过程，直接将command对象作为解析结果。然后TCP线程缓存起来，等待下一个协议响应。
*执行COMMAND_EXECUTE_QUERY协议时，把该命令对象取出，假设是Select命令，所以事实上是Select对象。因此就可以确定同一个Select对象对于同一个SQL命令多次执行。
*RESULT_CLOSE协议，COMMAND_CLOSE协议：两个协议分别释放之前的结果集对象的缓存以及Select对象在TCP线程中的缓存。Session对于Select对象的缓存（LRU），以及Select对象自身内部的lastResult缓存没有被释放。

另外，sql对象字符串只要有少许不同，例如多了空格，Session缓存就会失效，会重新解析一个新的Select对象。

2.然后如何判断table数据是否被修改：
主要由Database的数据修改ID，modificationDataId以及其下所有表(RegularTable或MVTable)都各自维护的修改ID，lastModificationId。

简单来说，就是当表执行addRow, removeRow, truncate, commit四个修改table数据的方法就会调用database.getNextModificationDataId(); 使database的modificationDataId加1，然后该表就保存该值到lastModificationId。事实上只有database的全局modificationDataId进行计数，所有的表都是记录该值作为checkpoint。
*getMaxDataModificationId()接口返回上一个data修改的ID。

这样Select对象通过判断要查询所有表的最大lastModificationId即可知道表是否经过修改。具体是第一次执行时，保存当前的database的modificationDataId到自身的lastEvaluated，然后等下次再执行的时候，如果database的modificationDataId大于lastEvaluated，并且所有表中最大的lastModificationId大于lastEvaluated，那就是某个表的数据经过修改，lastResult无效。
事实上，Select第一次执行可以直接保存所有表最大的lastModificationId到lastEvaluated，然后第二次执行，直接对比所有表最大的lastModificationId是否大于lastEvaluated也可。
PS：貌似这里对于multi-thread特性支持不大好。


=====  Select.queryFlat ===== 
select * from test where id = 5;

--Path
Select.queryFlat(TableFilter) -> IndexCursor(支持IN(..)以及IN(SELECT ...)优化) -> PageDataCursor/PageBtreeCursor

*该过程中，直接拿RegularTable的scanIndex进行迭代，key的最小值和最大值为Long.MIN_VALUE和Long.MAX_VALUE，然后不断遍历叶子结点遍历数据。要注意的是叶子结点PageBtreeLeaf/PageDataLeaf的遍历过程: 两个兄弟叶子结点之间并没有指针连接起来，遍历完这个叶子结点要通过递归查询父结点获取下一个兄弟结点。具体为PageDataLeaf.getNextPage / PageBtreeLeaf.nextPage

*select索引过程中，首先从索引条件中解析出索引的最小值(>= LONG_MIN)和最大值(<= LONG_MAX)，然后去寻找所属范围最可能包含最小key的PageDataLeaf，寻找成功后PageDataLeaf构造一个PageDataCursor返回。然后TableFilter就开始进行cursor的遍历操作。


Condidtion总体：
返回boolean值或NULL的条件语句
Expression
 - Condition
    - ConditionNot              Not ...
    - ConditionAndOr            An 'and' or 'or' condition as in WHERE ID=1 AND NAME=?   index
    - ConditionInConstantSet    IN(...)中In list全部均为同种类型的常量                   index
    - CompareLike               where name like xxx                                      index
    - Comparison                >=,>,<=,<, !=, is null, is not null                      index
    - ConditionExists           WHERE EXISTS(SELECT ...)
    - ConditionIn               WHERE NAME IN(...)                                       index
    - ConditionInSelect         WHERE [ID IN(SELECT ...) / ID >= [ALL/ANY] (SELECT...)]  index

ConditionNot、ConditionExists不会建立索引。
ConditionAndOr只在And连接的条件建立索引。
ConditionInConstantSet默认情况下都建立索引。
CompareLike（like，regexp）中regexp不建立，like中如果patter首字母为匹配字符，即_或%时，则不建立索引，如果比较列类型不为字符也不建立索引。也就是对pattern为%xyz%, _xyz%不建立索引，对于xyz%，建立>=xyz的索引，以及<xy(z+1)的索引
Comparison，除了!=和is not null不建立索引，其它（>=,>,<=,<,is null等）比较与非自己表的列的表达式值时，都建立索引。
ConditionIn，要求inList的所有值都不能来自父select，具有非相关性，才能建立索引。
ConditionInSelect要求子select中selectList，condition，having子句全都不能来自父select语句，也就是与父select非相关，才能建立索引。

对于多重Condition，如where a.name >= 'aaa' and a.id <= 99 and b.v1 = 39 and b.v2 >= 'aaa'，会组成一颗树，根据括号的优先级最高，AND优先级比OR高，从左到右建立的一颗二叉树。
需要注意的是一个规律是，由于AND比OR优先级高，如果同一层级里出现OR条件，则OR会作为树根，判断的时候会从OR开始。


具体细节：
*操作符>=,>,<=,<比较值的过程中，把形如a > 3的表达式分解为三个对象ExpressionColumn(a)、Comparison(>)、ValueExpression(3)，然后select出值后，通过ExpressionColumn解析出当前值所在列的值，ValueExpression取出指定值，然后Comparison进行比较，如果两种类型不一致，则会每个row都需要进行转型，如a > 3里，a是string类型，则每次都要转换成Int。
*操作符!=, is not null不会使用索引，以[Long.MIN_VALUE, Long.MAX_VALUE]范围从scanIndex搜索，每个row进行比较判断是否添加到结果集
*操作符is null会使用索引，对于PageDataIndex，由于key不可能为null，会以[Long.MIN_VALUE, Long.MIN_VALUE]进行一次搜索。对于PageBtreeIndex，由于允许NULL的key存在，则直接以null为key进行搜索，NULL比任何非NULL的值要小，因此所需搜索值都在前面的叶子结点。
*操作符in(...)，把常量值排序后，逐个利用索引查找。IndexCursor保存了inList，负责迭代inList的值，然后用Index进行查找。
*操作符Not。一般把Not的condition在内层。在Select层判断中，迭代结果会被NOT内层的condition判断，然后判断结果再进行NOT操作。
*操作符between ... and ...。编译为ConditionAndOr对象(可初始化为And或者Or，这里是And)，内部包含两个Compairson对象，left和right。left是>=，right是<=。如between start and end：简单地创建以[start, end]为范围，使用index进行搜索，将搜索结果在Select层再进行ConditionAndOr的判断，这里是And，即left和right必须均为true。
*操作符And，Or。
1.操作符And，left and right会对left, right表达式尝试建立索引条件，Or则不会建立索引条件。
2.注意And和Or的短路判断。
3.And的优先级比Or要高。

*in (select ...)
select id1 from test_btree t where v2 in (select v2 from test2 where id >= 30) no index
select id1 from test_btree t where id1 in (select v2 from test2 where id >= 30) index

子select与父select非相关，要分两种情况（no index和index）：
---如果in表达式的左侧列不能使用索引，则会进行全范围scan。在查询外层table的行的时候，condition过滤中，进行子select查询获取总的结果集（只查询一次，结果集会cache到子Select.lastResult），然后在这个结果集中进行查找，有两个方式 1，对于非all的并且是in/=的相等比较时，使用hash的distinct比较(LocalResult.containsDistinct）使用hash而而不用排序＋binary search可以减少value值的实际比较；2、否则遍历结果集逐个比较判断，要注意考虑是否all，最后返回condtion过滤结果。
---如果in表达式的左侧列可以使用索引，则左侧列对应的TableFilter会创建indexConditions，这样在计算cost的时候，由于子select是evauable，所以可以创建对应索引。执行时进行子select递归查询，获取结果集，缓存到内存中，再逐个对这些值进行父select的索引查询。
（对于非相关性，实现就是和缓存小表进行join一样，但是如果in的子select结果集大，则会消耗大量内存。改良方法：可以考虑转化为子select去重后进行nested loop join。如果转化为join之后，则通过改变join顺序可能会提高效率）


select * from test_btree t where id1 in (select v2 from test2 where id = t.id)
子select与父select相关，则不能建立索引，这时会首先逐个查询父select的行，然后再传给子select进行查询（可以根据这个值进行索引查询），看看是否满足in的值相等条件。如例子中，会先逐个查询test_btree的值，然后传入t.id到子select，子select会利用id的索引进行查询，如果存在row，则查看v2是否等于id1，如果等于则添加到结果集。
以上查询执行效果与join类似：select * from test_btree a join test2 b on (a.id = b.id and a.id1 = b.v2)。但以上的子查询等于限制了join顺序，不能进行优化。

关于join和子查询的比较
http://stackoverflow.com/questions/2577174/join-vs-sub-query
结论是1、子查询在逻辑上更加容易理解；2、子查询不用担心B有重复值带来的影响；3、一般情况join比子查询效率更高。

*多重操作符混合。解析过程见Parser.readCondition()。
*ConditionAndOr.optimize()优化：
0.根据cost大小，交换left和right（优化选取第一个进行索引查询的策略）
1.B=A AND B=0 -> B=A AND B=0 AND A=0  (多表join中有用)
2.B=3 AND B=0 -> B in (3, 0)
3.A IN(1, 2) OR A=3 -> A IN(1, 2, 3)
4.短路判断
*多个in(...)进行And合并。 则选取第一个进行索引查询，然后其它在最终进行condition进行过滤。
*Or不会建立索引！
*范围搜索And连接，则会对范围进行交集。

=====  Select.queryGroup/queryQuick/queryGroupSorted =====
isGroupQuery = true

select count(1) from test;
group by
order by
having ...
where + index

Expression
 - Aggregate    integrated aggregate functions, such as COUNT, MAX, SUM.

有以下的type
COUNT_ALL             COUNT(*)
COUNT                 COUNT(expression)
GROUP_CONCAT          GROUP_CONCAT(...)
SUM                   SUM(expression)
MIN                   MIN(expression)
MAX                   MAX(expression)
AVG                   AVG(expression)
STDDEV_POP            STDDEV_POP(expression)    (总体的标准差, VAR_POP()的平方根)
STDDEV_SAMP           STDDEV_SAMP(expression)   (样本的标准差, VAR_SAMP()的平方根)
VAR_POP               VAR_POP(expression)       (总体的统计方差)
VAR_SAMP              VAR_SAMP(expression)      (样本的统计方差)
BOOL_OR               BOOL_OR(expression)
BOOL_AND              BOOL_AND(expression)
SELECTIVITY           SELECTIVITY(expression)   (Selectivity 100 means values are unique, 10 means every distinct value appears 10 times on average)
HISTOGRAM             HISTOGRAM(expression)     （柱状图）

------
*queryQuick()，一种优化聚集的查找，执行时，直接获取aggreate的值。
如SELECT COUNT(*) FROM TEST 或者 SELECT MAX(ID) FROM TEST可以采用queryQuick。
只能COUNT_ALL，COUNT，MIN，MAX的聚集类型。对于COUNT、COUNT_ALL直接获取表的行数即可。对于MIN、MAX根据情况利用索引获取第一个或最后一个的值。
检查的条件比较严格：
没有group by，having语句，且只查找一个表
expressions：类型为COUNT时，里面的表达式不能为distinct且不能为NULL，最后还需要表能直接获取行数。类型为COUNT_ALL只需要表能直接获取行数。类型为MIN、MAX的要存在以该列为第一索引列的索引，也就是满足索引前缀，如以索引(a,b)，则MIN(a)成立，MAX(b)为不成立。
condition：存在有列表达式就不成立。

------
select sum(id), avg(v1) from test2 group by v3 having sum(v2) > 10;
*queryGroup()：
首先要索引查找where condition指定的，然后进行group by聚集计算，最后进行having过滤。

聚集过程：
ValueHashMap<HashMap<Expression, Object>> groups，group by分组和对应表达式分组数据的映射。
-->  HashMap<Expression, Object>  currentGroup， 某个group by分组的表达式以及对应的聚集数据的映射。
-->  AggregateData data。具体group by分组的具体select或having表达式的聚集数据。
-->  调用data.add()将row的值进行叠加计算到聚集数据中。
having过滤：
根据分组的key遍历ValueHashMap<HashMap<Expression, Object>> groups，复制出对应的值在row中，然后根据having条件进行过滤，最后添加到结果集中。

*优化的聚集投影（非强制表达式必须出现在group by中）：
ExpressionColumn.updateAggregate()
select的表达式以及having表达式中，如果某一列在同一group by分组中的值均相等，则该列可以不需要出现在group by分组。query execution时判断。

*Aggreate.updateAggreate() --> AggregateData.add()
对于COUNT、SUM、MIN、MAX、AVG的处理都很简单，基本在row分到对应分组后进行处理，最后获取结果的时候如有需要继续进行处理。

------
*queryGroupSorted()  group by index
isGroupSortedQuery=true
存在非scan非hash的索引，并且group by的column符合索引前缀的条件（index(a,b,c) good:group by b,a bad:group by a,c)。

总体流程：
在索引查找后经过where condition过滤，然后通过判断当前分组key是否与上一次的相同，如果相同则用上一次key的分组数据，然后进行聚集计算，如果不同则创建新的分组HashMap<Expression, Object>  currentGroup，并且同时会把上一次分组的数据进行having过滤，添加到结果集。
这是由于符合前缀索引条件时，可以确保数据按照分组的顺序进行遍历，可以按顺序计算出聚集结果输出单个分组，不需要遍历完所有数据，减轻内存负担。


=====  distinct  =====
Select.distinct=true

------
*select distinct v1,v2 from test2
distinct只能放在select表达式第一位，此时所有select表达式组成key进行distinct操作，
LocalResult.addRow()进行distinct操作，利用ValueHashMap<Value[]> distinctRows。如果结果集超过MAX_MEMORY_ROWS_DISTINCT，会使用临时表。

-----
*select sum(distinct v1) from test2 group by ...
与group by流程一致，将在聚集计算的时候进行distinct操作，利用ValueHashMap过滤重复的值。注意此时Select.distinct=false

------
*queryDistinct
distinct查询的一个优化，当distinct仅包含一个列col时，存在符合该col的前缀条件的索引，则会利用该索引进行查询，特别的是这里不是范围查找，而是每次指定刚好大于上一次col结果的值来进行查找，这样就不需要在LocalResult进行distinct操作。
另外要注意该col的selectivity < 20，也就是存在较多的冗余值，这样能过滤更多不必要的查找，更加有效。


=====  Order by SortOrder.sort =====
Select.sort=true

------
*SortOrder.sort
查找完所有的结果后，执行LocalResult.done --> SortOrder.sort进行排序。
如果内存允许，并且没有limit和offset，则直接调用Collections.sort(rows, this)，Java内置的List排序算法进行排序（Timsort，对于部分有序的数组会有远小于NLog(N)，并且对于随机乱序的数组同样保持NLog(N)）。
如果存在offset或limit，则使用Utils.sortTopN(arr, offset, limit, this)。首先使用快速排序进行部分排序，具体是使[offset, limit + offset - 1]这范围内的值放到这范围上（该范围内的值不一定有序），然后使用Arrays.sort(array, offset, (int) Math.min((long) offset + limit, array.length), comp)保证[offset, limit + offset - 1]有序（Arrays.sort同样是Timsort，仅对指定范围排序，其它范围顺序不变）。

使用快速排序进行部分排序，可以参考Utils.partialQuickSort(X[] array, int low, int high, Comparator<? super X> comp, int start, int end)，关键是在开始增加判断条件(low > end || high < start || (low > start && high < end))，如果成立则直接return，不需要继续排序。

------
*sortUsingIndex=true
使用索引进行排序。利用索引的顺序遍历数据，数据集就保证有序，可以避免在最后进行的排序操作，对于结果集数据比较大的时候相当有效。
使用条件：
1.符合order by里指定列顺序，非scan和非hash索引，并且索引的每列排序类型必须符合order by的指定（如index(v1, v2), order by v1 asec, v2 desc不符合，order by v1, v2符合），这个索引为排序索引
2.如果之前经过cost选择的索引current是scan（默认索引），或者与排序索引一致，并且不存在IN条件查询（IN条件查询可能导致遍历结果与order by不一致），则sortUsingIndex=true。
3.代码上是替换current索引，如果排序索引列排序类型与current索引不一致，但按照cost计算已经考虑order by因素，暂时没有想到这种情况出现。


=====  join  =====
只利用嵌套循环实现join（join可以通过把小表放内存、排序-合并、散列、等方法实现。）（对于小表join下，嵌套循环效果比较简单有效）

inner join
------
select a.id, b.v1 from test a join test2 b on a.id = b.id
select a.id, b.v1 from test a, test2 b where a.id = b.id;
两条SQL经过parse一致。

*cost计算。列出所有join表的组合A(n, n)(n为join表的数量)(Permutations类实现)作为Plan，分别计算每个Plan的cost，取最小值的plan。每个Plan中，不同的table分别计算cost，cost += cost * item.cost计算plan的总cost。另外要注意当前tableA计算cost之后，evaluatable=true，这样下一个有该tableA关联条件的tableB就可以利用索引计算。
这里要注意一个可能的规律，小表放在最左边能够使cost更小。（这样会对大表使用索引查找，在嵌套循环更加有效）。因此，在计算完每个table的cost的时候，考虑到indexConditions越多则一般表越小，所以会有以下的计算：
item.cost -= item.cost * indexConditions.size() / 100 / level;  （level是join表的顺序，100是一个启发式计算值）
（nested loop实现的join，oracle计算cost = costA + rowA * costB，估计这里为了方便所以是cost = costA + costA * costB）

对于这种cost计算方式，如果join不能使用索引，如以下SQL：
select * from test_btree a join test2 b on (a.v2 = b.v2);
a的scan cost为10320，b的scan cost为58880，由于启发式cost对b减小差值较多，因此会令b作为第一个join表（有点像副作用，实际这里join顺序影响不大），实际上是一个cross join最后加上Select的condition过滤。
但如果有index，则差别会非常大，这个cost计算方式就会生效。

*完成SQL语句编译后，把最左边的join table作为topTableFilter，然后从它开始进行循环。
*先读入TableA一列数据（实际读入整个block），然后b再根据id利用索引搜索，找出所有相同id的列。
foreach tableA as rowA
 foreach tableB as rowB
  if (rowB.id == rowA.id) {
    result.addRow(rowA,rowB);
  }

*H2的inner join/left, right join的on子句都是可选的。如果没有on子句，效果就和cross join一致。


condition push down & filterCondition
------
select a.id, b.v1 from test a join test2 b on a.id = b.id where a.name >= 'aaa' and a.id <= 99 and b.v1 = 39 and b.v2 >= 'aaa'
select a.id, b.v1 from test a join test2 b on a.id = b.id where a.name >= 'aaa' and a.id = 99 or b.v1 = 39 or b.v2 >= 'aaa'  （可以考虑会出现什么判断，注意OR）

原理：
为了提高join的效率，在嵌套循环中，可以把condition push down到join表中，这样就可能减少join的次数，提高效率。另外，对于最后一个join表，则不需要这个优化，因为已经完成了join，最终还是会到condition的过滤，不需要filterCondition的提前过滤。

流程：
1、条件上推（Parser阶段）。Parser.parseJoinTableFilter把非outer join的joinCondition（a.id = b.id）添加到Select.condition中，Parser.parseSelectSimple把where的条件加入到Select.condition中。这样就把所有的condition上推到顶层Select中。
2、索引条件下推（准备阶段）。Select.prepare中，所有的TableFilter会根据Select的condition判断是否适合创建IndexCondition（Index遍历需要），也就是下推到TableFilter。
3、cost计算（优化阶段）。Select.preparePlan过程中，首先push所有Select的condition到每个TableFilter的fullCondition中，然后Optimizer.optimize()优化过程计算所有A(n,n)的join组合，这个过程会参考indexCondition进行cost的计算，最后选择最小cost的join组合作为执行plan。
4、fullCondition下推（优化阶段）。主要把满足条件的fullCondition下推到filterCondition（在嵌套循环中过滤，Plan.optimizeFullCondition）。大致要求condition的表达式必须是evaluatable，也就是如果涉及别的表的列表达式，则该表达式必须是较前join顺序的表。另外对于AND的condition，可以left和right分别判断是否符合条件，但对于OR的condition，必须是左右同时满足evaluatable（可以仔细想想为什么，因为OR的话，如果仅仅left符合，但不确定是否可以filter，所以必须left和right均一起添加到filterCondition才有意义，但AND则可以left或者right符合，则可以判断是否filter）。

结果：
在上面例子最终选择的join顺序为（B,A）：具体如下
TableFilter b的filterCondition为((B.V2 >= 'aaa') AND (B.V1 = 39))
，同时index为PageBtreeIndex（v1, v2），indexCondition为((B.V2 >= 'aaa') AND (B.V1 = 39))
TableFilter a的filterCondition是NULL，同时index为scanIndex，indexCondition为a.id = b.id。
Select的condition为
((A.ID = B.ID) AND ((B.V2 >= 'aaa') AND ((B.V1 = 39) AND ((A.NAME >= 'aaa') AND (A.ID <= 99)))))
之所有选择B,A，是因为当B作为topTableFilter的时候，A就可以利用scanIndex进行join匹配，这时候由于是EQUAL，所以cost比id <= 99的范围要少得多，因此就选择了B，A。

virtual table join
------
select a.id, b.v1 from test a join (select * from test2 where id = 99) b on (a.id = b.id)  where b.v1 <= 99  
（深入优化：可以考虑把id >= 99 上推到外层的select，然后再下推到test中）

select a.id, b.v1 from test a join (select * from test2 where id <= 99) b on (a.id = b.id)  where a.id <= 99
（indexConditions和filterCondition都包括相同的a.id <= 99，H2的优化不足，没有取出冗余条件）

总体流程和上面的condition push down & filterCondition差不多，关键是内层的Select看成virtual table，table为TableView，视图。

过程：
-外层Select解析为TableFilterA和TableFilterB。TableFilterB（内部的table为TableView，视图。同时包含内层的Select语句），就是把内层Select解析成一个virtual table。（内层Select解析的过程有点麻烦（TODO）
-条件上推。外层Select的condition为 a.id = b.id and b.v1 <= 99
-索引条件下推。TableFilterA的IndexCondition为 a.id = b.id。TableFilterB的IndexCondition为 a.id = b.id和v1 <= 99。
-计算cost。同样是列出所有的排序顺序A(n,n)，然后通过公式cost = costA + costA * costB计算cost。另外还会push顶层的condition到TableFilterA, TableFilterB的fullCondition。
-计算TableFilterB的cost（ViewIndex.getCost）。首先将内层的Select语句再次解析到Select q，然后根据传入的索引masks，往q传入参数指定的列和对应的参数，把a.id = b.id and b.v1 <= 99 转换为 TEST2.ID IS ?1 AND TEST2.V1 <= ?2，添加到q的condition。（Select.addGlobalCondition）。这时q的condition变为id >= 99 and TEST2.ID IS ?1 AND TEST2.V1 <= ?2，然后重新取出q的SQL语句，重新对该SQL语句进行解析编译，根据刚刚的condition进行解析，cost计算等，获取了新的select对象q。对于该例子，还是选取了id is ?1以及id >= 99同时作为IndexCondition。
-经过分析后，执行条件就显而易见：TableFilterA作为外层循环，通过scanIndex得出row，然后，TableFilterB作为内层循环，通过id is ?1 以及 id >= 99的indexConditions获取每次搜索的范围，然后利用索引查找对应的join的row，这里TableFilterB的索引是ViewIndex，负责了把id is ?1的条件转换为每次循环的实际值，也就是A的id。然后还要经过内层Select的condition过滤。
-另外有一个有趣的是，如果把内层的select的condition改为id = 99，此时则会是TableFilterB作为外层的循环，TableFilterA变成内层循环，具体cost计算可以参考下面，主要是因为TableFilterB为外层循环的时候，v1 = 99的EQUAL条件可以令cost大大降低，于是总的cost也大大降低
id >= 99
A  10206.9          29.85
B  30.096           19055.708
   317424           587899

id = 99
A  10206.9        29.85
B   30.096        30.086
     317424       959

select a.sid, b.v1 from (select sum(id) as sid from test where id >= 30 group by name) a join (select * from test2 where id >= 99) b on (a.sid = b.id);
-在计算TableFilterA的cost中，把顶层Select的condition下推的时候，该select子句是group by查询，并且参数指定的列不在group by的列中，会直接把该参数条件转换为having子句。即会变成
SELECT SUM(ID) AS SID FROM PUBLIC.TEST WHERE ID >= 30 GROUP BY NAME HAVING SUM(ID) IS ?1

结构：
Select  (select a.id, b.v1 from test a join (select * from test2 where v1 >= 99) b on (a.id = b.id))
  condition (A.ID = B.ID)
  TableFilter (A)
    indexCondition (null)
    RegularTable (A)
    PageDataIndex (scanIndex)
  TableFilter (B)
    indexCondition (A.ID = B.ID)
    TableView (B)
      ViewIndex
    ViewIndex
      Select (SELECT TEST2.ID,TEST2.V1,TEST2.V2,TEST2.V3 FROM PUBLIC.TEST2 WHERE (V1 >= 99) AND (TEST2.ID IS ?1))
        condition (v1 >= 99 and test2.id is ?1)
        TableFilter (test2)
          indexCondition (ID is ?1)
          RegularTable (test2)
          PageDelegateIndex (scanIndex wrap)

left outer join
------
select a.id, b.v1 from test a left outer join test2 b on (a.id = b.id)  where b.v1 <= 99 and a.name >= 'aa'

由于left outer join不能决定了join的顺序，因此对比之前的join有了一定的限制：
-topFilters只有TableFilter A，并且a.id = b.id也没有上推到外层Select的condition，这是由于上推是为了在计算cost的时候对于不同join顺序，计算对应的cost，但现在只计算一个顺序，因此不需要上推。（Parser.parseJoinTableFilter, isOuter = true）
-另外对于outer join后面的表，只有原来的a.id = b.id，不会从Select的condition中创建indexConditions（索引条件下推），因为下推可能会影响结果。可以假设下推条件到B，如果B过滤了某些行，但是一样可以产生join结果，只不过在对应B的列为NULL，这时就等于过滤失败。具体可以参考下面的SQL：
select p, c from parent left outer join child on p = pc where c is null;
-计算cost的时候，只计算A，B的顺序，并且TableFilterB被计算了两次，可能有BUG。
-fullCondition下推到filterCondition的时候，对于TableFilterB不会执行（并且也没有意义），这和前面索引条件不能下推的理由一样。

*执行Plan大致为：TableFilterA使用scanIndex，filterCondition为a.name >= 'aa'，indexConditions为NULL；TableFilterB使用PRIMARY_KEY_INDEX，indexConditions为a.id = b.id，joinCondition为a.id = b.id，filterCondition为NULL。
*过程：A先遍历出一行，然后B遍历，首先根据主键索引找出对应的行，然后通过joinCondition过滤（a.id = b.id使用了两次，此处的joinCondition应该是冗余），如果B找不到row，则会设置为NULL row。B遍历完毕，返回到顶层的Select，Select的condition过滤后，将投影的列的值从对应的A、B取出。

right ouer join
------
select a.id, b.v1 from test a right outer join test2 b on (a.id = b.id)  where b.v1 <= 99 and a.name >= 'aa'
三个TableFilters：B, SYSTEM_JOIN_78(DUAL table，一行一列), A
SYSTEM_JOIN_78作为一个DUAL table，类似一个proxy，进行nested join的查询。

外层Select的condition为b.v1 <= 99 and a.name >= 'aa'；
B的indexConditions为v1 <= 99，filterCondition也为v1 <= 99，index为PageBtreeIndex（v1，v2），join为SYSTEM_JOIN_78；
SYSTEM_JOIN_78的joinCondition为a.id = b.id，index为RANGE_INDEX (实际不会用到)，nestedJoin为A，joinOuter=joinOuterIndirect=true；
A的index为主键索引，indexConditions为a.id = b.id，另外fullCondition为NULL, joinOuterIndirect=true, joinOuter=false。

SYSTEM_JOIN_78进行类似nested join的查询，当调用next()的时候，会调用nestedJoin.next()进行查询。

natural join
------
select a.id, b.v1 from test a natural join test2 b where b.v1 <= 99 and a.name >= 'aa'
natural join与inner join类似，注意亮点：
1、Select中出现*这个通配符需要去除a和b的相同列b.id，2、自动添加condition a.id = b.id。
其余都与采用a.id = b.id的inner join一致，即同样的condition下推，join顺序优化，索引选择等。

cross join
------
select a.id, b.v1 from test a cross join test2 b where b.v1 <= 99 and a.name >= 'aa'
cross join流程与inner join类似，就是没有了inner join的on condition（a.id = b.id），同样又condition下推，join顺序优化，索引选择等。


nested join
------
select a.id, b.v1, b.v3 from test a join test2 b on a.id = b.id and a.name = b.v2 
left outer join test3 c
join test4 d on (c.id = d.id)
on (a.id = c.id) where a.name >= 'a';

通过移动on子句的位置，可以改变join的顺序，对于inner join结果一样，但outer join会有差别。可以通过配置来控制是否支持netsed join，具体通过在URL中添加配置，如"jdbc:h2:test;;NESTED_JOINS=FALSE"，则会关闭此特性的解析。
关于nested join的实现，主要看TableFilter.next()中的循环（就是nested loop对于每个TableFilter的一次循环，代码写得比较复杂）：
1、如果没有nestedJoin表，则首先当前TableFilter通过索引查找出合适条件一行，否则，调用nestedJoin.next()，即让nestedJoin进行迭代；
2、如果前面当前TableFilter无法查找适合条件一行，则退出当前循环；如果nestedJoin.next()返回false，即同样没有找到合适的行，并且为outer join且之前没有找出符合的一行，则设置当前行为NULL行。
3、filterCondition过滤（join前过滤），如果不符合条件则会退出循环。注意nested Join的filterCondition为NULL，则肯定符合条件。
4、joinCondition过滤（join后过滤），如果不符合条件则会退出循环。
5、join.next()。如果join.next()返回false，即没有找到合适的行，则退出当前循环。


以下针对outer join进行讨论：
nestedJoins=true：
则会解释为
(A join B) left ouer join (C join D)
Parser解析为：
A join B outer join SYSTEM_JOIN_XXX nested join C join D
left outer join当遇到nested join的时候会借助SYSTEM_JOIN_XX进行nested join循环的辅助。

nestedJoins=false:
解释为：
A join B outer join D outer join C
Parser解析为：
A join B join D(outer:true) join C(outer:true)
另外，以上的SQL由于C放在后面，因此d on (c.id = d.id)中的c.id无效，解析会失败。

如果将left outer join改为right outer join，则：
nestedJOins=true，解释为：
(C join D) outer join (A join B)
Parser解析为：
C join D outer join SYSTEM_JOIN_XX nested join A join B
right outer join无论是否有nested join都会借助SYSTEM_JOIN_XX进行nested join循环的辅助。这里与left outer join不同，因为left outer join是在判断nested && joined后可以直接往left outer join的右边添加SYSTEM_JOIN_XX，right outer join需要往中间添加SYSTEM_JOIN_XX，为了方便，因此right outer join的右边不会判断是否存在nested join，直接往中间添加。具体可以参考Parser.readJoin()。

nestedJOins=false，解释为：
C join D outer join A outer join B
Parser解析为：
C join D outer join A outer join B


Join的解析 ＋ condition作用总结
------------
Praser.readJoin
从左到右解析join：
如果cross join, natural join, inner join，则可以任意组合join顺序，也不改变topTableFilter，并且可以condition下推等优化。
如果left outer join，则左边的表以及之后的所有TableFilter的join顺序就会被固定，但不会改变topTableFilter，不可执行condition下推的优化。
如果right outer join，则把topTableFilter转为右边的表，并且整个join顺序都不能再改变，并且会创建SYSTEM_JOIN_xxx表进行join辅助。
--尤其要注意的是outer join对join顺序限制，仔细考虑为什么是这样的规则，具体原因是join顺序改变会对结果造成影响。


outer join不能随意下推condition：
一致：
select * from test5 a join test6 b on (a.id = b.id) where a.name = b.name;
select * from test5 a join test6 b on (a.id = b.id and a.name = b.name);

不一致：
select * from test5 a left outer join test6 b on (a.id = b.id) where a.name = b.name;
select * from test5 a left outer join test6 b on (a.id = b.id and a.name = b.name);
因此在left outer join中，不能把where的条件子句下推到B.joinCondition/B.indexCondition，会影响结果。


join, outer join的condition总结：
Select.condition是查询结果加入结果集前的过滤条件，最后的过滤；indexCondition一般是索引查找过程的条件；filterCondition一般是where的条件子句，主要用于join之前的过滤；joinCondition一般是on的条件子句，主要用于join之后的过滤。由于outer join的限制，包括优化存在，这三个condition有可能为NULL。

select a.id, b.v1, b.v2 from test a right outer join test2 b on a.id = b.id and a.name = b.v2 join test3 c on (a.id = c.id) where b.v3 >= 'a'

0、初次编译。根据join顺序，给join表B的join和joinCondition赋值。即A.join = B, B.joinCondition = (a.id = b.id and a.name = b.v2)。然后会让join表B对on表达式的条件尝试创建indexConditions（TableFilter.mapAndAddFilter）。另外注意：
inner join： A.isJoinOuter() == A.isJoinOuterIndirect() == B.isJoinOuter() == B.isJoinOuterIndirect() == false；
left outer join： A.isJoinOuter() == A.isJoinOuterIndirect() == false； B.isJoinOuter() == B.isJoinOuterIndirect() == true；
right ouer join：
1、条件上推（Parser阶段）。对于inner join、natural join，Parser.parseJoinTableFilter把join的joinCondition（a.id = b.id）添加到Select.condition中，Parser.parseSelectSimple把where的条件加入到Select.condition中。这样就把所有的condition上推到顶层Select中。另外，在这阶段，同时把所有非outer join的TableFilter都成为topTableFilters，表明可以更改join顺序。（outer join不参与，condition只包含where部分）
2、索引条件下推（准备阶段）。Select.prepare中，对于!isJoinOuter() && !isJoinOuterIndirect()的TableFilter会根据Select的condition判断是否适合创建IndexCondition（Index遍历需要）。
3、cost计算（优化阶段）。Select.preparePlan过程中，首先push所有Select的condition到每个TableFilter的fullCondition中，然后Optimizer.optimize()优化过程计算所有A(n,n)的join组合，这个过程会参考indexCondition进行cost的计算，最后选择最小cost的join组合作为执行plan。
4、fullCondition下推（优化阶段）。主要把满足条件的fullCondition下推到filterCondition（在嵌套循环中过滤，Plan.optimizeFullCondition）。大致要求condition的表达式必须是evaluatable，也就是如果涉及别的表的列表达式，则该表达式必须是较前join顺序的表。另外对于AND的condition，可以left和right分别判断是否符合条件，但对于OR的condition，必须是左右同时满足evaluatable（可以仔细想想为什么，因为OR的话，如果仅仅left符合，但不确定是否可以filter，所以必须left和right均一起添加到filterCondition才有意义，但AND则可以left或者right符合，则可以判断是否filter）。（isJoinOuter() == true不参与）

inner join可以对A、B进行filterConditions、indexConditions优化，left outer join只会对A进行filterConditions、indexConditions优化。

BUG:
1、Select.condition不会对已经下推的condition进行删除，所以会有不必要的冗余过滤。
2、Plan.calculateCost()根据每个join顺序的plan中，循环是根据join顺序中每个表计算cost。但如果是outer join则join顺序已经固定，因此循环里应该是join顺序固定好的filters，而不是allFilters，不必要遍历其它join顺序。目前在循环的时候，allFilters为filters中的表才是有效的PlanItem，outer join固定了join顺序后，会递归计算join表的cost，而不再需要在循环里再次计算cost。
即allFilters是包括A，B，C，但事实上只要计算B的时候，会递归计算SYSTEM_JOIN_XX，A，C，具体如下：

B -join-> SYSTEM_JOIN_XX -nestedJoin-> A
                         -join->       C
A
C

3、Plan.removeUnusableIndexConditions()同样也是allFilters应该转换为filters？


multi-table mixed join
------
select a.id, b.v1, c.v2 from test a right outer join test2 b on (a.id = b.id) right outer join test_btree c on (c.id = a.id) where b.v1 >= 99 and a.name >= 'a' and c.id1 >= 'aa'

TableFilters: C --join--> SYSTEM_JOIN_130 --nestedJoin--> B --join--> SYSTEM_JOIN_83 -->nestedJoin--> A
其中，除了C以外，joinOuterIndirect均为true。


select a.id, b.v1, c.v2 from test a join test2 b on (a.id = b.id) join test_btree c on (c.id = a.id) where b.v1 >= 99 and a.name >= 'a' and c.id1 >= 'aa'
A join B join C，和之前流程一致，计算所有的join顺序的cost，然后选出最小的join顺序。注意上面特殊例子中，两个join条件，a.id = b.id和c.id = a.id，优化器会添加b.id = c.id到condition，能产生更有效的执行plan。
cross join、natural join、inner join都不会因为join顺序影响，可以通过计算不同join顺序的cost得出最优执行plan。


union/union all/except/intersect
------
select a.id, b.v1 from test a cross join test2 b where b.v1 <= 99 and a.name >= 'aa'
union/union all/except/intersect
select a.id, b.v1 from test a left outer join test2 b on (a.id = b.id)  where b.v1 <= 99 and a.name >= 'aa'

SelectUnion，unionType可以为UNION（并集去重）, UNION_ALL（并集）, EXCEPT/MINUS（left中不包括right）, INTERSECT（交集）
有left和right两个select对象，根据unionType分别对left和right进行query，还有结果集LocalResult的处理。
查询前准备：
对于UNION和EXCEPT，要求left和right采用distinct查询，以及LocalResult设置distinct处理，INTERSECT则需要left和right采用distinct查询，UNION_ALL忽略。
查询后处理：
UNION_ALL添加结果集即可，UNION通过addRows添加left和right结果集同时进行distinct处理，EXCEPT先添加left结果集同时进行distinct处理，然后去掉right的结果集中相同的部分。INTERSECT需要创建一个临时结果集，先把left结果集添加到temp同时进行distinct处理，然后查看right结果集中，如果包含在temp中则添加到返回的结果集里。


***
Select总结：Select的实现由于仅支持nested loop，扩展性极差，是属于面向过程的实现；对于condition的优化不够好，loop过程中有一些重复的condition。可以参考PostgreSQL的执行流程，让一些诸如scan、sort、join的操作对象化，组成类似树的结构。另外对于condition优化，应该参考Hive的树遍历机制，整理condition。
尽量不要用right outer join，不要用in子查询（join+distinct替代），


=======================================================================================================================
***********************************************************************************************************************


                                                     Insert


***********************************************************************************************************************
=======================================================================================================================

insert into test4 values(14, 14);

流程：
1、Parser解析
2、Insert.prepare()进行简单的优化。对values表达式每个进行简单优化，或者调用select.prepare()优化select的表达式
3、Insert.update()执行命令。


Insert -> PageDataIndex/PageBtreeIndex -> PageDataNode,Leaf/PageBtreeNode,Leaf


insert into test4 values(13, 13);
-Insert.insertRows()
..将values列表的值按照插入对应的Column定义的类型进行转换，然后对每一行插入数据进行操作：按照默认值更新NULL值，检查插入值限制，精度转换，Sequence值更新操作。
..table.lock锁表
..RegularTable.addRow。循环该table的所有index添加row。具体调用index.add()。另外这里有个trick，如果更改次数超过一定，则会取一定数量的列作为sample，然后创建SQL查询每列的selectivity，然后更新每列的selectivity（RegularTable.analyzeIfRequired()）。
..Session.log()。往session的undoLog添加undo log（与PageLog不同）。主要用于事务roll back。
-Session.commit()
往PageLog写入commit日志，包括当前session的id，表示当前session提交事务。
接着清空undoLog。
unlock所有在Session保存的锁表locks中的锁。


*index.add()实现 (PageDataIndex、PageBtreeIndex)：
PageDataIndex ：
把row插入rootPage，然后计算出split point，如有需要则split该rootPage，rootPage有可能是Leaf或Node。插入前决定row的key（如果存在主索引列，则以该列的值作为key，否则以记录的lastKey递增的值作为key），注意split rootPage的时候，为了不改变rootPageId带来的负担，更改原来rootPage的pageID，然后再原来的rootPageID上创建新的PageDataNode。split完成后，然后需要重新插入查找插入位置，再进行插入操作。
然后更新rowCount，然后调用PageStore.logAddOrRemoveRow()，写入redo日志，让当前session记录当前logSectionId，logPos作为第一个没提交的事务记录。然后往PageLog写入type为ADD的日志并输出到PageOutputStream。

PageBtreeIndex：
add方法基本一致，但不需要后面的logAddOrRemoveRow（redo日志只需要写一次，PageDataIndex必定已调用）

插入row到PageDataLeaf、PageDataNode、PageBtreeLeaf、PageBtreeNode：
主要有两个方法addRowTry()、split()。4个页类型都有自己的实现，addRowTry()主要是添加row到该页，并且返回split point。split()则是split page，创建新的兄弟叶子结点。

----
-PageDataLeaf
addRowTry()
修改之前，要写入undo日志。undo日志是以page为单位，格式为[type(UNDO), pageId, pageData]，pageData会经过LZF压缩。（PageStore.logUndo()）注意这里并没有flush操作，undo日志仍然可能在内存中；接着然后判断添加row是否会溢出页面大小（添加的row是从底部向上的，因此只需要判断最后的offset - row长度 < start + keyoffset）：
..没有溢出
如果之前没有数据，或者插入后不会溢出。首先通过二分查找找出insert point，然后往offsets数组插入新的offset，注意offsets中插入点后面的值要偏移。接着往keys，rows数组插入row的key以及row。然后调用PageStore.update()更新该page，主要是在对应的PageFreeList设置used的标志，然后更新一下CacheLRU的链表。接着要更新page的数据data，把数据从insert point开始前移rowLength（逆序增加），然后在insert point写入row。最后返回-1作为split point，表示不需要后续的split操作。
..插入前有数据，并且插入后溢出：
需要增加新的Leaf结点作为兄弟，按照insert point的大小，有3种情况：
1.entryCount/3
如果insert point位于[0, entryCount/3)，则split point为entryCount/3；
如果位于[entryCount/3, 2*entryCount/3)，split point为insert point；
如果位于[2*entryCount/3, entryCount - 1]，split point为2*entryCount/3。
由于Leaf页保存row的数据，比单纯保存keys要大，因此这个方式可以保证split point比较接近insert point的同时，也保证split之后page至少包括entryCount/3，确保一个更好的页面利用率。
2.entryCount/2
如果insert point<5的时候（<= 5 ?），entryCount/3的算法并不能保证更好的分配，因此split point只为entryCount/2。
3.insert point
如果sortedInsertMode为true，则insert point为split point。按照不同情形直接返回对应的split point，不进行插入row操作。
..插入前没有数据，插入row后溢出，即rowLength大于页大小，需要写overflow page。具体就是，首先把row的部分复制到page剩下的空间，然后根据剩下大小分配PageDataOverflow页，然后继续把剩下的复制进去，如果仍然不足，继续分配PageDataOverflow页，继续填充该页，直到把rowLength充满位置，注意PageDataOverflow之间都有parentPageId、nextPage代表前后页的pageID，另外当前PageDataLeaf页也有保留第一个PageDataOverflow的pageID。要注意的是，为了方便后面的读操作，有SoftReference直接对该row的引用，避免要遍历PageDataOverflow读取数据。
split()。
分配并创建新的PageDataLeaf，然后把范围[split point, entryCount - 1)的数据添加到新的叶子结点，然后删除这段范围的记录。删除前写入undo日志，然后偏移页数据data覆盖旧值，以及修改offsets、keys、rows数组。返回创建的新页。

-PageDataNode
addRowTry()
写入undo日志。然后是一个循环，需要不断循环尝试查找插入点，如果遇到split则先split后再查找，直到不需要进行split可直接插入row为止。具体为：
二分查找插入点，选择插入点的子page，调用page.addRowTry()，进行递归查找，直到叶子结点调用addRowTry添加row。如果子page需要进行split操作，表示当前页也需要进行插入row。需要判断是否溢出，这里的逻辑比Leaf简单，具体为
如果溢出，则直接返回entryCount/2作为split point。（由于Node结点只包括key值，不需要考虑页面利用率）
如果没有溢出，首先取出子page的split point - 1的位置的key作为pivot，然后子page.split()出新的兄弟页page2，然后PageStore.update()更新该page,page2的相关缓存信息，接着调用addChild()把page2插入，pivot作为key作为新的子page。然后再PageStore.update()更新当前Node页的相关缓存信息。split完成后，返回循环开始，再重新查找插入点。
成功插入row后更新行数＋1。
split()
分配并创建新的PageDataNode。把[split point, entryCount - 1)的数据添加到新的PageDataNode，并且从该页删除。删除前同样写入undo日志，然后修改pages、childpageIds数组。
要注意对于PageDataNode，keys[0]是childPageIds[0]中最大的rowKey，并且childPageIds大小为entryCount+1，最后一个childPageIds为最右边的子页。因此childPageIds是从split point + 1开始移动到新的子页。最后并且要注意把新的PageDataNode的子页重新设置parent为自己。

-PageBtreeLeaf
addRowTry()
基本和PageDataLeaf一致，在溢出的时候，会令onlyPosition为true，只保存position。
split()
基本和PageDataLeaf一致。
-PageBtreeNode
基本和PageDataNode一致。

总结：
PageDataIndex插入row，具体为：
查找插入点      -->     是否进行split操作 -不需要split-> 插入row。
           <-需要split-

查找插入是从根到叶，split操作是从叶到根的遍历。

首先从rootPage开始利用二分搜索查找插入点，一直遍历到底层的PageDataLeaf。如果PageDataLeaf溢出，则从split point创建兄弟结点，然后父PageDataNode则会尝试增加它的兄弟。这样相当于向父结点插入新的值。如果父结点已满，则递归向其父结点PageDataNode请求插入，如果一直递归到PageDataIndex，则需要新增PageDataNode作为rootPage根索引页，层数增加1。然后重新查找插入点，直到不需要进行split成功插入为止。

存在问题：
1.插入row非常大的时候（超过pageSize），按照entryCount/3的算法有可能不断split page，直到split出空页，然后再插入该空页以及分配overflow页，这样会导致大量的低利用率的page产生。（使用CLOB类型）CLOB根据大小，如果数据不大，则保存内存并直接把数据写入用户表；如果数据太大，则写入专门的LOB表，通常是把数据压缩后插入，同样需要overflow页保存数据，然后获取LOB表中对应的id，把这个id插入用户表。
2.需要先split，然后再insert，考虑如何同时完成split以及insert操作。


*h2的insert into...select...扩展语法
insert into xxx [direct/sorted] select ...
默认Select的结果保存到结果集中，默认在内存中，如果结果集太大，可能写入临时文件，或者建立临时表（需要随机访问结果集）。然后遍历结果集，作为insert的输入，逐个row插入。

When using DIRECT, then the results from the query are directly applied in the target table without any intermediate step.
-Insert.insertFromSelect=true
把select的结果row直接作为insert的输入，直接插入。

When using SORTED, b-tree pages are split at the insertion point. This can improve performance and reduce disk usage.
-Insert.sortedInsertMode=true
PageDataLeaf插入row溢出的时候，则以insert point作为split point。


Insert总结：
1、锁。
有4个lock mode。默认为LOCK_MODE_READ_COMMITTED
LOCK_MODE_OFF(0)，            READ_UNCOMMITTED，不上锁
LOCK_MODE_TABLE(1)，          SERIALIZABLE，    表锁
LOCK_MODE_TABLE_GC(2)，       SERIALIZABLE+GC， 表锁+GC，等待锁的时候会进行GC
LOCK_MODE_READ_COMMITTED(3)， READ_COMMITTED，  表锁，read lock在命令执行完后马上释放

insert前调用RegularTable.lock()，每个RegularTable都包含lockShared（HashSet<Session>），lockExclusive（Session）对象表示获取共享锁，互斥锁的Session对象。同时Session通过locks记录获取锁的RegularTable。上锁时，按照共享和互斥锁锁兼容性判断，另外注意的是，在LOCK_MODE_READ_COMMITTED下，如果是单线程则不用获取share lock。如果无法获得锁，则进行sleep，同时检测超时、检测死锁，GC等操作。

死锁检测是一个DFS的算法，每次只允许一个session进行检测，具体为，将当前Session，A等待的RegularTable的lockShared，lockExclusive（即获得此表锁的Session）进行遍历，获取这些Session正在等待的表锁，然后递归遍历这些表锁的Session，如果遍历过程中，发现A，则表示死锁。另外注意为了避免堆栈溢出的死循环，要保存每次已经访问过的session，避免重复访问。

2、b-tree page的修改。

3、undo/redo日志。（用于recover）

4、Session的UndoLog（用于rollback）
Session.log()



=======================================================================================================================
***********************************************************************************************************************


                                                     Delete


***********************************************************************************************************************
=======================================================================================================================

delete from test4 where id > 1000

流程：
1、Parser解析
2、Delete.prepare()，condition优化，计算cost最小的plan。
3、Delete.update()执行命令。


Delete.update()
首先获取test4表的互斥锁，然后查询test4表所有符合condition的rows（如果数据量太大，保存到临时文件。这里把文件按照FILE_BLOCK_SIZE，16字节划分，写入读取大小都按FILE_BLOCK_SIZE整数，批量、对齐的IO操作可以提高效率 https://www.percona.com/blog/2011/06/09/aligning-io-on-a-hard-disk-raid-the-theory/，RAID，文件系统分块等原因）。然后遍历rows，逐个执行RegularTable.removeRow删除，并且记录到Session的undo日志。最后还要注意一些触发器以及限制的判断。

RegularTable.removeRow()
逻辑上和addRow类似，只不过这里需要倒序遍历index（防止在遍历索引删除过程中出错，则需要重新遍历索引插入该row，如果顺序遍历，则再次插入row的时候，rowKey会改变，这样会影响后续Index的再次插入），执行index.remove()删除row。另外在最后执行analyzeIfRequired()更新统计数据。

index.remove()
------
PageBtreeIndex
如果只剩下一个row，则清空所有的页面，创建一个空的PageBtreeLeaf更新PageStore。多于一个row时，调用rootPage.remove()，然后rowCount--。

PageBtreeLeaf.remove()
二分查找删除的row，PageLog记录undo日志，然后从内存数据data中覆盖该row，然后从offsets、rows数组中删除该元素，调用PageStore.update()更新缓存。如果删除的row是最后的那个row，也就是key最大的，就要返回删除后最大row（如果删除后为empty page，则返回删除的row），让父page修改对应的结点（父page保存的都是leaf page中最大的key）。否则返回null。

PageBtreeNode.remove()
同样是一个递归删除。二分查找删除的row的page，PageLog记录undo日志，然后调用该子page.remove()，如果返回null，则证明最大key不需要修改，返回null表示本page也不需要修改。如果返回的row和删除的row一致，证明子page变为空page，这时释放子page，同时删除对应的key，然后同样需要判断删除后是否empty，末尾key是否改变。如果返回的row和删除不一致，则需要修改对应的key为返回的row的key。最后调用PageStore.update()更新缓存。
问题：没有实现page合并！

PageDataIndex
流程基本和PageBtreeIndex一致。除了要注意CLOB等大对象需要往session注册unlink，并且在最后要往PageLog添加remove该row的undo日志。

PageDataLeaf.remove()
流程基本和PageBtreeLeaf一致。同时注意释放Overflow page。


=======================================================================================================================
***********************************************************************************************************************


                                                     Update


***********************************************************************************************************************
=======================================================================================================================

流程：
1、Parser解析
2、Update.prepare()，condition优化，计算cost最小的plan，优化update中set的表达式
3、Update.update()执行命令。

Update.update()
采用先delete后insert的做法，实现简单，但效率低。

注意：
1.注释提示自身参照完整性在多行更新以及条件反转（update is multi-row and 'inversed' the condition）的时候失效？测试不出问题。
2.考虑实现in-place update。避免所有indexes都要更新


=======================================================================================================================
***********************************************************************************************************************


                                                     Recover


***********************************************************************************************************************
=======================================================================================================================
日志恢复机制。 steal, no-force缓存策略，因此需要undo/redo操作.

begin;
insert into test3 select max(id) + 1, 15, 15 from test3;
commit;

begin;
insert into test3 select max(id) + 1, 15, 15 from test3;
delete from test3 where id >= 15


----------------------------------
PageLog机制(undo/redo日志)
-----------------------------------
1.每次对表进行insert、delete、truncate操作时，都会写入undo/redo日志。
2.undo日志写入的数据是修改前Page的全部data，
3.redo日志写入的是insert，delete操作的row的相关数据（ADD，REMOVE日志），也就是逻辑日志。第一次写入redo日志的时候，Session会记录当前的logID，也就是checkpoint的位置，commit的时候置回无效值-1。
4.checkpoint机制，定期删除多余日志记录，避免日志过长导致recover时间过长。

5.DropTable、CreateTable等非事务命令(DDL)，在执行完成后会直接commit


理论：
<<数据库系统实现>>提到undo/redo日志实现如下：
..添加undo日志为修改前数据，redo日志为修改后的记录
..修改记录的内存数据
..刷新undo/redo日志到硬盘
..刷新记录的内存数据到硬盘/刷新commit日志到硬盘（两个顺序不限）

checkpoint机制：
记录在checkpoint时刻没有提交的事务ID，写入start记录，将所有缓冲区修改过的page写入硬盘（不要求必须是提交事务写过的page），写入end记录，刷新日志。

问题：每次commit就执行flush会造成大量的IO，并且由于硬盘的转速限制，写入量过大则会限制写入速度。另外，市面上的硬盘都会有自己的buffer，flush并不会真正写入到介质上，断电后一样会丢失（除非是不间断电源UPS）。

实现：
H2的默认实现采用了commit事务延迟写（大部分数据库都支持的特性），具体如下：
添加undo日志PageStore.logUndo()，修改记录的内存数据PageStore.update()，添加commit日志PageStore.commit()。
...记录刷新：
只在checkpoint的时候刷新到硬盘上。
...undo日志刷新：
WriterThread定时刷新undo/redo日志，默认500ms刷新一次。另外可以设置WRITE_DELAY（commit和flush之间最大延迟，实际上是WriterThread的延迟间隔）使每次commit执行flush。
另外注意，刷新的undo/redo日志使用了synchronized同步，因此会影响正在写入undo/redo日志的事务的执行。

checkpoint机制：
每次PageStore.commit()的时候，都会检查undo日志大小，超过一定大小（默认阀值DEFAULT_MAX_LOG_SIZE，16MB）则调用PageStore.checkpoint()。主要目的是清除不必要的日志，具体是找出当前所有正在连接的session的当前没有提交事务的最小logID，logID指定某个checkpoint的位置，删除这个checkpoint之前所有的日志即可。要注意必须首先writeback所有修改过的记录的页面到硬盘，才能进行日志删除操作，这样才能确保已经提交的记录持久化。

总结：commit延迟写机制可以减轻IO，提高性能，但提高了丢失数据的风险，事实上undo/redo日志的实现保证在延迟刷新的时间内，最多只有一个page的数据保留在内存中（参见字节流写入机制），因此最多只有一个page的undo/redo日志数据丢失。由于使用的是undo/redo日志，因此记录刷新不用强制要求在commit的时候执行，H2规定只在checkpoint的时候执行，批量的page延迟写入能避免插入过程产生大量IO。

PageStore成员变量。
PageLog属于undo/redo机制，需要不断地写入日志数据，利用PageOutputStream完成底层写入操作。另外如下类型页面都需要添加undo log：
TYPE_DATA_LEAF = 1;      //A data leaf page (without overflow: + FLAG_LAST)
TYPE_DATA_NODE = 2;      //A data node page (never has overflow pages).
TYPE_DATA_OVERFLOW = 3;  //A data overflow page (the last page: + FLAG_LAST).
TYPE_BTREE_LEAF = 4;     //A b-tree leaf page (without overflow: + FLAG_LAST).
TYPE_BTREE_NODE = 5;     //A b-tree node page (never has overflow pages).
TYPE_FREE_LIST = 6;      //A page containing a list of free pages (the last page: + FLAG_LAST).


*初始化
PageLog的初始化过程在Database的初始化中。PageLog的初始化步骤包括读初始化openForReading和写初始化openForWriting，读初始化只是记录第一个trunk page和data page，写初始化需要涉及trunk page和data page的分配。

写初始化PageLog.openForWriting：
-PageStore分配一个页面作为logFirstTrunkPage，也就是PageLog的第一个trunk page；
-初始化输出流PageOutputStream。new PageOutputStream(...)
-输出流预留1字节。产生data page以及下一个trunk page的分配。
-PageStore.setLogFirstPage。PageStore把第一个trunk page，logFirstTrunkPage以及第一个data page，logFirstDataPage记录记录在页面头中，然后写入磁盘
-初始化writeBuffer。初始化PageLog自身的writeBuffer。

*添加undo log
对于每个添加undo log的页面，在checkpoint之间只写入一次。
-PageStore.logUndo()。入口函数在PageStore.logUndo()。利用bit数组判断对应的页面是否已经刷新到硬盘上，如果没有刷新，则把PageStore转换为写模式（初始化的时候为读模式，PageStore.openForWriting()，一般情况下，初始化转换为写模式，此后不需要转化。）

PageStore.openForWriting()转换写模式。
-首先PageLog.free()释放PageLog分配的页面。然后重新分配新的页面作为日志的第一个trunk page，logFirstTrunkPage。
-调用PageLog.openForWriting重新初始化PageLog。
-调用checkpoint()。具体见下

*CheckPoint
入口在PageStore.checkpoint()：首先database.checkPowerOff()，然后把PageStore保存的索引逐个写入rowCount大小（刚初始化的时候，只有PAGE_INDEX表的索引）；
..调用PageLog.checkpoint()，首先在PageOutputStream写入1字节大小的check point标记，然后把已写入undo页面BitField标记清空（表明所有页面可以再次开始写入undo日志），logSectionId加一（把undo日志按照每个check point进行分割，两个check point之间的位置以logSectionId标记），flush掉PageOutputStream（把当前的data page写入硬盘）。重新预留并分配新的data page。把新的logSectionId和新的data page的id保存到logSectionPageMap中。
..writeBack()回写。把PageStore的内存cache中已经修改过的页面写回硬盘。
..清理多余的undo日志。首先获取连接到数据库的所有session中第一个没有被提交的事务的sectionID（对应undo日志上的logSectionId），然后PageLog.removeUntil()进行删除操作：具体是首先从logSectionPageMap获取对应的sectionID对应的data page, firstDataPageToKeep，然后从firstTrunkPage的trunk page开始一直删除到包含该firstDataPageToKeep的trunk page为止，具体是往undo日志写入要释放的pages的id，然后从PageStore的缓存中去掉这些页面，同时添加到PageStore的freeList。最后返回剩下的第一个trunk page作为firstTrunkPage。PageStore重新设置firstTrunkPage, firstDataPageToKeep为当前的trunk page和data page。清空logSectionPageMap中多余的logSectionID。（undo日志、freeList page都可能被修改）
before: trunk1, data1, data2... trunk2, data21, data22, ... trunk3, data31, data32, data_firstDataPageToKeep
after:  trunk3, data31, data32, data_firstDataPageToKeep
..再次writeBack()。把freeList在之前的修改刷新到硬盘中。
..再次PageLog.checkpoint()。确保undo日志写入硬盘。
..清空硬盘空闲页数据。从PAGE_ID_FREE_LIST_ROOT（值为3）开始到PageStore的所有页，逐个通过FreeList判断查看是否在中使用，如果已经使用freed标记置为false；如果没有使用，则往该页写入0，freed置为true。


数据库恢复recover
------
PageStore.recover()
初始化数据库的时候调用。数据库突然崩溃，重启的时候，recover需要使其恢复到崩溃前的状态，尽量恢复已提交事务的数据。

流程：
1. RECOVERY_STAGE_UNDO阶段。
从没有脏数据的checkpoint开始！保证undo能避免所有没提交事务的脏数据。checkpoint位置记录在文件头中！

顺序读取undo/redo日志，对不同类型的日志进行处理：
UNDO。则把page的data读出，解压后，写入硬盘。注意尽管多个checkpoint阶段中，同一page出现多次，但UNDO中一个page只写一次。
CHECKPOINT。logId++，记录checkpoint的次数。
COMMIT。保存当前commit日志的sessionId, logId, pos。sessionId是commit的session的id，pos是当前日志的位移。
ADD。如果添加的是index root page的记录，则预留该页面，避免后面redo被分配。（TODO）
REMOVE/TRUNCATE。忽略。
ROLLBACK。忽略。
PREPARE_COMMIT。记录sessionId，transaction名字，当前日志的dataPage id。
1.1 分配之前预留的页面
2. RECOVERY_STAGE_ALLOCATE阶段。
读取undo/redo日志，记录这些日志分配的所有页面。
2.1 重新读取meta数据（包含所有RegularTable以及相关index和index root page），等待redo阶段操作。
3. RECOVERY_STAGE_REDO阶段。
与undo阶段类似，顺序读取undo/redo日志，但对不同类型的日志需要进行redo处理：
UNDO。则把page的data读出后，忽略。
CHECKPOINT。logId++，记录checkpoint的次数。
COMMIT。忽略
ADD。根据UNDO阶段保存commit的记录，判断当前日志的session是否已经提交，如果已提交，则redo一次add操作，否则忽略。
REMOVE/TRUNCATE。与ADD类似，判断session是否提交，已提交则redo操作，否则忽略。
ROLLBACK。忽略。
PREPARE_COMMIT。忽略
注意redo阶段不会写入undo/redo日志（FreeList除外），但修改的page仍然在缓存中。
4.清理。
removeUntil清理多余日志记录，清理临时index，释放UNDO阶段的预留页，writeBack把缓存中修改的页回写到硬盘（包括FreeList页）。清空其它数据结构


总结：修改的记录只在checkpoint、或者缓存超过阈值才进行刷新，而且undo/redo日志也使用延迟写机制，这些措施都尽可能减小了IO，提高写入性能。与ARIES相比，采用了恢复到checkpoint状态，然后重新redo成功commit的事务，由于add和delete row操作都是幂等的，所以不需要使用LSN保证操作只应用一次，也不需要使用CLR使rollback只执行一次。另外，checkpoint由于限制在没有脏数据的checkpoint，因此不一定是最近的一个checkpoint，因此如果有长事务，recover则可能需要跨越多个checkpoint。



字节流写入
------
写入byte数组流（目前只有PageLog使用），要利用PageOutputStream写入，类型包括TYPE_STREAM_TRUNK和TYPE_STREAM_DATA
对于undo日志，recover的时候顺序IO能够提升性能，因此一般分配页面的时候尽可能地分配顺序页面，这可以通过一次过分配多个顺序页面，进行预留操作实现。
更 重要的是，日志是顺序写入的，在正常事务处理中，能够提高IO性能。


*Page页面结构
TYPE_STREAM_TRUNK   （包含TYPE_STREAM_DATA的id，可以包含(pageSize - DATA_START) / 4个TYPE_STREAM_DATA，以及下一个TYPE_STREAM_TRUNK的id）
TYPE_STREAM_DATA    （包含数据流的数据，最高可容纳pageSize - DATA_START个字节）
TYPE_STREAM_DATA
TYPE_STREAM_DATA
......
TYPE_STREAM_TRUNK
TYPE_STREAM_DATA
TYPE_STREAM_DATA

*PageOutputStream
  PageStreamData data;      内存byte数组Data的封装。
  IntArray reservedPages;   预留页的id数组
  PageStreamTrunk trunk;    负责保留管理多个pageIDs的数据

*write()方法负责把数据写入到文件。
写入前进行预留操作，具体是调用reserve()，根据写入数据大小预留一定的page页面（预留策略见下）。接着开始往data page写数据，data page会分配好一个页面大小的buffer，然后往buffer写数据（页面头已经写入）。如果数据太大超出data page的buffer，则把当前data page写入磁盘，然后从PageStreamTrunk中分配新的data page（一般已经预留足够），继续进行写入操作。如果trunk page可以保存的data page也写完，则会从之前预留的页面里拿出一页作为新的trunk page，再开始分配data page。这里注意到，由于每次写之前都进行好预留操作，因此不用担心预留页面不足，需要向PageStore重新分配影响写性能。

*reserve()预留操作。以trunk page能够保存的页面为单位进行分配。
先计算trunk Page可以保存多少页面（页面字节大小为2048 - 页面头，则能分配507个），然后计算这些页面总共可以保存多少字节（2048-页面头），如果总共保存字节大于预留字节（这里为1字节），则请求PageStore分配这些页面＋1个trunk page（作为下一个trunk page，总共508页）；初始化trunk page对象PageStremTrunk以及data page对象PageStreamData。初始化trunk page的页面头，并且写入磁盘。




=======================================================================================================================
***********************************************************************************************************************


                                                    Transaction


***********************************************************************************************************************
=======================================================================================================================

MULTI_THREADED
------
开发阶段特性。可以让连接的session同时执行statement。默认下同时只能有一个session对同一个database执行statement。


Transaction Isolation
------
H2只支持三种事务隔离等级：
Read Committed（默认）。
  读不需要加锁，但在MULTI_THREADED下会加锁，但在statement结束时释放。写要求一直持有锁，直到事务提交后一次释放所有锁。
Serializable
  读和写都要加锁，直到事务提交后一次释放所有锁。
Read Uncommitted
  不加任何锁。

问题：
Dirty Reads。脏读。
  读取了任何没提交事务的修改。另外脏读还可能导致级联回滚问题。只有Read Uncommitted发生。

Non-Repeatable Reads。非可重复读。
  同一事务中，多次读取同一row可能读取到不同的已提交事务修改的值。只有Read Uncommitted，Read Committed发生。

Phantom Reads。幻读。
  同一事务中，用同一condition多次读取table，可能读取到已提交事务新插入的值。只有Read Uncommitted，Read Committed发生。

另外还可能出现覆写问题。
  也就是事务A首先写入row，事务B接着写入row，此时事务A回滚，这时row会被修改为A写入前的值，也就是事务B的修改丢失。只有Read Uncommitted发生。


Table Level Locking
------
事务采用二阶段封锁＋表锁实现事务并发控制。避免脏读，覆写等问题。
实现通过Table记录所有获得共享锁以及互斥锁的session，以及session记录获得表锁的所有Table。
死锁检测就是DFS算法遍历查找。

UndoLog
------
事务的rollback主要依靠Session的UndoLog来实现。Session的UndoLog区别于PageLog的undo/redo日志，由于undo/redo日志为了防止数据丢失，必须定时刷新到硬盘上，因此使用专门的UndoLog可以避免事务rollback时产生不必要的IO。

RegularTable插入／删除row后，往Session添加undo日志，记录的是插入的row（PageLog是插入前添加undo日志，记录的是修改前的page数据），如果undo日志条数过多，则会写入临时文件。
commit，直接把之前插入的undo日志删除。
rollback，从最后开始，倒序遍历undo日志（如果日志保存在临时文件，则批量导入部分undo日志到内存），然后根据日志记录的操作执行反操作（如Inser则delete，delete则insert），然后删除多余的undo日志。由于修改了记录，因此最后还需要执行PageLog.commit添加PageLog的undo日志。


Two Phase Commit
------
PREPARE_COMMIT是2 phase commit的预提交，可用于分布式事务。参考MySQL的xa事务。
Session进行PREPARE_COMMIT后，如果客户端断开连接，则数据库会rollback该事务。如果是数据库崩溃，则数据库重启后会恢复该事务为IN_DOUBT状态。
然后执行COMMIT TRANSACTION transactionName或ROLLBACK TRANSACTION transactionName，进行事务提交或rollback。

*The database needs to be closed and re-opened to apply the changes*
如果数据库崩溃过后恢复，在recover过程发现存在IN_DOUBT事务，则设置database为readonly。此时必须commit或rollback该IN_DOUBT事务。然后重启数据库才能生效。这是因为重新提交往PageLog写入commit日志，recover的时候则会恢复该事务。

问题：
过程需要强制重启数据库，是否有更好的实现？


Multi-Version Concurrency Control (MVCC)
------
"MVCC=TRUE;AUTOCOMMIT=OFF"
database.isMultiVersion() == true

delete, insert and update使用共享的表锁；
添加或删除列、drop table、select...for update等DDL使用互斥表锁；
如果未提交事务写入row，其它Session读取的是该row的写入前的值。
只有提交的数据，才能被其它Session读取。
多个Session更新同一row，会等待，直到其它Session commit或者超时。


理论对比：
在《数据库系统实现》中，实现的是串行化的MVCC，每个Row都有读时间戳RT，写时间戳WT，是否提交位变量C，另外还会保存未提交事务修改前的旧版本Row。
根据读写时间戳的大小判断请求是否可行。另外读还会查找旧版本符合的Row。

H2实现的是read commited的MVCC，每个Row都有delete位变量，sessionID记录未提交事务的id，还有version避免相同row插入delta，也有保存未提交事务修改导致的差异delta。
由于是read committed，没有严格考虑事务先后发生顺序，如两个没提交事务，后来的事务可以写入已经被前面事务读取的数据。要实现可序列化，需要使用时间戳实现MVCC。另外H2的MVCC有bug。
同时该MVCC对于写冲突的行为是乐观锁模式。


Database初始化MVCC=true时
recover阶段，MVCC设为false， because the multi-version index sometimes compares rows and the LOB storage is not yet available.
recover结束后，恢复到原来值。
RegularTable初始化index的时候，除了scanIndex，其它都被封装到MultiVersionIndex类中(PageBtreeIndex,PageDelegateIndex, etc)。


MultiVersionIndex封装了原来的二级索引，并且创建delta作为差异更新，delta的索引列和原来的二级索引一致，因此compareRows的时候只比较对应的索引列，另外compareKeys则会当key相同时，继续比较version，version越大则越小。
delta是TreeIndex（内存AVL树，AVL树是自平衡二叉搜索树，以发明者命名），add/remove的时候会自动进行balance操作，add会根据LL（右旋转）、RR（左旋转）、LR（下部分左旋转，整个部分右旋转）、RL（下部分右旋转，整个部分左旋转）进行结点旋转。remove的操作类似（但要注意remove的结点有left和right的时候）。H2的实现利用balance因子记录子树平衡情况，然后进行结点替换。

注意：这里采用AVL树保存Row数据，而不是类似B+树。Row数据作为键值保存到AVL树结点中。应该是考虑到delta数据量不大，能够放内存，更适合于BST树结构。

AVL树等BST树，是二叉树，每个结点只保存一个键值。适合于数据量较小，可以快速进行查找。可以进行balance操作，避免数据倾斜。
B+树是多叉树，目的是深度尽可能少，查找时减少IO。更适合于大量数据，需要与硬盘IO操作的情况。


Command.filterConcurrentUpdate()发现更新同一row，等待后重试，超时则抛出异常


1.Select
Select默认不加锁，如果已经存在互斥表锁，则需要等待。
候选index中包括MultiVersionIndex和PageDataIndex。两个Index分别实现了MVCC读写。MultiVersionIndex负责保证能够只读取事务已提交的数据。

Select的关键是对未提交事务的Insert和Delete（Update实现为Delete old + Insert new）的处理：
忽略Insert的，选择Delete前的。忽略Insert的可以靠Row的sessionId属性，对于Delete的，需要记录所有未提交事务Delete的row，也就是Delta。但如果同一事务先insert再delete同一row但仍不提交，只记录delete的row到delta是会导致其它事务会select了该row，因此必须add也同时添加到Delta，然后进行先删除后添加的判断（事实上仍然存有bug）。

PageDataIndex扫描查找：
PageDataIndex只应用于全表扫描。
PageDataCursor.next()
先遍历Iterator delta（PageDataIndex.delta.iterator()）。只Select其他未提交事务修改（sessionId不等于当前SessionId）且被删除的row（isDeleted() == true）。
然后遍历当前PageDataLeaf里包含的row。只Select出本事务修改的row或者其他事务已经提交的row。

问题：这次的遍历没有遵守key的从小到大？但问题不大，貌似SQL标准没规定。

MultiVersionIndex范围查找[first, last]：
让base索引和delta索引分别找到刚小于或等于first元素，然后把各自的Cursor组合到MultiVersionCursor进行逐个元素遍历。
MultiVersionCursor.next()
-首先通过TreeCursor遍历TreeIndex delta中的数据，指定范围为[first, last)，node为当前cursor位置。
TreeCursor遍历通过BST的next()（查找直接后继结点）,previous()（直接前继结点）的迭代实现。
next()首先迭代查找右子树中的最小结点，如果不存在右子树，则迭代查找父结点中非祖先结点右子树的结点。
previous()首先迭代查找左子树的最大结点，如果不存在左子树，则迭代查找父结点中非祖先结点左子树的结点。
-然后通过baseCursor遍历base中的数据。
baseCursor的multiversion为false，select出来的是所有row，包括未被提交事务修过的数据。

根据deltaRow和baseRow进行select，逻辑上保证不select其它未提交事务修过的数据。
0.首先按需要分别select出deltaRow和baseRow的数据
1.如果deltaRow为null，则表明当前没有未提交事务修改的row，则可以直接从baseRow找出数据。如果baseRow也为null，则没有符合的结果。
2.如果deltaRow的sessionId为当前sessionId，则表明为当前事务修改的数据，继续下面判断，如果delete为true，则重新从delta遍历。
3.如果baseRow为null，但deltaRow的delete为true，并且deltaRow的sessionId为当前sessionId，则最后一个元素被当前session删除，则没有符合结果。但如果deltaRow的sessionId不等，则是其它未提交session删除，select该row，下次从delta遍历
4.进行比较baseRow和deltaRow，把MultiVersionIndex的base索引进行其索引列部分的比较，如果相等，继续比较key。根据比较结果判断，如果相等，则判断是否被删除，如果被删除且是当前Session的修改，则抛出异常（还残留在base中），如果不是session的删除，就是insert的row，继续判断delta是否当前session的insert，如果是则select当前row，如果是其它session的insert，则忽略，重新遍历一次。

MultiVersionIndex的遍历遵守从小到大的顺序。


Insert
------
Insert same row？     由于Index中有相同key，抛出DuplicateKeyException异常
Inserted and delete？ Inserted无法被select
Inserted and update？ Inserted无法被select
same transcation？


Insert.update()
获取互斥锁，变为获取共享表锁。为了避免表元数据修改，所以要上锁，写是乐观并发的，所以是共享锁。
RegularTable.addRow()。直接把插入的row设置当前的SessionId ，表示当前session的修改row。
遍历该RegularTable的indexes，插入row：

PageDataIndex.add() 递归PageDataNode.addRowTry(), PageDataLeaf.addRowTry()(照常插入)
row.setDeleted(false);
初始化HashSet delta，如果delta存在该row（rollback），则删除，否则添加该row。
sessionRowCount添加sessionID和当前rowCount（计算rowCount用，另外还有rowCountDiff，rowCount两个变量。TODO）

MultiVersionIndex.add() 先调用base.add()，让内部的真正index添加row。如果delta不存在row并且row的sessionId不为0（创建索引的时候为0），则添加，如果存在同一row（rollback删除的row），则delta删除row，如果存在同一key和version的row，则把version＋1（removeIfExists）。


添加UndoLog。另外注意如果UndoLog无使用，commit所有index


Delete
------
Delete same row？    Delete的时候检查isDeleted()为true则抛出并发更新的异常
Deleted and insert？  没有提示异常？此时insert的事务select出两个相同primary key，deleted的事务不能rollback只能等待insert的事务rollback。BUG!
Deleted and update？  与Delete same row一样，抛出并发更新异常
same transcation？

Delete.update()
获取互斥锁，变为获取共享表锁。
Select出所有符合条件的row，添加到rowList。由于限制Select出未被提交事务修过的数据，因此不会存在并发更新问题。


RegularTable.removeRow()。然后要把插入的row设置当前SessionId，设置前检验是否被删除，或者已经存在的SessionId（rollback添加的row是同一id）但不是当前的SessionId，则是并发更新异常，需要等待重试插入。
逆序遍历该RegularTable的indexes，删除row：

MultiVersionIndex.remove()。先调用base.remove()，如果delta不存在row（第一次修改row），则添加，如果存在同一row（rollback添加的row），则delta删除row，如果存在同一key和version的row，则把version＋1（removeIfExists）。

PageDataIndex.remove()。递归删除。
row.setDeleted(true);
delta如果存在该row，则删除，否则添加该row。

添加UndoLog。


Update
------
Update same row？    第二次Update的时候由于Select的row是已经被deleted了，再次delete的时候抛出并发更新异常。
updated and delete？ Select了被delete的row，再delete抛出并发更新异常。
updated and insert？ Insert same row一样
same transcation？

Update.update()
获取互斥锁，变为获取共享表锁。
Select出所有更新的row，添加到rowList。

Table.updateRows()。把旧row调用removeRow删除，update的新row用addRow插入。
这里同样是delta的逻辑（存在即删除，不存在即添加）PageDataIndex的delta包含新旧两个row。
MultiVersionIndex的delta插入新row A时，如果找到和新row的key和version还有对应索引列一致的row B，但不是完全相等，为了区分插入时这两个row，则B的版本设置为A的版本+1。这样在delta添加B需要比较compareKeys的时候，version越大值越小，则B<A。

另外注意row的key是唯一的，因此delta里面A和B这样的key和version还有对应索引列一致的row最多只有两个（delete、insert产生）。


Commit
------
Session负责遍历UndoLog，让对应的RegularTable的所有索引commit每个修改的row，PageDataIndex.commit()负责删除delta中row的记录，MultiVersionIndex.commit()同样也是删除delta的记录。


限制：
不能和MULTI_THREADED共同使用；
UndoLog必须保留在内存里；
不能修改事务隔离等级（LOCK_MODE）



关闭Database
------
DataBaseCloser.run(), Database.close(), checkpoint, writeback, compact...


=======================================================================================================================
***********************************************************************************************************************


                                                    MVStore


***********************************************************************************************************************
=======================================================================================================================
"MV_STORE=TRUE;AUTOCOMMIT=OFF"
MV_STORE=TRUE的时候，默认设置Database.multiVersion=true

MV_STORE不能和FILE_LOCK=SERIALIZED共用。


=====================
      Features
=====================
**Maps
1.key lookup

2.fast index lookup
3.used like database table(key=>primary key, value=>row)/index(key=>index key, value=>primary key)

**Versions
access the current and old version
copy on write

**Transactions
0.read committed
1.savepoints
2.2pc
3.overhead is small

**TransactionStore

**Pluggable Data Types
Serialization pluggable
no length limits

**BLOB Support

**Concurrent Operations and Caching
LIRS cache, against scan  https://en.wikipedia.org/wiki/LIRS_caching_algorithm
NOT support concurrent modification
MVMapConcurrent support concurrent read, write must after first read
sharding to multiple maps support concurrent write

**Log Structured Storage
flush in (commit()/ per 1s in background/ more than a number of pages are modified)
no transaction log/undo log/in-place updates..

**compact
write only once, B-tree pages are always full for easily compressed.

**Off-Heap and Pluggable Storage  （OffHeapStore）
**Encrypted Files
**Metadata Map

设计上MVMap的接口已经考虑好Session的multi-thread并发修改，在需要的地方添加了synchronized关键字


=====================
      LIRS
=====================
    LIRS是对比访问Page的IRR判断块访问频率的cache替换算法。MVStore利用hash分片的方法进行扩展实现并发LIRS。H2使用多个Segment响应cache请求，每个Segment都是一个独立的LIRS实现。

总内存maxMemory默认为16MB内存，平均分配到16个Segment，每个Segment为1MB。averageMemory为每个entry内存估计，值固定为pageSplitSize / 2。
总内存利用平均分配，如果出现倾斜，会影响内存利用率，应该考虑某个Segment使用率较高时，会steal其它空闲的Segment，还有averageMemory为固定值，不能准确反映cache状况。

分配方法：
1.限制Segment数量segmentCount为2的乘幂
2.segmentMask = segmentCount - 1
3.segmentShift则为segmentCount的末尾0的个数，
4.通过以下算式映射hash值到不同的Segment中：
int segmentIndex = (hash >>> segmentShift) & segmentMask


LIRS主要的put，get，remove操作都是通过hash到具体的Segment进行操作。每个Segment都会进行必要的synchronized。
Segment
--Entry<V>[] entries;   Map容器，Hash映射Segment所有的entry，快速查找对应的entry
--Entry<V> stack;       LIRS栈
--Entry<V> queue;       驻cache的FIFO队列
--Entry<V> queue2;      非驻cache的FIFO队列（防止entry数量过多）

Entry数据结构主要用于保存key，value值以及链表结构的Prev，Next引用等。
    LIRS的链表是从头部入列元素，尾部出列元素，其实现使用了dummy node的做法：初始化stack/queue为dummy node，该dummy node的Prev作为链表尾部引用，引用尾部元素；Next作为链表头部引用，引用头部元素。初始化空链表时，Prev和Next均指向自己，这样插入和删除元素的时候，就不用显示去修改链表尾部引用和头部引用。


注意：由于MVStore采用COW，因此不需要在替换cache的时候刷新回硬盘，只要直接置null即可。

------
 Put
------
put(long key, int hash, V value, int memory)
1.删除原来key映射的entry
2.根据Key，Value构造Entry e，然后插入Map容器entries。
3.如果内存总量超过阈值，则需要找到cold entry替换出cache（evict方法）
4.新的entry e插入stack头部（所有的新entry，无论是cold或是hot都要插入）

evict(Entry<V> newCold)
1.驻cache的FIFO队列queue小于stack的1/32时（3.125%），把栈底部的hot entry转换为cold entry，也就是从栈删除并插入queue的头部，同时执行"栈裁剪"操作
2.把newCold插入queue的头部
3.当queue大小大于1时，循环把queue的尾部元素替换出cache，并同时插入到queue2中，直到可用内存小于阈值。如果queue2的大小*2超过栈大小，则循环remove queue2尾部元素。

对比起原论文中，这里的put实现了改进：
使用queue2记录了非驻cache的cold entry，当超过一定大小的时候，就会从queue2尾部（时间最长的cold entry）开始remove entry，，这样可以避免栈长度过大；

其它部分和论文描述几乎一致


------
Remove
------
remove(long key, int hash)
1.Map容器entries中通过hash映射到entry e
2.如果e在栈中，从栈中移除
3.如果是hot entry，则把queue中entry（驻cache的cold entry）的头部元素变为hot entry（先从queue中删除即可，如果已在栈S即可，否则还需要重新插入栈S的尾部）。这样是为了尽量保持hot entry的数量一致
4.如果是cold entry，则从queue/queue2中删除。
5.执行“栈裁剪”操作。

删除hot entry的时候，注意从queue中的cold entry变为为hot entry的操作。


------
 Get
------
get(long key, int hash)
1.利用Map容器entries通过hash映射到entry e
2.如果没找到e，或者e为非驻cache的cold entry，则返回null
3.否则就执行access(key, hash)，也就是尝试将e移动到栈或queue的顶部

access(key, hash)
1.利用Map容器entries通过hash映射到entry e
2.如果e是hot entry，并且不是位于栈头部元素，而且距离上次栈头部插入元素大于stackMoveDistance的时候，则会把e插入栈的头部，如果e是位于栈尾部，则执行“栈裁剪”操作
3.如果e是cold entry，首先从queue中删除e，然后如果e在栈中的话（这是一个把cold entry变为hot entry的操作），则需要把e先从栈删除，然后把栈底部的hot entry变为cold entry，如果e不在栈中，则重新插入queue的头部。最后再插入栈头部。

get可以算作一个访问操作，因此access操作中，需要把满足一定条件的entry重新插入栈/queue的头部。


总体上来看，H2的LIRS实现采用了hash分片锁同步的做法，加大并发，同时在每个Segmenet中采用queue2限制栈的大小。实现简洁，基本和原论文描述一致。



=====================
      初始化
=====================
MVTableEngine.init();  //builder模式，更规范

Database -> MVTableEngine.Store(负责保存映射tableName和MVTable的tableMap，初始化MVStore、TransactionStore的实例)

Database
--MVTableEngine.Store mvStore
  --ConcurrentHashMap tableMap
  --TransactionStore transactionStore
    --MVStore store
  --MVStore store
    --MVMapConcurrent meta
    --CacheLongKeyLIRS cache
    --FileStore fileStore


===========
file format
===========
File Header 1
File Header 2
Chunk
-->header
-->Page
-->Page
-->Page
-->footer
Chunk
-->header
-->Page
-->Page
-->Page
-->footer
Chunk
-->header
-->Page
-->Page
-->Page
-->footer


File Header
--
H:2,block:5,blockSize:1000,chunk:d9,created:152cb564ddd,format:1,version:d9,fletcher:21ec9357

H: The entry "H:2" stands for the the H2 database.
block: The block number where one of the newest chunks starts (but not necessarily the newest).
blockSize: The block size of the file; currently always hex 1000, which is decimal 4096, to match the disk sector length of modern hard disks.
chunk: The chunk id, which is normally the same value as the version; however, the chunk id might roll over to 0, while the version doesn't.
created: The number of milliseconds since 1970 when the file was created.
format: The file format number. Currently 1.
version: The version number of the chunk.
fletcher: The Fletcher-32 checksum of the header.

Chunk
--
每个版本一个Chunk。包含Header，Page和footer。Page包含map的数据。一次写完一个Chunk？

Header:
chunk:d9,block:5,len:1,map:10,max:840,next:4,pages:2,root:364000003658,time:d1b16295,version:d9

Footer:
chunk:d9,block:5,version:d9,fletcher:c9d0c6e1

chunk: The chunk id.
block: The first block of the chunk (multiply by the block size to get the position in the file).
len: The size of the chunk in number of blocks.
map: The id of the newest map; incremented when a new map is created.
max: The sum of all maximum page sizes (see page format).
next: The predicted start block of the next chunk.
pages: The number of pages in the chunk.
root: The position of the metadata root page (see page format).
time: The time the chunk was written, in milliseconds after the file was created.
version: The version this chunk represents.
fletcher: The checksum of the footer.
livePages:

root pos 64bit
26 bits for the chunk id, 32 bits for the offset within the chunk, 5 bits for the length code, 1 bit for the page type (leaf or internal node).
chunkId = pos >>> 38
pageOffset = pos >> 6
pageMaxLength = ...

getPagePos(int chunkId, int offset, int length, int type)


Page:
length (int): Length of the page in bytes.
checksum (short): Checksum (chunk id xor offset within the chunk xor page length).
mapId (variable size int): The id of the map this page belongs to.
len (variable size int): The number of keys in the page.
type (byte): The page type (0 for leaf page, 1 for internal node; plus 2 if the keys and values are compressed).
children (array of long; internal nodes only): The position of the children.
childCounts (array of variable size long; internal nodes only): The total number of entries for the given child page.
keys (byte array): All keys, stored depending on the data type.
values (byte array; leaf pages only): All values, stored depending on the data type.


=========
 MVStore
=========
多版本存储引擎。提供MVMap等接口保存数据。

0.元数据
MVMapConcurrent<String, String> meta           负责记录每个MVMap的元数据。包括id，name，page root的pos，config(name,type还有createVersion，为第一次创建MVMap的时候MVStore.currentVersion的值)
ConcurrentHashMap<Integer, MVMap<?, ?>> maps   缓存id和对应的MVMap

1.首先根据config进行部分的初始化。

2.然后打开文件，读取文件头初始化元数据:
readFileHeader()
--
读取文件头的时候初始化meta，文件头大致如下：H:2,block:5,blockSize:1000,chunk:d9,created:152cb564ddd,format:1,version:d9,fletcher:21ec9357
MVStore.readFileHeader()
1.重复读取两个文件头。每个文件头处理一致：读取文件头到bytebuffer；计算文件头的fletcher32校验和，查看结果值和文件头的fletcher值是否相等；保存属性version为newestVersion，block为chunkBlock，created为creationTime；校验创建时间戳creationTime。
2.readChunkFooter()读取文件最后的Chunk footer。最后的Chunk的版本应该是最新的，因此当该Chunk的version大于文件头的newestVersion时，newestVersion和chunkBlock更新为该chunk的对应值。
3.循环读取chunk的header和footer，根据chunk的header.next不断读取下一个chunk，直到最后一个chunk，即lastChunk。
readChunkHeader()读取chunkBlock*BLOCK_SIZE偏移的Chunk header。readChunkFooter()读取chunk的footer。
4.设置meta的MVMap的version为lastChunk的version后，调用meta.setRootPos(lastChunk.metaRootPos, -1)，从lastChunk.metaRootPos读取page为meta的root page
5.查找meta中的"chunk."开头的key，记录的是所有chunk的header。然后把所有的Chunk.id, Chunk键值对存放到ConcurrentHashMap chunks中。
6.遍历chunks中所有chunk，如果Chunk.pageCountLive为0，调用registerFreePage注册空的Chunk，否则fileStore记录chunk为已用空间。
--

3.setAutoCommitDelay()初始化后台线程BackgroundWriterThread，该后台线程将会定时进行MVStore的commit操作，即把所有相关的MVMap的内容都刷新到硬盘上


MVStore的元数据meta：
name.NAME -> id     NAME包括表table.id，二级索引index.id，恢复日志undoLog，openTransactions
map.ID    -> config
root.ID   -> pos
chunk.ID  -> chunk信息  保存所有Chunk的Header


主要用于对应MVMap的元数据，也就是底层数据的保存（包括SYS表）。

用户表/视图，二级索引等数据库对象需要SYS表保存具体的table的元数据，然后遍历SYS表读取id，objectType, 以及DDL SQL

openMap(name, builder)
读取meta的内容，根据name获取对应的MVMap，如果不存在，创建MVMap，初始化相关的version，root page。writeVersion初始化为MVStore.currentVersion
root的Page的version初始化为-1


------
commit
------
Page root在commit之间只有一个writeVersion，期间多次修改只会有一个version的root

BackgroundWriterThread.run()
MVStore.commitInBackground()

1. MVMap.put()之后，root的Page进行了COW操作，这样会更新root的引用为新Page，该Page的version为writeVersion（就是MVStore进行openMap时的currentVersion）。MVMap的root的Page引用为volatile。这样后台线程就可以看到新的root的Page引用。

2. hasUnsavedChanges()。判断MVStore相关数据是否有修改。
  首先如果metaChanged为true，即元数据被修改则直接返回true。否则继续遍历所有maps保存的所有MVMap（openMap打开的MVMap都会保存在maps），调用MVMap.getVersion()，也就是root.getVersion()，如果进行了COW操作，root的Version就等于writeVersion，此值>=0 && > lastStoredVersion时则返回true。也就是修改过就会返回true。

3. commitAndSave()。
  防止commit过程无穷递归，如果currentStoreVersion >= 0则直接返回，否则后面currentStoreVersion = currentVersion。另外还有一些sanity check。

4. storeNow()。把MVMap从上次commit后开始到这次commit时修改的数据flush到硬盘上。

 0.首先执行一些版本的相关修改：
  storeVersion = currentVersion    (storeVersion为当前commit的版本)
  version = ++currentVersion       (version为当前版本currentVersion自增，也就是下次commit的版本)
  lastStoredVersion 为上次store的版本 = currentVersion - 1;    (lastStoredVersion为上次commit的版本，每次commit后被赋值)
  lastChunk为最后，也是最新的Chunk块（MVStore初始化中赋值，storeNow最后也会更新为写入的新Chunk）

 1. 创建新的Chunk，其version值为++currentVersion，其chunkId为从lastChunk递增开始分配，保证不超过最大值Chunk.MAX_ID，并且不与已经存在的Chunk的chunkId重复。
 2. 遍历所有关联的MVMap，调用MVMap.setWriteVersion(version)更新到最新版本，注意此时开始，MVMap后续的修改只在下次commit的时候刷新到硬盘。
    判断哪些是修改过的MVMap。如果MVMap.getCreateVersion() > storeVersion，则表明在store开始后才创建的MVMap，跳过此MVMap。
    如果MVMap.getVersion() > 0 && >= lastStoredVersion，即表示MVMap的当前root版本是在上次commit到本次commit之间经过COW。注意，store过程中Session线程可能会修改MVMap，MVStore只把当前storeVersion版本的修改写入硬盘。
    如果此时Session线程对MVMap从上次commit开始的修改还在继续，则需要调用MVMap.waitUntilWritten(storeVersion)等待修改完成。注意这是一个多线程同步，实现其实很简单：MVMap的修改过程中，beforeWrite()会currentWriteVersion = writeVersion和afterWrite()方法currentWriteVersion = -1。这样waitUntilWritten就不断进行while判断currentWriteVersion == storeVersion，则调用Thread.yield()让当前store线程让出控制，进入等待状态。注意这里的writeVersion在之前被赋值下次commit的版本version，因此这里的判断可以保证只会等待当前版本修改完成。
    完成同步后，则调用MVMap.openVersion(storeVersion)，复制一个readOnly并且root的版本为storeVersion的MVMap，如果此MVMap.getRoot().getPos() == 0，也就是该root还没有被写入硬盘（Page写入硬盘后pos != 0），则添加到数组changed中，稍后写入硬盘。

  3.遍历changed，先把MVMap的root page信息插入meta中，key为root.ID，value为pos，如果Page.getTotalCount() == 0则默认为0（不会写入buffer，所以pos为0），否则为Long.MAX_VALUE(下面写入buffer后，有效pos值覆盖这个)。
  
  4.调用applyFreedSpace(storeVersion, time)。把之前需要删除Page的时候，调用registerFreePage注册到freedPageSpace的数据进行检测。如果发现某个Chunk当前版本中maxLenLive为0，也就是没有数据，并且Chunk的创建时间至今已经超过retentionTime，则返回符合要求的Chunk，保存到removedChunks，等待删除。否则更新meta中该chunk的数据。

  5.遍历Changed的MVMap，如果root的getTotalCount() > 0，则表示MVMap有数据，然后调用Page.writeUnsavedRecursive(Chunk, buff)把全部Page的数据按照DFS写入buffer中，写入Buffer后，Page.pos就有值（chunkId, start, pageLength, type合并的long值）。注意如果写入buffer前，pos!=0(已经写入过硬盘)，则不会写入（每个Page只会写入一次）。把这个pos值写入meta中对应key为root.ID的value值。

  6.meta.setWriteVersion(version)更新meta版本为version，即下一次commit的版本。然后把meta的root调用writeUnsavedRecursive写入Buff中。（meta写入到Chunk的最后）

  7.在文件中分配位置写入buffer。reuseSpace默认为true，则调用FileStore.allocate(length)在文件中找寻适合buffer大小的空间，否则reuseSpace为false，则直接写到文件最后。找到的位置为filePos。

  8.调用FileStore.free()释放removedChunks的空间(事实上只是BitSet置空，并没有在文件上进行删除操作)，分配完buffer的写入位置filePos后才释放空间，这样可以避免覆盖旧数据，从而避免写入失败导致数据丢失。

  9.如果reuseSpace为false，即写入的是文件最后，这时调用FileStore.markUsed(end,length)标记空间已经使用。

  10.按照本Chunk的大小，也就是包含block的数量，使用FileStore.allocate进行分配，预测下一个block的filePos，赋值给Chunk.next

  11.把Chunk的Header写入buffer；然后调用revertTemp()释放freedPageSpace相关数据以及对所有MVMap.removeUnusedOldVersions()删除旧版本的root（采用复制list来避免加锁同步，但考虑到commit和put可并发，由于commit期间只有一个version，root会缓存，因此同步正确）；最后写入Chunk的footer到buffer。

  12.FileStore.writeFully()把buffer写到filePos的起始位置。

  13.根据需要判断是否重写FileHeader。

  14.如果写入的buffer不是在文件最后，则shrinkFileIfPossible()，收缩文件大小（由于之前删除过removedChunks）

  15.遍历changed的MVMap，调用MVMap.writeEnd()，清空MVMap所有缓存的childrenPages引用（已经写入硬盘，Page.getPos() != 0）。调用metaRoot.writeEnd()。这样下次读取需要从硬盘重新读取子Page。相当于清理Page的cache数据。

  16.更新unsavedPageCount，metaChanged，lastStoredVersion变量。

freedPageSpace记录maxLenLive，pageCountLive

------
rollback
------
rollbackTo(version)

1.如果version == 0，则清空meta，chunks，maps，freedPageSpace的数据，并且清空文件内容。

2.遍历maps，调用MVMap.rollbackTo(version)，迭代MVMap.oldRoots，把大于等于version的Page删掉。

3.删除freedPageSpace里从currentVersion到version的数据

4.meta.rollbackTo(version)，回滚meta

5.从lastChunk开始，递减ChunkId，找出第一个Chunk.version小于version的Chunk removeChunksNewerThan （commit的时候，Chunk分配是循环递增id的，见步骤1）

6.如果找到removeChunksNewerThan，则从lastChunk开始递减id到removeChunksNewerThan，清理这些Chunk（写入0覆盖文件）。然后重新写文件头，读取新文件头

7.然后遍历maps，如果MVMap的创建版本getCreateVersion() >= version，则删除MVMap，否则如果之前的步骤清理过Chunk，则重新读取meta的root数据，从硬盘读取对应的root数据

8.更新lastChunk.id - 1的ChunkId的信息到meta。（可能会被回滚了？）

9.更新currentVersion，setWriteVersion(version)更新meta和所有MVMap的version。

------
compact
------
compact(int targetFillRate, int minSaving)
0.首先判断compact后是否满足目标填充率targetFillRate, 以及最小节省Page数量minSaving。
fillRate = (int) (100 * maxLengthLiveSum / maxLengthSum)，如果fillRate已经>=targetFillRate，则直接返回。
minSaving为所有old trunk（创建时间到当前时间超出了保存时间retain（默认为45s）），所有非活跃Page的数量，如果<minSaving，则直接返回。
找出所有要清理的Chunk保存到old。

1.遍历old，分别调用copyLive()。
copyLive首先重新遍历Chunk的所有Page，每个Page重新找回对应的MVMap，然后遍历Page的所有key，如果MVMap从key找回的Page存在old中，则删除该key后再重新插入，这样就等于把该Page创建当前版本的copy。

2.最后调用commitAndSave()。重新写入新的trunk，并且删除旧的空Chunk。


------
open old version
------
MVMap.openVersion(long version)

如果version比root（MVMap保存的最新版本的B+树的root）要大，则创建readOnly的MVMap m，并设置m.root = root;
否则二分法查找oldRoots保存的旧版本的root，找到指定root则返回readOnly的MVMap为该root，找不到root，则调用MVStore.openMapVersion(long version, int mapId, MVMap<?, ?> template)查找，该方法首先从硬盘读取旧版本version的meta数据oldMeta，然后从oldMeta中读取mapId指定的rootPos，最后创建readOnly的MVMap，并设置rootPos和version为旧版本的数据。



注意：
1.没有recover，即没有undo/redo。因为缓冲是No steal,Force策略
2.每个chunk在commit的时候只有两次写的操作：一次是新的chunk写入文件，一次是文件头的更改，令其指向新的chunk。

3.要注意防止文件碎片化和压缩处理等。


Map:
===========
MVMap<K, V>
===========

volatile Page root;                         
volatile long writeVersion;                 version used for writing
volatile long currentWriteVersion = -1;     version is set during a write operation
int id;                                     map id init by MVStore.openMap
long createVersion;                         version is set by MVStore.openMap when creating
final DataType keyType;
final DataType valueType;
ArrayList<Page> oldRoots                    store old root?


MVMap实现了Copy-On-Write的B+树。

init()
MVMap的createVersion和writeVersion都初始化为MVStore的当前版本值currentVersion。同时id为MVStore传入。


put() {
    beforeWrite() //checkConcurrentWrite();  currentWriteVersion = writeVersion;
    // if root.version == writeVersion then copy. sharedFlags to controll whether share values/keys/childrens/counts,
    // copy()->COW, sharedFlags = SHARED_KEYS | SHARED_VALUES | SHARED_CHILDREN | SHARED_COUNTS
    copyOnWrite(root, writeVersion);
    
    // if root exceed limit, split it 
    splitRootIfNeeded(p, v);

    // 递归从root开始插入key/value，注意这是从上到下
    put(p, v, key, value);

    //更新root，另外会根据需要删除oldRoots保存多余版本的root，并且如果是新版本则添加到oldRoots保存
    newRoot();

    //重置currentWriteVersion为-1
    afterWrite();
}

put方法:
0.首先检查是否有并发修改（检查并发修改版本是否为-1，然后设置为当前写版本），如果有则抛出异常。
1.然后比较root的当前version是否为当前的writeVersion，如果不是则shallow copy新的page作为新root。MVStore的每次commit都会使writeVersion + 1。
2.如果root超出大小限制，则split为两个兄弟page，并且新建一个root，作为它们的parent。
3.然后从root开始递归向leaf插入value，如果超出大小限制，则split。递归过程中，只要遇到node/leaf，如果不是和当前writeVersion相等，都会进行copy。这样会尽可能地把Page从old chunk移动到当前version的chunk（commit的时候写入）。
4.设置新的root。（removeUnusedOldVersions, etc...）
5.设置并发修改版本为-1

注意：
关于第3点，在copyOnWrite时，只要找到node，则直接Copy，事实上，put的时候可能只会对leaf结点有影响，node结点只要不split就没有变化，这样做可以在commit的时候把尽可能多的旧page写到commit的Chunk中，这样就



get(key)方法就是从root开始二分查找B+树。


===============
MVMapConcurrent
===============

==========
MVRTreeMap
==========




======
 Page
======
Page是MVMap的B+树结构对象。可以作为node和leaf结点。

Page
--MVMap map
--long version            记录当前的version
--int keyCount
--Object[] keys
--Object[] values
--int childCount          node专用
--long[] children         node专用，记录Page的pos，MVStore.readPage()
--Page[] childrenPages    node专用，记录Page对象
--long pos                存储pos，如果已经存储硬盘，则不为0。



Page.binarySearch(Object key)，标准的Binary Search实现，其中返回-(low + 1)表示要插入的位置为low，查找完成后记录本次查找的结果cachedCompare，这样下次开始查找的位置从cachedCompare开始，如果和上次查找一样，则可以马上结束查找。

Page的insert采用递归式从上至下的insert node方式，首先判断插入的结点是否超过限制，是则首先split，然后插入对应的子结点，然后重新从该父结点开始，递归继续insert node。
缺点：需要多次binary search。。。
这样做的目的应该是希望尽可能地更新结点的version，等下次commit的时候写入新的chunk。这样旧的chunk没有数据时，就可以重复利用旧空间。



Page的B+树结构和PageBtreeLeaf/PageDataLeaf大致相同。
Node结点时，keys[i]的值为childrenPages[i]和children[i]所指的childrenPage的最大值，该子结点范围为[keys[i - 1], keys[i])。
leaf结点之间同样没有链接，要遍历下一个叶子结点，必须递归查询父node结点，获取兄弟叶子结点。


Page.copy()  使用的是Copy on Write的模式，只有当真正修改数组元素时，才进行复制对应的数组。
0.创建新的Page对象，这是一个shallow copy对象，所有的数组都具有相同的引用。
1.removePage()。实际上是往MVStore注册当前version的对应Chunk的maxLenLive和pageCountLive减去相应的值。另外，如果是meta在commit过程中的修改，则为上一个版本的注册。


=======
总结
=======
PageStore是传统的存储系统，提供了数据流式存储日志，以及随机B+树块写入操作。steal, No force的缓存策略（可以控制是否commit的时候flush日志，定时刷新日志。同时为了提高性能，只在checkpoint阶段执行writeback写入B+树数据块，不会定时写入）。对于并发控制采用简单的读写锁，也有MVCC和乐观并发控制作为并发控制的另外选择（不过有bug）。

MVStore是采用了Log structured storage的新型存储系统，主要优点是采用版本控制读写，commit的时候把所有的数据块变为顺序写入新的chunk，采用No steal, force的缓存策略。另外，默认采用了MVCC以及乐观并发控制的并发控制方法。



==========================================================
              DB相关
==========================================================

=========
 MVTable
=========

  包含MVPrimaryIndex，MVDelegateIndex，MVSecondaryIndex三种类型的index。MVPrimaryIndex专门用于scan，MVDelegateIndex封装了MVPrimaryIndex，专门用于primary index，MVSecondaryIndex专门用于二级索引。
  同样是首先初始化MVPrimaryIndex，默认的mainIndexColumn为-1，也就是使用内在的key，然后添加到indexes。接着meta表如果存在用户定义的primary index，则判断如果该index定义符合条件（单列，并且类型是long,int,short,byte，并且是ASC排序），则设置mainIndexColumn为该列。并且此时就会创建MVDelegateIndex添加到indexes，专门用于primary index查询。（MVPrimaryIndex只能用于scan）

MVPrimaryIndex初始化关联MVStore
//getId()是objectID，创建新表的时候由Database.allocateObjectId()分配。然后保存到meta表中（Database.addMeta()）。database初始化的时候取meta表重新创建表。
mapName = "table." + getId();
//dataMap就包含了MVTable的数据。
dataMap = mvTable.getTransaction(null).openMap(mapName, keyType, valueType);

================
 MVPrimaryIndex
================
TransactionMap dataMap的map key就是row key。map value存放的都是整个row。
getCost()和PageDataIndex.getCost()实现一致。10 * (rowCount + Constants.COST_ROW_OFFSET);


=================
 MVDelegateIndex
=================
和PageDelegateIndex作用类似，作为以primary key为索引进行select的index。简单封装MVPrimaryIndex，getCost(), find()都和PageDelegateIndex的实现一致。

==================
 MVSecondaryIndex
==================
TransactionMap dataMap的map key中除了index columns外，还包括row key。这样可以保证key和value唯一对应。因此map key的列数量keyColumns为索引列数量+1。map value存放的都为ValueNull对象的单例。这样在每次构造map key的时候就把row key添加到最后。

getCost的实现和MVDelegateIndex一致。

TODO
find(Session session, SearchRow first, boolean bigger, SearchRow last)
bigger = true，没有采用一次二分查找，而是offset * 2后再/2的方法找到刚好大于first的key，然后继续判断当前key是否存在？


类比PageBtree.find(SearchRow compare, boolean bigger, boolean add, boolean compareKeys) 通过控制bigger查找刚好少于等于或大于compare的索引。使用一次二分查找即可。


========================
      Transaction
========================
TransactionStore
--MVMap<Long, Object[]> undoLog;            //undo日志记录 Key: {opId}, value: {mapId, key, oldValue}
--MVStore store


TransactionStore.Transaction [static class]  //每个Session对象有当前的一个Transaction对象
--TransactionStore store
--int transactionId                         //transactionId表示当前事务ID。由TransactionStore保证唯一。
--long logId                                //TransactionStore.undoLog里记录的最后日志ID。 初始化时为0。Transaction.log()/rollbackToSavepoint()等会修改logId.
初始化：Session.getTransaction()初始化Transaction对象。



TransactionMap<K, V>   //组合了MVMap以及Transaction对象，封装为具有事务特性的MVMap。
--int mapId
--long readLogId                  //TransactionMap读值时默认logId。当前事务更新不会立即可见，支持语句处理操作，如update test set id = id + 1。目前都为Long.MAX_VALUE
--MVMap<K, VersionedValue> map    //写最新数据的存储map   Key: rowKey, Value: VersionedValue
--Transaction transaction         //当前关联的Transaction对象。



           TransactionStore
        ^                   ^
        |                   |
Transaction（Session）    Transaction（Session）  ...   (每个Session有单个Transaction引用TransactionStore)
        ^
        |
TransactionMap(MVPrimaryIndex.datamap.map/mapId)  ... (MVPrimaryIndex.dataMap会负责创建属于该Session的TransactionMap，作为提供给该Session的接口查询数据)



MVPrimaryIndex -> dataMap(TransactionMap  -> Transaction = null)


==========
  commit
==========
Session.commit()
Session.commit开始，和PageStore相比，由于不会写Session的undoLog，undo日志的commit由Transaction和TransactionStore负责。
1.遍历获得共享锁的表locks，分别调用这些表的MVTable.commit()，(MVTable.commit只是增加database的modificationDataId。select的lastResult缓存相关）
2.Transaction.commit() -> TransactionStore.commit()
  通过从0开始递增到Transaction的logId，和TransactionId组合为operationId，这样就可以获得所有未提交修改对应的undo日志的key。通过TransactionStore.undoLog，找出该事务的所有undo日志，注意如果logId返回的undo日志为空，则可能因为在之前commit过程中删除了部分undo日志，但没有完成commit却发生了crash，因此重新找到下一条该事务提交的undo日志，继续上次没有完成的commit。
  日志包含三个对象{mapId, rowKey, oldValue}，commit过程只需要利用mapId从TransactionStore.maps中找出undo记录对应的MVMap，然后从该map中根据rowKey找出未提交数据VersionedValue value，如果value为null，表示在之前的undo记录删除，因此忽略（如先insert后delete）；如果value.value为null，也就是当前事务删除值，则调用map.remove(key)删除该记录；如果value.value有值，则重新创建operationId为0，value相同的VersionedValue，map.put(key, value)插入即可。
  顺利完成该undo日志的处理后，undoLog.remove(key)删除该undo日志的记录

3.TransactionStore.endTransaction()
当前没有已经begin并且修改了数据的事务（undoLog为空），并且MVStore中存在太多脏page数（> 3/4最大值，最大值=19kb / pageSplitSize页面split大小）则调用MVStore.commit()刷新记录。


------
BackgroundWriterThread.run() -> MVStore.commitInBackground()
除了事务显示commit外，MVStore有后台线程定时commit，刷新数据到硬盘。注意这是个多线程刷新，刷新的时候可能还在修改MVMap的数据。




==========
 rollback
==========
Session.rollback()
同样，不会写Session的undoLog，rollback由TransactionStore负责。
Session.rollbackTo()
1.利用Iterator遍历，日志id从Transaction.logId逐渐减小到savepointId（如果全部rollback，则为0），同样和TransactionId组成operationId，通过TransactionStore.undoLog找出要rollback的所有undo日志。对于每条undo日志，根据mapId找到对应的MVMap，然后把mapName，rowKey，oldValue封装Change对象返回。mapName是通过mapId向MVStore.meta元数据查找出的名字。
2.根据mapName找出对应的MVTable。由于MVPrimaryIndex的MVMap的mapName是table.xx，MVSecondaryIndex的mapName是index.xx。所以只对MVPrimaryIndex的undo日志执行rollback操作，通过构造UndoLogRecord重新调用MVTable进行remove/put操作。注意，此过程中会重新产生undo日志。另外此过程并没有删除undo日志。
3.Transaction.commit()
重新commit在rollback过程中产生undo日志。


TransactionStore.rollbackTo()
与Session.rollbackTo类似，但会在完成undo操作后，直接删除undo日志，比前者要方便简单。另外就算在该过程crash，也不会出现问题，因为每个步骤都是可逆的。



总结：
要注意区分commit和rollback：
1.commit在redo过程中会删除undo日志，rollback并不会删除任何undo日志，相反还会写入新的undo日志，直到完全rollback完成后再次commit才会删除undo日志。
2.rollback删除undo日志是从最大的logId开始到0的，commit是从0开始到最大的logId
3.commit和rollback都必须先执行操作后删除undo日志
4.Session.rollback先undo所有更改后再commit删除所有undo日志。TransactionStore.rollbackTo则在undo一个操作后，马上删除对应undo日志。两者过程中遇到crash都可以recover。相比较，insert和delete都是先写undo日志，然后再更新数据。



savepoint x1;
ROLLBACK TO SAVEPOINT x1;



==========
 Recover
==========
MVStore负责recover相关。
1.undo日志是TransactionStore.undoLog，MVMap负责保存。
2.MVTable表的索引MVPrimaryIndex和MVSecondaryIndex的数据组织内部同样也是由MVMap保存。
因此只需要MVStore负责恢复MVMap即可。事实上，由于MVStore后台线程会定期commit，MVStore把符合要求MVMap的Page刷新到硬盘上，包括undo日志以及未提交的修改数据。所以当数据库crash重启后，会出现未提交数据在MVMap中，此时就需要利用undo日志进行recover操作。

transaction状态：
STATUS_CLOSED     = 0       a closed transaction (committed or rolled back)                    commit()/rollback()完成后设置。
STATUS_OPEN       = 1       an opened but not commit or roll back yet transaction.             初始化时设置
STATUS_PREPARED   = 2       a prepared transaction                                             2pc相关
STATUS_COMMITTING = 3       being committed, but possibly not yet finished (Store is closed)   commit()中设置


recover操作
MVTableEngine.Store.initTransactions()
调用TransactionStore.getOpenTransactions()恢复在关闭前，还没开始commit或需要rollback的（STATUS_OPEN）或者已经开始但没有完成commit（STATUS_COMMITTING）的各个transaction的状态。然后这些transaction的状态为STATUS_OPEN的需要rollback，STATUS_COMMITTING的需要commit。

注意此时的rollback，执行的是Transaction.rollback()，会执行日志删除！

====
总结
====
1.MVStore的recover步骤，对于非STATUS_COMMITTING状态的事务（还没开始commit）都会进行undo操作。
2.MVStore认定只有Transaction至少logId >= 0的undo日志被删除，这样Transaction才算处于STATUS_COMMITTING，如果发生crash，recover步骤就会redo这些事务。rollback则只有当rollback操作完成后，后续执行的Transaction.commit()才开始删除undo日志。


=====================
      Select
=====================
Select -> TableFilter -> MVTable ->  -> MVPrimaryIndex/MVDelegateIndex/MVSecondaryIndex -> TransactionStore -> MVStore -> CacheLongKeyLIRS/FileStore -> Chunck -> Page


所有的MVTable
MVTable.TransactionStore store = Database.MVTableEngine.Store store.transactionStore 

MVPrimaryIndex.find()
map = getMap();
new MVStoreCursor(TransactionMap.entryIterator(min), max);

TransactionMap.entryIterator(min)
    cursor = MVMap.cursor(from) new Cursor(MVMap, Page root, from) 
  return new Iterator<Entry<K, V>>() { 
  {
    fetchNext(); //初始化，移动cursor到min的前一个值
  }
  
  cursor.next(),cursor.hasNext() 
  }


select xxx from test where xxx
------
Select操作符层的逻辑基本没变，关键是MVStore层对数据的迭代方式不同。从IndexCursor.next()开始封装了不同的index迭代方式。另外还有关于对Transaction的支持。

IndexCursor.next()。
对于不同的index，调用方法Cursor find(TableFilter filter, SearchRow first, SearchRow last)。传入Select的范围，获取Cursor，然后利用该Cursor进行遍历。
*对于PageDataIndex，从root开始对B+树进行二分查找到达Leaf结点，然后返回PageDataCursor
*对于PageBtreeIndex，类似PageDataIndex的做法，从root开始到Leaf结点，返回PageBtreeCursor。
*对于MVPrimaryIndex，底层同样也是遍历B+树，但对于迭代器的封装更为模块化，具体如下：


IndexCursor.next()
------
包含三层迭代器，由上到下分别为：MVPrimaryIndex.MVStoreCursor，TransactionMap.entryIterator().Iterator<Entry<K, V>>，org.h2.mvstore.Cursor<K, V>。

TableFilter.next() -> IndexCursor.next() -> MVPrimaryIndex.MVStoreCursor.next() -> TransactionStore.TransactionMap.Iterator.next() -> org.h2.mvstore.Cursor.next()
org.h2.mvstore.Cursor.next() -> Page.getKey(int index)/Page.getValue(int index)


1.
MVPrimaryIndex.MVStoreCursor
--Entry<Value, Value> current
--Iterator<Entry<Value, Value>> it
--ValueLong last    //赋值为max
MVPrimaryIndex提供给IndexCursor的接口。利用it遍历Entry元素，发现超过last的时候，则设置current为null，表示遍历结束。
返回值给IndexCursor有两个方法
getSearchRow()和get()实现一样，把DataUtils.MapEntry<K, V>转换为Row返回给IndexCursor。   
类的实现逻辑和PageDataCursor一致

MVSecondaryIndex.MVStoreCursor
MVSecondaryIndex提供给IndexCursor的接口。
逻辑和MVPrimaryIndex.MVStoreCursor类似，遍历元素，发现超过last，则结束遍历。返回值给IndexCursor有两个方法
getSearchRow()只是简单转换K的值Row，只有row key以及索引列的值。
get()会通过MVTable利用row key从MVPrimaryIndex中获取对应Row的所有值。   
类的实现逻辑和PageBtreeCursor一致


2.
TransactionStore.TransactionMap.entryIterator().Iterator<Entry<K, V>>         //MVPrimaryIndex
fetchNext()中调用TransactionMap.getValue(key, readLogId, data)                //getValue()查找key对应已提交或当前事务修改的值。
把K，VersionedValue转换为DataUtils.MapEntry<K, V>，返回给MVStoreCursor。

TransactionStore.TransactionMap.wrapIterator().Iterator<K>                  //MVSecondaryIndex
fetchNext()中包括了includeUncommitted和containsKey()判断，当从Cursor获取了值后，如果includeUncommitted为true，直接返回。否则判断TransactionMap.containsKey()，如果不是已提交或当前事务修改，则跳过这个值。   

返回K给MVStoreCursor。


3.
org.h2.mvstore.Cursor<K, V>
--Page root
--MVMap map
--ValueLong from              //赋值为min
--CursorPos pos
--ValueLong current
--K current, last;            //last为已经遍历了的Key，current为当前需要遍历的Key
--V currentValue, lastValue;  //last为已经遍历了的Value，current为当前需要遍历的Value
Cursor用于遍历MVMap的元素，从from开始按照map key 大小遍历Page到最后（没有max限制），如果找不到小于等于from的就直接找刚大于from的，等MVStoreCursor进行过滤。
min()方法负责进行二分查找并记录对应的CursorPos，fetchNext()则负责按照CursorPos的位置获取下一个值。
CursorPos保存遍历二叉查找树的位置信息，每个对象记录当前的Page，以及index，还有父结点的CursorPos引用parent。另外要注意，index对于leaf结点，则是刚好大于等于查找key的索引；对于node结点，则是index + 1，也就是下一个叶子结点的索引。这是因为当前leaf结点已经被遍历，返回到node结点时，就是需要直接遍历下一个leaf结点了。
返回K，VersionedValue给2。
利用Page提供的getKey(index)，getValue(index)返回key和value。
Cursor直接遍历MVMap底层的B+树，因此符合前缀索引的选择逻辑，注意map key中多个索引列的sortTypes可能不同。ValueDataType为map key类型。


=====================
      Insert
=====================
insert into test values(5, 'aaa')

不同事务：
Insert same row？     由于获取的VersionedValue为未提交事务写入，抛出ERROR_TRANSACTION_LOCKED异常
Inserted and delete？ Inserted无法被select
Inserted and update？ Inserted无法被select


同一事务：
Insert same row？  MVPrimaryIndex.add()抛出DUPLICATE_KEY_1异常



TransactionStore.VersionedValue    //operationId和对应value的封装对象
--long operationId
--Object value


MVTable
--MVPrimaryIndex primaryIndex;
--TransactionStore store;
--...    //剩下的基本和RegularTable差不多

MVPrimaryIndex
--MVTable mvTable;
--String mapName;
--TransactionMap<Value, Value> dataMap;     //数据接口对象。
--long lastKey;


Insert.insertRows():
MVTable.lock()和RegularTable的lock()方法实现逻辑一样。
MVTable.addRow(Session session, Row row)
session.log(); 直接返回。已经在TransactionStore记录了undo日志。

*****
MVTable.addRow(Session session, Row row):
从MVPrimaryIndex开始顺序遍历table的所有indexes调用Index.add(session, row);  (下面接着)
如果add抛出异常失败，则调用Transaction.rollbackToSavepoint(savepoint);
另外还有MultiVersionIndex判断？但已经不可能出现MultiVersionIndex？

*****
MVPrimaryIndex.add(Session session, Row row):
1.首先根据mainIndexColumn设置row的rowKey。然后是getContainsLargeObject的LOB判断。这些和PageDataIndex逻辑一致。
2.
getMap(session) 
-->
TransactionMap<K, V> m = new TransactionMap<K, V>(transaction, map, mapId);
m.setSavepoint(Long.MAX_VALUE));
获取当前Session对应的TransactionMap，并设置savePoint，即readLogId最大。（所有的更新都可被当前事务可见）
注意该TransactionMap底层的数据存储MVMap与MVPrimaryIndex.dataMap一致，也就是MVTable底层的存储。

3.Value old = map.getLatest(key); (get(key, Long.MAX_VALUE);) 获取要插入rowKey的最新value，如果不为null，则抛出DUPLICATE_KEY_1异常。为null则接着执行。
4.map.put(key, ValueArray.get(row.getValueList()));             (下面接着)
插入row到Session对应的TransactionMap中。
5.lastKey = Math.max(lastKey, row.getKey());

最后，put成功以后，dataMap对应的key就为VersionedValue值，其中包含了operationId和具体的value值。此时还没有commit。

undo日志记录的是之前的值，是null



*****
TransactionMap.put(K key, V value)：
->set(key, value)
V old = get(key);                       //获取当前key最新更新的值。下面分解
boolean ok = trySet(key, value, false);  //下面分解
trySet失败则抛出并发更新异常。

*****
-->1.  get(key):
->VersionedValue data = map.get(key);  return getValue(key, maxLog, data);
从存储map获取key保存的VersionedValue。

TransactionMap.getValue(K key, long maxLog, VersionedValue data)
根据rowKey和maxLog获取VersionedValue。注意判断data的事务ID和logID。
1.如果data.operationId为0，则为已提交数据，直接返回。
2.否则从operationId抽取transactionId，如果和当前TransactionMap.transaction的事务id相等，则为本事务添加，然后operationId抽取logID比maxLog小则返回data。以上都不属于则要undoLog读取值。
3.从database所属的TransactionStore.undoLog.get(operationId)获取没提交事务修改前的data
4.如果data为null，则可能transaction刚刚commit或rollback，但事务可能仍然打开状态。
5.如果data仍然为null则已经被删除，否则继续判断，如果该data的事务id不是当前事务id，或者logID比当前大，则都要抛出并发更新异常。如果是当前事务修改且小于maxLogid，则返回该data。

*****
-->2.  trySet(K key, V value, boolean onlyIfUnchanged):
尝试更新或者删除key指定的value，可以指定只有当map打开后key对应值仍然不变才执行操作（onlyIfUnchanged）。
1.先直接从map获取key当前的值current。map.get(key)

分支2.onlyIfUnchanged为true。首先利用readLogId读取map中key的值old，getValue(key, readLogId)，如果old和current相等就可以接着修改，否则继续判断，如果old的事务ID不同于当前事务ID，则直接返回false。如果是同一事务ID，如果value为null，则表示要删除之前添加的值，忽略。如果current.value为null，则表示之前删除了该值，现在进行添加，则这里直接跳到3继续执行添加操作。如果两者都不为null，证明要重新更新？return false？ 
目前均为调用均为false。
update test set id = id + 1?

3.根据关联的Transaction以及value创建VersionedValue对象newValue，注意VersionedValue的operationId = ((long) transaction.transactionId << 40) | transaction.logId;

分支4.如果current为null，则表示newValue需要进行添加操作。首先往当前事务添加undo日志（记录值为更新前旧值），log(int mapId, Object key, Object oldValue)，然后进行一个加锁的同步插入到map的操作，putIfAbsent(key, newValue)（synchronized方法），如果插入失败（可能有其它事务正在更新），则删除事务刚刚添加的undo日志，logUndo()，返回false。插入成功直接返回true。
细节：Transaction.log()/logUndo()实现都是请求TransactionStore记录日志，TransactionStore利用MVMap保存undo日志（undoLog对象，key为operationID，value为{ mapId, key, oldValue }数组），由于属于database全局，因此需要synchronized同步。 

分支5.current不为null，通过operationID获取事务ID，如果不为当前事务ID，则返回false。（已有其它事务进行修改，类似MVCC）否则为当前事务的修改，类似4的做法，首先Transaction记录undo日志，调用map.replace(key, current, newValue)（synchronized方法）更新值，成功返回true，失败则删除添加的undo日志，返回false。
细节：replace()方法同样为synchronized，首先查看map中对应key的值是否和current相等，如果相等才修改对应值，否则返回false。


*MVSecondaryIndex.add()
------
MVSecondaryIndex的插入逻辑与MVPrimaryIndex类似。但也有部分注意的地方。

具体做法：首先是获取Session对应的TransactionMap map（getMap()和MVPrimaryIndex一样的实现），然后把row按照MVSecondaryIndex的index columns + row key转换成ValueArray作为map的key，如果不是unique索引，则直接插入(key, ValueNull)到map即可（插入过程和MVPrimaryIndex一样经过Transaction的判断）。

这里的关键是要注意unique索引的处理：
1.首先在插入map之前，找出已提交数据中，刚好大于等于插入row的row r2，如果插入row和r2不相等可以继续插入，否则要继续判断r2的ValueNull，调用BaseIndex.containsNullAndAllowMultipleNull()判断是否允许NULL的条件，如果不允许则抛出Duplicate key异常。（unique索引有几种情况允许null的存在，详细看代码）
2.插入map之后，还要继续判断未提交数据是否含有重复索引，如果含有，抛出CONCURRENT_UPDATE_1异常。(为何不在插入前判断？)

undo日志记录的是之前的值，是ValueNull



=====================
      Delete
=====================
delete from test where id = 4

Delete same row？     Delete是设置为null，后面的事务接着Delete时会因为存在没提交数据而失败
Deleted and insert？  会因为select出原来的key，导致primary key冲突。
Deleted and update？  与Delete same row一样，抛出异常

同一事务：
Delete same row?    找不到row，忽略



Delete.update()
权限校验，加上共享表锁，以及where条件查询出需要delete的row。
MVTable.removeRow删除row。
Session.log()同样因为MVTable跳过Session的undo日志记录。

*****
MVTable.removeRow(Session session, Row row)
和RegularTable一样，逆序遍历indexes，删除row。


*****
MVSecondaryIndex.remove(Session session, Row row)
getMap()创建Session对应的TransactionMap，然后调用TransactionMap.remove(key)删除row，其实就是调用set(key, null)把key对应的值置为null。
这里要注意，MVSecondaryIndex保存的键值为(key, VersionedValue.value = ValueNull)，值ValueNull虽然表示null，但事实是对象，与null不能混为一谈。

VersionedValue.value变化：
ValueNull -> null
undo日志记录的是之前的值，也就是ValueNull


*****
MVPrimaryIndex.remove(Session session, Row row)
getMap()获取TransactionMap，TransactionMap.remove(key)删除row。

VersionedValue.value变化：
ValueArray -> null
undo日志记录的是之前的值，也就是ValueArray


=====================
      Update
=====================
同样是先delete后insert。

Update same row？    第二次Update的时候由于存在没提交数据的null，因此失败
updated and delete？ 同样是存在没提交数据的null，因此失败
updated and insert？ Insert same row一样，primary key冲突

同一事务：
update same row?    成功


MVPrimaryIndex.dataMap.map包括有两个entry，一个是update前的key1，对应的value为null，另外一个是update后的key2，对应的value为更新row。


create table test5(
id int primary key,
id1 int,
v1 int,
FOREIGN KEY(id1) REFERENCES (id)
)


=======
总结
=======
1.以MVStore为存储引擎，实现了事务性的存储模块TransactionStore，并发控制的策略是MVCC(MV_STORE=TRUE的时候，默认设置Database.multiVersion=true) + 乐观并发控制
2.利用MVMap保存undo日志，以及在索引的MVMap中保存没提交的数据（可以当redo日志使用，delete的没有提交要设置为null占位）
3.使用steal,no-force缓存策略，recover的时候需要根据事务是否提交进行redo和undo（与ARIES不同的策略）




============================
语法特性：

Create temp[GLOBAL TEMPORARY] table

Temporary tables are deleted when closing or opening a database. Temporary tables can be global (accessible by all connections) or local (only accessible by the current connection). The default for temporary tables is global. Indexes of temporary tables are kept fully in main memory, unless the temporary table is created using CREATE CACHED TABLE.


TODO:


compact

FOR UPDATE


Select
//order by --  TimSort!!  http://svn.python.org/projects/python/trunk/Objects/listsort.txt


View实现
//FOREIGN KEY


compact
close database...Database.closeOpenFilesAndUnlock()


//TCP server
// memtable






